<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 8]
- [cs.CL](#cs.CL) [Total: 2]
- [cs.LG](#cs.LG) [Total: 9]
- [cs.AI](#cs.AI) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Any4D: Unified Feed-Forward Metric 4D Reconstruction](https://arxiv.org/abs/2512.10935)
*Jay Karhade,Nikhil Keetha,Yuchen Zhang,Tanisha Gupta,Akash Sharma,Sebastian Scherer,Deva Ramanan*

Main category: cs.CV

TL;DR: Any4D是一个可扩展的多视角transformer，用于度量尺度、密集前馈4D重建，能够直接生成N帧的逐像素运动和几何预测，支持多种模态输入，在精度和计算效率上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常专注于2视角密集场景流或稀疏3D点跟踪，而近期从单目RGB视频进行4D重建的方法无法处理其他模态和传感器数据。需要一种更灵活、全面的4D重建框架。

Method: 采用模块化的4D场景表示：将每视角的4D预测编码为以局部相机坐标表示的自我中心因素（深度图和相机内参）和以全局世界坐标表示的他者中心因素（相机外参和场景流）。使用可扩展的多视角transformer架构，支持RGB-D帧、IMU自我运动、雷达多普勒测量等多种模态输入。

Result: 在多种设置下取得优越性能：精度上误差降低2-3倍，计算效率上快15倍。为多个下游应用开辟了新途径。

Conclusion: Any4D提供了一个灵活、高效的4D重建框架，能够处理多种传感器模态，在精度和速度上都显著优于现有方法，具有广泛的应用前景。

Abstract: We present Any4D, a scalable multi-view transformer for metric-scale, dense feed-forward 4D reconstruction. Any4D directly generates per-pixel motion and geometry predictions for N frames, in contrast to prior work that typically focuses on either 2-view dense scene flow or sparse 3D point tracking. Moreover, unlike other recent methods for 4D reconstruction from monocular RGB videos, Any4D can process additional modalities and sensors such as RGB-D frames, IMU-based egomotion, and Radar Doppler measurements, when available. One of the key innovations that allows for such a flexible framework is a modular representation of a 4D scene; specifically, per-view 4D predictions are encoded using a variety of egocentric factors (depthmaps and camera intrinsics) represented in local camera coordinates, and allocentric factors (camera extrinsics and scene flow) represented in global world coordinates. We achieve superior performance across diverse setups - both in terms of accuracy (2-3X lower error) and compute efficiency (15X faster), opening avenues for multiple downstream applications.

</details>


### [2] [Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation](https://arxiv.org/abs/2512.10949)
*Yiwen Tang,Zoey Guo,Kaixin Zhu,Ray Zhang,Qizhi Chen,Dongzhi Jiang,Junli Liu,Bohan Zeng,Haoming Song,Delin Qu,Tianyi Bai,Dan Xu,Wentao Zhang,Bin Zhao*

Main category: cs.CV

TL;DR: 本文首次系统研究了强化学习在文本到3D自回归生成中的应用，提出了AR3D-R1模型，通过奖励设计、算法改进和层次化优化解决了3D生成中的空间复杂性和一致性挑战。


<details>
  <summary>Details</summary>
Motivation: 强化学习在2D图像生成中已证明有效，但应用于3D生成仍面临挑战，因为3D对象具有更高的空间复杂性，需要全局一致的几何结构和细粒度局部纹理，对奖励设计和RL算法更为敏感。

Method: 从四个维度系统研究RL在文本到3D生成中的应用：1) 奖励设计评估；2) GRPO算法变体研究；3) 引入MME-3DR基准测试；4) 提出Hi-GRPO层次化优化方法，最终开发AR3D-R1模型。

Result: 开发了首个RL增强的文本到3D模型AR3D-R1，能够从粗略形状到纹理细化进行专家级生成。研究表明与人类偏好对齐的奖励设计和多模态模型提供的稳健信号对3D属性生成至关重要。

Conclusion: 本研究为RL驱动的3D生成推理提供了重要见解，证明了强化学习在解决3D生成空间复杂性和一致性挑战方面的有效性，为未来3D生成研究奠定了基础。

Abstract: Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1.

</details>


### [3] [MMSI-Video-Bench: A Holistic Benchmark for Video-Based Spatial Intelligence](https://arxiv.org/abs/2512.10863)
*Jingli Lin,Runsen Xu,Shaohao Zhu,Sihan Yang,Peizhou Cao,Yunlong Ran,Miao Hu,Chenming Zhu,Yiman Xie,Yilin Long,Wenbo Hu,Dahua Lin,Tai Wang,Jiangmiao Pang*

Main category: cs.CV

TL;DR: MMSI-Video-Bench是一个全面评估多模态大语言模型视频空间智能的基准测试，包含1,106个问题，覆盖感知、规划、预测和跨视频推理四个层次，揭示了当前模型与人类在空间理解方面存在巨大差距。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏全面评估MLLMs在连续视觉输入中空间理解能力的基准测试，而空间理解对于MLLMs成为物理环境中的通用助手至关重要。

Method: 构建了一个完全人工标注的视频空间智能基准测试，采用四层框架（感知、规划、预测、跨视频推理），基于25个数据集和内部视频的1,278个片段，每个问题由3DV专家精心设计和审查。

Result: 评估了25个开源和专有MLLMs，发现显著的人机差距：许多模型表现接近随机水平，最佳推理模型落后人类近60%。空间微调模型在基准测试上泛化能力仍然不足。

Conclusion: 该基准测试为推进视频空间智能研究提供了坚实的测试平台，揭示了当前模型在几何推理、运动基础、长时程预测和跨视频对应方面的系统性失败。

Abstract: Spatial understanding over continuous visual input is crucial for MLLMs to evolve into general-purpose assistants in physical environments. Yet there is still no comprehensive benchmark that holistically assesses the progress toward this goal. In this work, we introduce MMSI-Video-Bench, a fully human-annotated benchmark for video-based spatial intelligence in MLLMs. It operationalizes a four-level framework, Perception, Planning, Prediction, and Cross-Video Reasoning, through 1,106 questions grounded in 1,278 clips from 25 datasets and in-house videos. Each item is carefully designed and reviewed by 3DV experts with explanatory rationales to ensure precise, unambiguous grounding. Leveraging its diverse data sources and holistic task coverage, MMSI-Video-Bench also supports three domain-oriented sub-benchmarks (Indoor Scene Perception Bench, Robot Bench and Grounding Bench) for targeted capability assessment. We evaluate 25 strong open-source and proprietary MLLMs, revealing a striking human--AI gap: many models perform near chance, and the best reasoning model lags humans by nearly 60%. We further find that spatially fine-tuned models still fail to generalize effectively on our benchmark. Fine-grained error analysis exposes systematic failures in geometric reasoning, motion grounding, long-horizon prediction, and cross-video correspondence. We also show that typical frame-sampling strategies transfer poorly to our reasoning-intensive benchmark, and that neither 3D spatial cues nor chain-of-thought prompting yields meaningful gains. We expect our benchmark to establish a solid testbed for advancing video-based spatial intelligence.

</details>


### [4] [BabyVLM-V2: Toward Developmentally Grounded Pretraining and Benchmarking of Vision Foundation Models](https://arxiv.org/abs/2512.10932)
*Shengao Wang,Wenqi Wang,Zecheng Wang,Max Whitton,Michael Wakeham,Arjun Chandra,Joey Huang,Pengyue Zhu,Helen Chen,David Li,Jeffrey Li,Shawn Li,Andrew Zagula,Amy Zhao,Andrew Zhu,Sayaka Nakamura,Yuki Yamamoto,Jerry Jun Yokono,Aaron Mueller,Bryan A. Plummer,Kate Saenko,Venkatesh Saligrama,Boqing Gong*

Main category: cs.CV

TL;DR: BabyVLM-V2是一个基于婴儿发展轨迹的视觉语言模型框架，通过纵向多模态预训练集和认知评估工具包，在小规模模型上实现了与GPT-4o竞争的性能。


<details>
  <summary>Details</summary>
Motivation: 早期儿童发展轨迹为视觉基础模型的高效预训练提供了自然目标，旨在开发更符合人类认知发展规律的视觉语言模型。

Method: 1) 构建纵向、多方面的婴儿中心化视听语料预训练集；2) 开发DevCV Toolbox认知评估工具包，将NIH Baby Toolbox的视觉相关测量转化为10个多模态任务；3) 采用紧凑模型从头开始预训练。

Result: 紧凑模型在DevCV Toolbox上表现出色，在某些任务上超越了GPT-4o，展示了从零开始预训练的小模型也能达到竞争性性能。

Conclusion: BabyVLM-V2框架为发展合理的视觉基础模型预训练研究提供了原则性、统一的解决方案，有望加速该领域的发展。

Abstract: Early children's developmental trajectories set up a natural goal for sample-efficient pretraining of vision foundation models. We introduce BabyVLM-V2, a developmentally grounded framework for infant-inspired vision-language modeling that extensively improves upon BabyVLM-V1 through a longitudinal, multifaceted pretraining set, a versatile model, and, most importantly, DevCV Toolbox for cognitive evaluation. The pretraining set maximizes coverage while minimizing curation of a longitudinal, infant-centric audiovisual corpus, yielding video-utterance, image-utterance, and multi-turn conversational data that mirror infant experiences. DevCV Toolbox adapts all vision-related measures of the recently released NIH Baby Toolbox into a benchmark suite of ten multimodal tasks, covering spatial reasoning, memory, and vocabulary understanding aligned with early children's capabilities. Experimental results show that a compact model pretrained from scratch can achieve competitive performance on DevCV Toolbox, outperforming GPT-4o on some tasks. We hope the principled, unified BabyVLM-V2 framework will accelerate research in developmentally plausible pretraining of vision foundation models.

</details>


### [5] [OmniView: An All-Seeing Diffusion Model for 3D and 4D View Synthesis](https://arxiv.org/abs/2512.10940)
*Xiang Fan,Sharath Girish,Vivek Ramanujan,Chaoyang Wang,Ashkan Mirzaei,Petr Sushko,Aliaksandr Siarohin,Sergey Tulyakov,Ranjay Krishna*

Main category: cs.CV

TL;DR: OmniView是一个统一的4D一致性框架，通过分离空间、时间和视角条件表示，实现了多种4D任务（如新视角合成、文本/图像到视频生成等）的泛化能力，在多个基准测试中表现优于任务专用模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法将相机控制注入扩散模型时，通常只专注于特定的4D一致性任务子集（如新视角合成、文本到视频等），导致这些碎片化方法在可用的3D/4D数据的不同子集上训练。作者希望建立一个统一的框架，能够泛化到广泛的4D一致性任务。

Method: OmniView框架将空间、时间和视角条件分开表示，允许这些输入的灵活组合。这种方法使得模型能够处理静态、动态和多视角输入的新视角合成，在时间上向前和向后外推轨迹，以及从文本或图像提示创建具有完整相机控制的视频。

Result: OmniView在多个基准测试和指标上与任务专用模型竞争，在相机条件扩散模型中：多视角NVS LLFF数据集上图像质量得分提升33%，动态NVS Neural 3D Video基准上提升60%，RE-10K静态相机控制上提升20%，文本条件视频生成中相机轨迹误差减少4倍。

Conclusion: OmniView通过一个模型展示了强大的泛化能力，证明了通用4D视频模型的可行性。该框架能够统一处理多种4D一致性任务，为4D内容生成提供了更灵活和高效的解决方案。

Abstract: Prior approaches injecting camera control into diffusion models have focused on specific subsets of 4D consistency tasks: novel view synthesis, text-to-video with camera control, image-to-video, amongst others. Therefore, these fragmented approaches are trained on disjoint slices of available 3D/4D data. We introduce OmniView, a unified framework that generalizes across a wide range of 4D consistency tasks. Our method separately represents space, time, and view conditions, enabling flexible combinations of these inputs. For example, OmniView can synthesize novel views from static, dynamic, and multiview inputs, extrapolate trajectories forward and backward in time, and create videos from text or image prompts with full camera control. OmniView is competitive with task-specific models across diverse benchmarks and metrics, improving image quality scores among camera-conditioned diffusion models by up to 33\% in multiview NVS LLFF dataset, 60\% in dynamic NVS Neural 3D Video benchmark, 20\% in static camera control on RE-10K, and reducing camera trajectory errors by 4x in text-conditioned video generation. With strong generalizability in one model, OmniView demonstrates the feasibility of a generalist 4D video model. Project page is available at https://snap-research.github.io/OmniView/

</details>


### [6] [Mull-Tokens: Modality-Agnostic Latent Thinking](https://arxiv.org/abs/2512.10941)
*Arijit Ray,Ahmed Abdelkader,Chengzhi Mao,Bryan A. Plummer,Kate Saenko,Ranjay Krishna,Leonidas Guibas,Wen-Sheng Chu*

Main category: cs.CV

TL;DR: Mull-Tokens是一种模态无关的潜在令牌，允许模型在文本和图像模态之间自由思考，以解决多模态推理问题，在空间推理基准上相比基线有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现实世界推理需要超越语言的多种模态（空间、时间、可操作性等），现有多模态模型依赖专业工具、图像生成或手工数据，存在脆弱性和扩展性问题。

Method: 提出Mull-Tokens（模态无关潜在令牌），通过预训练在文本或图像模态中保存中间信息，采用两阶段训练：先用交错文本-图像轨迹监督训练，然后用最终答案进行无监督微调。

Result: 在四个具有挑战性的空间推理基准测试中，Mull-Tokens相比仅文本推理或交错图像-文本推理的基线方法平均提升3%，在推理密集的谜题解决任务上最高提升16%。

Conclusion: Mull-Tokens为文本和视觉推理的落地挑战提供了简单解决方案，允许模型在多个模态中抽象思考，是多模态推理的有效方法。

Abstract: Reasoning goes beyond language; the real world requires reasoning about space, time, affordances, and much more that words alone cannot convey. Existing multimodal models exploring the potential of reasoning with images are brittle and do not scale. They rely on calling specialist tools, costly generation of images, or handcrafted reasoning data to switch between text and image thoughts. Instead, we offer a simpler alternative -- Mull-Tokens -- modality-agnostic latent tokens pre-trained to hold intermediate information in either image or text modalities to let the model think free-form towards the correct answer. We investigate best practices to train Mull-Tokens inspired by latent reasoning frameworks. We first train Mull-Tokens using supervision from interleaved text-image traces, and then fine-tune without any supervision by only using the final answers. Across four challenging spatial reasoning benchmarks involving tasks such as solving puzzles and taking different perspectives, we demonstrate that Mull-Tokens improve upon several baselines utilizing text-only reasoning or interleaved image-text reasoning, achieving a +3% average improvement and up to +16% on a puzzle solving reasoning-heavy split compared to our strongest baseline. Adding to conversations around challenges in grounding textual and visual reasoning, Mull-Tokens offers a simple solution to abstractly think in multiple modalities.

</details>


### [7] [AlcheMinT: Fine-grained Temporal Control for Multi-Reference Consistent Video Generation](https://arxiv.org/abs/2512.10943)
*Sharath Girish,Viacheslav Ivanov,Tsai-Shien Chen,Hao Chen,Aliaksandr Siarohin,Sergey Tulyakov*

Main category: cs.CV

TL;DR: AlcheMinT是一个统一框架，通过引入显式时间戳条件，实现主题驱动视频生成中的细粒度时间控制，能够精确控制多个主题在视频中的出现和消失时间。


<details>
  <summary>Details</summary>
Motivation: 现有主题驱动视频生成方法缺乏对主题出现和消失的细粒度时间控制，这对于组合视频合成、故事板和可控动画等应用至关重要。

Method: 提出AlcheMinT框架：1）引入新颖的位置编码机制，支持时间间隔编码（与主题身份关联）；2）结合主题描述性文本标记，增强视觉身份与视频描述的绑定；3）通过标记级连接避免额外交叉注意力模块，参数开销极小。

Result: 实验结果表明，AlcheMinT在视觉质量上与最先进的视频个性化方法相当，同时首次实现了视频内多主题生成的精确时间控制。建立了评估多主题身份保持、视频保真度和时间遵循性的基准。

Conclusion: AlcheMinT通过显式时间戳条件实现了主题驱动视频生成的精确时间控制，为组合视频合成、故事板制作和可控动画等应用提供了新的可能性。

Abstract: Recent advances in subject-driven video generation with large diffusion models have enabled personalized content synthesis conditioned on user-provided subjects. However, existing methods lack fine-grained temporal control over subject appearance and disappearance, which are essential for applications such as compositional video synthesis, storyboarding, and controllable animation. We propose AlcheMinT, a unified framework that introduces explicit timestamps conditioning for subject-driven video generation. Our approach introduces a novel positional encoding mechanism that unlocks the encoding of temporal intervals, associated in our case with subject identities, while seamlessly integrating with the pretrained video generation model positional embeddings. Additionally, we incorporate subject-descriptive text tokens to strengthen binding between visual identity and video captions, mitigating ambiguity during generation. Through token-wise concatenation, AlcheMinT avoids any additional cross-attention modules and incurs negligible parameter overhead. We establish a benchmark evaluating multiple subject identity preservation, video fidelity, and temporal adherence. Experimental results demonstrate that AlcheMinT achieves visual quality matching state-of-the-art video personalization methods, while, for the first time, enabling precise temporal control over multi-subject generation within videos. Project page is at https://snap-research.github.io/Video-AlcheMinT

</details>


### [8] [SceneMaker: Open-set 3D Scene Generation with Decoupled De-occlusion and Pose Estimation Model](https://arxiv.org/abs/2512.10957)
*Yukai Shi,Weiyu Li,Zihao Wang,Hongyang Li,Xingyu Chen,Ping Tan,Lei Zhang*

Main category: cs.CV

TL;DR: SceneMaker是一个解耦的3D场景生成框架，通过分离去遮挡模型和3D物体生成，并引入统一姿态估计模型，解决了严重遮挡和开放集场景下几何质量与姿态准确性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在严重遮挡和开放集场景下，由于缺乏足够的开放集去遮挡和姿态估计先验知识，难以同时生成高质量的几何结构和准确的姿态。

Method: 1. 将去遮挡模型与3D物体生成解耦，利用图像数据集和收集的去遮挡数据集增强对多样化开放集遮挡模式的处理能力；2. 提出统一姿态估计模型，集成全局和局部机制的自注意力和交叉注意力以提高准确性；3. 构建开放集3D场景数据集以扩展姿态估计模型的泛化能力。

Result: 综合实验表明，该解耦框架在室内和开放集场景上均表现出优越性。

Conclusion: SceneMaker通过解耦去遮挡和3D生成、增强姿态估计模型，有效解决了严重遮挡和开放集场景下的3D场景生成问题，代码和数据集已开源。

Abstract: We propose a decoupled 3D scene generation framework called SceneMaker in this work. Due to the lack of sufficient open-set de-occlusion and pose estimation priors, existing methods struggle to simultaneously produce high-quality geometry and accurate poses under severe occlusion and open-set settings. To address these issues, we first decouple the de-occlusion model from 3D object generation, and enhance it by leveraging image datasets and collected de-occlusion datasets for much more diverse open-set occlusion patterns. Then, we propose a unified pose estimation model that integrates global and local mechanisms for both self-attention and cross-attention to improve accuracy. Besides, we construct an open-set 3D scene dataset to further extend the generalization of the pose estimation model. Comprehensive experiments demonstrate the superiority of our decoupled framework on both indoor and open-set scenes. Our codes and datasets is released at https://idea-research.github.io/SceneMaker/.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [9] [Quantifying Emotional Tone in Tolkien's The Hobbit: Dialogue Sentiment Analysis with RegEx, NRC-VAD, and Python](https://arxiv.org/abs/2512.10865)
*Lilin Qiu*

Main category: cs.CL

TL;DR: 使用计算文本分析研究《霍比特人》对话的情感基调，发现整体保持积极、平静的语调，随着故事进展角色能动性逐渐增强，体现了小说在紧张与舒适之间的情感节奏平衡。


<details>
  <summary>Details</summary>
Motivation: 通过计算文本分析方法，揭示J.R.R.托尔金《霍比特人》中对话的情感结构，探索数字方法如何帮助发现文学作品中的微妙情感模式。

Method: 使用正则表达式提取对话文本，经过预处理后，采用NRC-VAD词典对情感维度进行量化评分，包括效价（积极/消极）、唤醒度（兴奋/平静）和支配度（能动性）。

Result: 对话整体保持积极（高效价）和冷静（低唤醒度）的基调，随着故事进展角色能动性（支配度）逐渐增强；情感轨迹显示托尔金的语言在紧张与舒适之间循环，危险和兴奋时刻与幽默、友情和缓解时刻保持平衡。

Conclusion: 计算工具与文学解读相结合，能够揭示《霍比特人》中塑造叙事的稳定节奏和情感调节，展示了数字方法在发现文学作品微妙情感结构方面的价值。

Abstract: This study analyzes the emotional tone of dialogue in J. R. R. Tolkien's The Hobbit (1937) using computational text analysis. Dialogue was extracted with regular expressions, then preprocessed, and scored using the NRC-VAD lexicon to quantify emotional dimensions. The results show that the dialogue maintains a generally positive (high valence) and calm (low arousal) tone, with a gradually increasing sense of agency (dominance) as the story progresses. These patterns reflect the novel's emotional rhythm: moments of danger and excitement are regularly balanced by humor, camaraderie, and relief. Visualizations -- including emotional trajectory graphs and word clouds -- highlight how Tolkien's language cycles between tension and comfort. By combining computational tools with literary interpretation, this study demonstrates how digital methods can uncover subtle emotional structures in literature, revealing the steady rhythm and emotional modulation that shape the storytelling in The Hobbit.

</details>


### [10] [Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity](https://arxiv.org/abs/2512.10882)
*Hauke Licht*

Main category: cs.CL

TL;DR: 该研究评估了多模态大语言模型在视频情绪分析中的表现，发现在理想条件下模型表现良好，但在真实议会辩论场景中效果不佳。


<details>
  <summary>Details</summary>
Motivation: 随着多模态生成式AI在政治情绪分析中的应用日益增多，但缺乏对其有效性的实证证据，需要评估这些模型在实际政治分析中的表现。

Method: 使用两个互补的人工标注视频数据集，评估当前多模态大语言模型在视频情绪唤醒度分析中的表现，包括理想条件和真实议会辩论场景。

Result: 在理想条件下，mLLMs的情绪唤醒度评分高度可靠且几乎没有人口统计学偏见；但在真实议会辩论录音中，模型的唤醒度评分表现不佳，可能对下游统计推断产生负面影响。

Conclusion: 研究强调需要持续、彻底评估新兴生成式AI方法在政治分析中的应用，并提供了一个可复制的评估框架。

Abstract: Emotions are central to politics and analyzing their role in political communication has a long tradition. As research increasingly leverages audio-visual materials to analyze the display of emotions, the emergence of multimodal generative AI promises great advances. However, we lack evidence about the effectiveness of multimodal AI in emotion analysis. This paper addresses this gap by evaluating current multimodal large language models (mLLMs) in video-based analysis of emotional arousal in two complementary data sets of human-labeled video recordings. I find that under ideal circumstances, mLLMs' emotional arousal ratings are highly reliable and show little to know indication of demographic bias. However, in recordings of speakers in real-world parliamentary debates, mLLMs' arousal ratings fail to deliver on this promise with potential negative consequences for downstream statistical inferences. This study therefore underscores the need for continued, thorough evaluation of emerging generative AI methods in political analysis and contributes a suitable replicable framework.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [11] [Digital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation](https://arxiv.org/abs/2512.10925)
*Zamirddine Mari,Mohamad Motasem Nawaf,Pierre Drap*

Main category: cs.LG

TL;DR: 本文提出基于PPO算法的深度强化学习方法，用于BlueROV2水下机器人的自主导航，在复杂环境中优于传统DWA方法，并验证了从仿真到实物的迁移能力。


<details>
  <summary>Details</summary>
Motivation: 水下环境自主导航面临GPS缺失、能见度差、存在水下障碍物等挑战，需要开发鲁棒的导航方法来解决这些问题。

Method: 采用基于PPO算法的深度强化学习方法，观测空间结合目标导向导航信息、虚拟占用网格和操作区域边界的射线投射，并与传统DWA方法进行对比。

Result: PPO策略在高度杂乱环境中持续优于DWA方法，具有更好的局部适应性和更少的碰撞，同时验证了从仿真到真实世界的可迁移性。

Conclusion: 深度强化学习在水下机器人自主导航中具有实际应用价值，PPO方法在复杂环境中表现优异，且仿真到实物的迁移验证了该方法的可行性。

Abstract: Autonomous navigation in underwater environments remains a major challenge due to the absence of GPS, degraded visibility, and the presence of submerged obstacles. This article investigates these issues through the case of the BlueROV2, an open platform widely used for scientific experimentation. We propose a deep reinforcement learning approach based on the Proximal Policy Optimization (PPO) algorithm, using an observation space that combines target-oriented navigation information, a virtual occupancy grid, and ray-casting along the boundaries of the operational area. The learned policy is compared against a reference deterministic kinematic planner, the Dynamic Window Approach (DWA), commonly employed as a robust baseline for obstacle avoidance. The evaluation is conducted in a realistic simulation environment and complemented by validation on a physical BlueROV2 supervised by a 3D digital twin of the test site, helping to reduce risks associated with real-world experimentation. The results show that the PPO policy consistently outperforms DWA in highly cluttered environments, notably thanks to better local adaptation and reduced collisions. Finally, the experiments demonstrate the transferability of the learned behavior from simulation to the real world, confirming the relevance of deep RL for autonomous navigation in underwater robotics.

</details>


### [12] [Decoupled Q-Chunking](https://arxiv.org/abs/2512.10926)
*Qiyang Li,Seohong Park,Sergey Levine*

Main category: cs.LG

TL;DR: 本文提出了一种新算法，通过解耦评论家（critic）和策略（policy）的块长度，让策略在较短的动作块上操作，同时保留多步价值传播的优势，解决了块化评论家方法中策略提取的挑战。


<details>
  <summary>Details</summary>
Motivation: 时间差分方法通过自举机制高效学习状态和动作价值，但容易产生自举偏差。块化评论家方法虽然加速了价值备份，但提取策略时面临挑战：策略必须开环输出整个动作块，这在需要策略反应性的环境中可能次优，且随着块长度增长建模困难。

Method: 提出解耦评论家和策略块长度的算法，通过针对部分动作块的蒸馏评论家优化策略。该蒸馏评论家通过乐观地从原始块化评论家回溯构建，近似估计部分动作块扩展为完整块时可实现的最大价值。

Result: 在具有挑战性的长视野离线目标条件任务上评估该方法，结果显示它可靠地优于先前的方法。

Conclusion: 该方法既保留了多步价值传播的优势，又避免了开环次优性和学习长动作块策略的困难，为块化评论家方法提供了更实用的策略提取方案。

Abstract: Temporal-difference (TD) methods learn state and action values efficiently by bootstrapping from their own future value predictions, but such a self-bootstrapping mechanism is prone to bootstrapping bias, where the errors in the value targets accumulate across steps and result in biased value estimates. Recent work has proposed to use chunked critics, which estimate the value of short action sequences ("chunks") rather than individual actions, speeding up value backup. However, extracting policies from chunked critics is challenging: policies must output the entire action chunk open-loop, which can be sub-optimal for environments that require policy reactivity and also challenging to model especially when the chunk length grows. Our key insight is to decouple the chunk length of the critic from that of the policy, allowing the policy to operate over shorter action chunks. We propose a novel algorithm that achieves this by optimizing the policy against a distilled critic for partial action chunks, constructed by optimistically backing up from the original chunked critic to approximate the maximum value achievable when a partial action chunk is extended to a complete one. This design retains the benefits of multi-step value propagation while sidestepping both the open-loop sub-optimality and the difficulty of learning action chunking policies for long action chunks. We evaluate our method on challenging, long-horizon offline goal-conditioned tasks and show that it reliably outperforms prior methods. Code: github.com/ColinQiyangLi/dqc.

</details>


### [13] [Asynchronous Reasoning: Training-Free Interactive Thinking LLMs](https://arxiv.org/abs/2512.10931)
*George Yakushev,Nataliia Babina,Masoud Vahid Dastgerdi,Vyacheslav Zhdanovskiy,Alina Shutova,Denis Kuznedelev*

Main category: cs.LG

TL;DR: 提出了一种无需额外训练的方法，让具备推理能力的LLM能够同时思考、听取和生成输出，显著减少实时交互延迟


<details>
  <summary>Details</summary>
Motivation: 现有LLM需要先完成思考才能回答问题，这种顺序交互方式不适合需要实时响应和适应的语音助手等应用场景。人类可以异步地听、想、说，因此需要让LLM也能实现类似的异步推理能力。

Method: 利用旋转嵌入（rotary embeddings）的特性，使原本设计用于顺序交互的LLM能够同时进行思考、听取和生成输出，无需额外训练。

Result: 在数学推理、常识推理和安全推理任务上评估，该方法能够实时生成准确的思考增强答案，将第一个非思考token的生成时间从几分钟减少到≤5秒，整体实时延迟降低了6-11倍。

Conclusion: 通过利用旋转嵌入的特性，成功实现了LLM的异步推理能力，使其能够在实时交互场景中同时思考、听取和生成响应，显著提升了交互效率和响应速度。

Abstract: Many state-of-the-art LLMs are trained to think before giving their answer. Reasoning can greatly improve language model capabilities and safety, but it also makes them less interactive: given a new input, a model must stop thinking before it can respond. Real-world use cases such as voice-based or embedded assistants require an LLM agent to respond and adapt to additional information in real time, which is incompatible with sequential interactions. In contrast, humans can listen, think, and act asynchronously: we begin thinking about the problem while reading it and continue thinking while formulating the answer. In this work, we augment LLMs capable of reasoning to operate in a similar way without additional training. Our method uses the properties of rotary embeddings to enable LLMs built for sequential interactions to simultaneously think, listen, and generate outputs. We evaluate our approach on math, commonsense, and safety reasoning and find that it can generate accurate thinking-augmented answers in real time, reducing time to first non-thinking token from minutes to <= 5s. and the overall real-time delays by 6-11x.

</details>


### [14] [Stronger Normalization-Free Transformers](https://arxiv.org/abs/2512.10938)
*Mingzhi Chen,Taiming Lu,Jiachen Zhu,Mingjie Sun,Zhuang Liu*

Main category: cs.LG

TL;DR: 本文提出了一种新的点函数Derf（erf函数变体），在多种任务中超越了LayerNorm、RMSNorm和DyT等归一化方法，成为无归一化Transformer架构的实用选择。


<details>
  <summary>Details</summary>
Motivation: 尽管归一化层长期以来被视为深度学习架构不可或缺的组成部分，但最近提出的Dynamic Tanh（DyT）表明存在替代方案。本研究旨在寻找能够超越DyT性能的函数设计。

Method: 首先研究点函数的内在特性如何影响训练和性能，然后基于这些发现进行大规模搜索，最终提出Derf函数：Derf(x) = erf(αx + s)，其中erf(x)是重新缩放的高斯累积分布函数。

Result: Derf在视觉（图像识别和生成）、语音表示和DNA序列建模等多个领域中，性能均优于LayerNorm、RMSNorm和DyT。性能提升主要源于改进的泛化能力而非更强的拟合能力。

Conclusion: Derf的简单性和更强的性能使其成为无归一化Transformer架构的实用选择，为深度学习架构设计提供了新的方向。

Abstract: Although normalization layers have long been viewed as indispensable components of deep learning architectures, the recent introduction of Dynamic Tanh (DyT) has demonstrated that alternatives are possible. The point-wise function DyT constrains extreme values for stable convergence and reaches normalization-level performance; this work seeks further for function designs that can surpass it. We first study how the intrinsic properties of point-wise functions influence training and performance. Building on these findings, we conduct a large-scale search for a more effective function design. Through this exploration, we introduce $\mathrm{Derf}(x) = \mathrm{erf}(αx + s)$, where $\mathrm{erf}(x)$ is the rescaled Gaussian cumulative distribution function, and identify it as the most performant design. Derf outperforms LayerNorm, RMSNorm, and DyT across a wide range of domains, including vision (image recognition and generation), speech representation, and DNA sequence modeling. Our findings suggest that the performance gains of Derf largely stem from its improved generalization rather than stronger fitting capacity. Its simplicity and stronger performance make Derf a practical choice for normalization-free Transformer architectures.

</details>


### [15] [UrbanAI 2025 Challenge: Linear vs Transformer Models for Long-Horizon Exogenous Temperature Forecasting](https://arxiv.org/abs/2512.10866)
*Ruslan Gokhman*

Main category: cs.LG

TL;DR: 线性模型在仅使用历史室内温度数据的长期预测任务中表现优于Transformer架构，DLinear模型在所有评估中表现最佳


<details>
  <summary>Details</summary>
Motivation: 研究在仅使用历史温度数据的外生变量预测场景下，比较线性模型和Transformer系列模型在长期温度预测任务中的性能表现

Method: 使用标准化的训练、验证和测试划分，评估了Linear、NLinear、DLinear、Transformer、Informer和Autoformer等模型在仅使用历史室内温度数据的单变量长期预测任务中的表现

Result: 线性基线模型（Linear、NLinear、DLinear）在性能上一致优于更复杂的Transformer系列架构，其中DLinear在所有划分中实现了最佳的整体准确性

Conclusion: 精心设计的线性模型在仅使用外生变量的挑战性时间序列预测场景中仍然是强大的基线方法，不应忽视简单模型的有效性

Abstract: We study long-horizon exogenous-only temperature forecasting - a challenging univariate setting where only the past values of the indoor temperature are used for prediction - using linear and Transformer-family models. We evaluate Linear, NLinear, DLinear, Transformer, Informer, and Autoformer under standardized train, validation, and test splits. Results show that linear baselines (Linear, NLinear, DLinear) consistently outperform more complex Transformer-family architectures, with DLinear achieving the best overall accuracy across all splits. These findings highlight that carefully designed linear models remain strong baselines for time series forecasting in challenging exogenous-only settings.

</details>


### [16] [Guided Transfer Learning for Discrete Diffusion Models](https://arxiv.org/abs/2512.10877)
*Julian Kleutgens,Claudio Battiloro,Lingkai Kong,Benjamin Grewe,Francesca Dominici,Mauricio Tec*

Main category: cs.LG

TL;DR: 提出GTL方法，无需微调预训练离散扩散模型即可实现跨域迁移学习，通过引导采样和高效采样器解决大词汇量长序列的计算问题


<details>
  <summary>Details</summary>
Motivation: 离散扩散模型在语言等离散领域表现优异，但需要大量训练数据，跨域适应成本高。现有迁移学习方法需要微调大型扩散模型，计算开销大且不实用

Method: 基于连续扩散的比率迁移学习，提出GTL方法，通过引导采样从目标分布生成样本而不修改预训练去噪器。同时提出高效采样器，专注于规划选择的位置和候选词，降低计算成本

Result: GTL在序列数据（包括合成马尔可夫链和语言建模）上进行了评估，实现了有效的迁移学习，使大规模语言建模在大词汇量和长序列场景下变得实用

Conclusion: GTL为离散扩散模型提供了一种无需微调的迁移学习方法，通过引导采样和高效采样机制解决了计算效率问题，使离散扩散模型在实际应用中更加可行

Abstract: Discrete diffusion models achieve strong performance across language and other discrete domains, providing a powerful alternative to autoregressive models. However, their strong performance relies on large training datasets, which are costly or risky to obtain, especially when adapting to new domains. Transfer learning is the natural way to adapt pretrained discrete diffusion models, but current methods require fine-tuning large diffusion models, which is computationally expensive and often impractical. Building on ratio-based transfer learning for continuous diffusion, we provide Guided Transfer Learning for discrete diffusion models (GTL). This enables sampling from a target distribution without modifying the pretrained denoiser. The same guidance formulation applies to both discrete-time diffusion and continuous-time score-based discrete diffusion, yielding a unified treatment. Guided discrete diffusion often requires many forward passes of the guidance network, which becomes impractical for large vocabularies and long sequences. To address this, we further present an efficient guided sampler that concentrates evaluations on planner-selected positions and top candidate tokens, thus lowering sampling time and computation. This makes guided language modeling practical at scale for large vocabularies and long sequences. We evaluate GTL on sequential data, including synthetic Markov chains and language modeling, and provide empirical analyses of its behavior.

</details>


### [17] [SparseSwaps: Tractable LLM Pruning Mask Refinement at Scale](https://arxiv.org/abs/2512.10922)
*Max Zimmer,Christophe Roux,Moritz Wagner,Deborah Hendrych,Sebastian Pokutta*

Main category: cs.LG

TL;DR: 本文提出了一种针对大语言模型的高效剪枝方法，通过行级等稀疏约束和1-swap优化，显著降低了剪枝误差，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统剪枝方法在大语言模型上存在局限性：完全重训练成本过高，全局幅度剪枝在Transformer架构上效果不佳，现有方法要么使用近似解要么依赖启发式算法，无法获得最优剪枝掩码。

Method: 提出了一种可扩展的1-swap算法：1) 通过强制每行具有相同稀疏度来解耦行间依赖；2) 利用校准数据的Gram矩阵高效计算最优1-swap（交换一个保留权重和一个剪枝权重）；3) 从任意剪枝掩码开始，在GPU上高效运行，无需超参数调优。

Result: 相比Wanda方法，将每层剪枝误差降低了高达60%；在多种GPT架构上一致提升了困惑度和零样本准确率；算法在大语言模型规模下具有实际可行性。

Conclusion: 通过行级等稀疏约束和高效1-swap优化，成功解决了大语言模型剪枝中的可扩展性问题，提供了一种简单、高效且无需超参数调优的剪枝方法，显著提升了剪枝后模型的性能。

Abstract: The resource requirements of Neural Networks can be significantly reduced through pruning -- the removal of seemingly less important parameters. However, with the rise of Large Language Models (LLMs), full retraining to recover pruning-induced performance degradation is often prohibitive and classical approaches such as global magnitude pruning are suboptimal on Transformer architectures. State-of-the-art methods hence solve a layer-wise mask selection problem, the problem of finding a pruning mask which minimizes the per-layer pruning error on a small set of calibration data. Exactly solving this problem to optimality using Integer Programming (IP) solvers is computationally infeasible due to its combinatorial nature and the size of the search space, and existing approaches therefore rely on approximations or heuristics. In this work, we demonstrate that the mask selection problem can be made drastically more tractable at LLM scale. To that end, we decouple the rows by enforcing equal sparsity levels per row. This allows us to derive optimal 1-swaps (exchanging one kept and one pruned weight) that can be computed efficiently using the Gram matrix of the calibration data. Using these observations, we propose a tractable and simple 1-swap algorithm that warm starts from any pruning mask, runs efficiently on GPUs at LLM scale, and is essentially hyperparameter-free. We demonstrate that our approach reduces per-layer pruning error by up to 60% over Wanda (Sun et al., 2023) and consistently improves perplexity and zero-shot accuracy across state-of-the-art GPT architectures.

</details>


### [18] [Hierarchical Dataset Selection for High-Quality Data Sharing](https://arxiv.org/abs/2512.10952)
*Xiaona Zhou,Yingyan Zeng,Ran Jin,Ismini Lourentzou*

Main category: cs.LG

TL;DR: DaSH方法通过层次化建模数据集和组级效用，在资源约束下优化数据集选择，显著提升下游任务性能


<details>
  <summary>Details</summary>
Motivation: 现实世界中数据通常以离散数据集形式存在，这些数据集在相关性、质量和效用上存在差异。现有方法主要选择单个样本，忽略了数据集及其来源之间的差异，无法有效处理大规模异构数据集选择问题。

Method: 提出DaSH（Dataset Selection via Hierarchies）方法，在数据集和组（如集合、机构）两个层次上建模效用，通过层次化建模实现从有限观察中高效泛化，支持在资源约束下进行可扩展的自适应数据集选择。

Result: 在两个公开基准测试（Digit-Five和DomainNet）上，DaSH比最先进的数据选择基线方法在准确率上提升高达26.2%，同时需要显著更少的探索步骤。消融实验表明DaSH对低资源设置和缺乏相关数据集的情况具有鲁棒性。

Conclusion: DaSH方法通过层次化建模数据集和组级效用，为实际多源学习工作流提供了可扩展和自适应的数据集选择解决方案，在资源有限的情况下能够有效提升下游任务性能。

Abstract: The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.

</details>


### [19] [Bidirectional Normalizing Flow: From Data to Noise and Back](https://arxiv.org/abs/2512.10953)
*Yiyang Lu,Qiao Sun,Xianbang Wang,Zhicheng Jiang,Hanhong Zhao,Kaiming He*

Main category: cs.LG

TL;DR: BiFlow框架通过移除精确解析逆变换的需求，使用近似逆映射模型，在提升生成质量的同时将采样速度提高了两个数量级


<details>
  <summary>Details</summary>
Motivation: 传统归一化流需要精确的解析逆变换，这限制了模型架构和损失函数的灵活性。最近TARFlow等方法的因果解码成为主要瓶颈，需要更高效的解决方案

Method: 提出双向归一化流(BiFlow)框架，学习一个近似噪声到数据的逆映射模型，而不是依赖精确的解析逆变换，从而支持更灵活的架构和损失函数

Result: 在ImageNet上的实验显示，BiFlow相比因果解码方法提升了生成质量，同时将采样速度提高了两个数量级，在NF方法中达到SOTA，在单次评估方法中具有竞争力

Conclusion: BiFlow通过移除精确逆变换的需求，为归一化流提供了更灵活高效的框架，有望进一步推动这一经典范式的发展

Abstract: Normalizing Flows (NFs) have been established as a principled framework for generative modeling. Standard NFs consist of a forward process and a reverse process: the forward process maps data to noise, while the reverse process generates samples by inverting it. Typical NF forward transformations are constrained by explicit invertibility, ensuring that the reverse process can serve as their exact analytic inverse. Recent developments in TARFlow and its variants have revitalized NF methods by combining Transformers and autoregressive flows, but have also exposed causal decoding as a major bottleneck. In this work, we introduce Bidirectional Normalizing Flow ($\textbf{BiFlow}$), a framework that removes the need for an exact analytic inverse. BiFlow learns a reverse model that approximates the underlying noise-to-data inverse mapping, enabling more flexible loss functions and architectures. Experiments on ImageNet demonstrate that BiFlow, compared to its causal decoding counterpart, improves generation quality while accelerating sampling by up to two orders of magnitude. BiFlow yields state-of-the-art results among NF-based methods and competitive performance among single-evaluation ("1-NFE") methods. Following recent encouraging progress on NFs, we hope our work will draw further attention to this classical paradigm.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [20] [LLMs Can Assist with Proposal Selection at Large User Facilities](https://arxiv.org/abs/2512.10895)
*Lijie Ding,Janell Thomson,Jon Taylor,Changwoo Do*

Main category: cs.AI

TL;DR: LLMs可用于大型用户设施的提案选择，相比传统人工评审更具可扩展性、一致性和成本效益，能有效识别高发表潜力的提案。


<details>
  <summary>Details</summary>
Motivation: 传统人工提案评审存在提案间相关性弱、评审者偏见和不一致等问题，而基于成对偏好的方法虽然逻辑上更优，但工作量呈二次方增长，人工难以实施。

Method: 利用LLMs进行提案排序，基于美国橡树岭国家实验室散裂中子源三个光束线的精心策划的提案和发表记录，采用成对偏好方法进行排名。

Result: LLM排名与人工排名有强相关性（Spearman ρ约0.2-0.8，去除10%异常值后≥0.5），在识别高发表潜力提案方面不逊于人工评审，成本降低两个数量级以上。

Conclusion: LLMs为提案选择提供了可扩展、一致且经济高效的替代方案，还能进行提案相似性量化评估等高级分析，为评审委员会提供关键信息。

Abstract: We explore how large language models (LLMs) can enhance the proposal selection process at large user facilities, offering a scalable, consistent, and cost-effective alternative to traditional human review. Proposal selection depends on assessing the relative strength among submitted proposals; however, traditional human scoring often suffers from weak inter-proposal correlations and is subject to reviewer bias and inconsistency. A pairwise preference-based approach is logically superior, providing a more rigorous and internally consistent basis for ranking, but its quadratic workload makes it impractical for human reviewers. We address this limitation using LLMs. Leveraging the uniquely well-curated proposals and publication records from three beamlines at the Spallation Neutron Source (SNS), Oak Ridge National Laboratory (ORNL), we show that the LLM rankings correlate strongly with the human rankings (Spearman $ρ\simeq 0.2-0.8$, improving to $\geq 0.5$ after 10\% outlier removal). Moreover, LLM performance is no worse than that of human reviewers in identifying proposals with high publication potential, while costing over two orders of magnitude less. Beyond ranking, LLMs enable advanced analyses that are challenging for humans, such as quantitative assessment of proposal similarity via embedding models, which provides information crucial for review committees.

</details>


### [21] [Multi-Granular Node Pruning for Circuit Discovery](https://arxiv.org/abs/2512.10903)
*Muhammad Umair Haider,Hammad Rizwan,Hassan Sajjad,A. B. Siddique*

Main category: cs.AI

TL;DR: 提出了一种用于电路发现的节点级剪枝框架，解决了现有方法在可扩展性和粒度方面的限制，通过可学习掩码和多粒度稀疏惩罚实现单次微调中的全面压缩。


<details>
  <summary>Details</summary>
Motivation: 现有电路发现方法主要依赖迭代边缘剪枝，计算成本高且仅限于注意力头或MLP块等粗粒度单元，忽略了神经元等更细粒度的结构，存在可扩展性和粒度限制问题。

Method: 提出节点级剪枝框架，引入跨多个粒度级别（从整个块到单个神经元）的可学习掩码，在统一优化目标中使用粒度特定的稀疏惩罚来指导剪枝过程，实现单次微调中的全面压缩。

Result: 该方法发现的电路节点数少于先前方法，证明许多被粗粒度方法认为重要的神经元实际上无关紧要，同时保持任务性能；内存占用显著降低5-10倍，无需在内存中保存中间激活。

Conclusion: 提出的节点级剪枝框架在电路发现中解决了可扩展性和粒度限制，能够识别更小、更精确的电路，同时大幅降低内存需求，为LLM可解释性研究提供了更高效的工具。

Abstract: Circuit discovery aims to identify minimal subnetworks that are responsible for specific behaviors in large language models (LLMs). Existing approaches primarily rely on iterative edge pruning, which is computationally expensive and limited to coarse-grained units such as attention heads or MLP blocks, overlooking finer structures like individual neurons. We propose a node-level pruning framework for circuit discovery that addresses both scalability and granularity limitations. Our method introduces learnable masks across multiple levels of granularity, from entire blocks to individual neurons, within a unified optimization objective. Granularity-specific sparsity penalties guide the pruning process, allowing a comprehensive compression in a single fine-tuning run. Empirically, our approach identifies circuits that are smaller in nodes than those discovered by prior methods; moreover, we demonstrate that many neurons deemed important by coarse methods are actually irrelevant, while still maintaining task performance. Furthermore, our method has a significantly lower memory footprint, 5-10x, as it does not require keeping intermediate activations in the memory to work.

</details>


### [22] [On Decision-Making Agents and Higher-Order Causal Processes](https://arxiv.org/abs/2512.10937)
*Matt Wilson*

Main category: cs.AI

TL;DR: 该论文建立了部分可观测马尔可夫决策过程（POMDP）中的决策智能体与单输入过程函数（高阶量子操作的经典极限）之间的精确对应关系。


<details>
  <summary>Details</summary>
Motivation: 探索人工智能中的决策理论与物理学中量子操作理论之间的深层联系，为理解智能体决策过程提供新的数学框架。

Method: 通过将智能体的策略和记忆更新结合成过程函数w，使用链接积与POMDP环境交互，建立智能体与过程函数之间的对应关系。

Result: 建立了POMDP智能体与单输入过程函数之间的精确对应，并发现这种对应具有双重解释：从物理视角看，过程函数作为环境；从AI视角看，它编码智能体。还将此视角扩展到多智能体系统。

Conclusion: 该研究揭示了人工智能决策理论与量子操作理论之间的深刻联系，为理解智能体决策提供了新的数学框架，并可将此视角扩展到多智能体系统，特别是观察独立的分散式POMDP。

Abstract: We establish a precise correspondence between decision-making agents in partially observable Markov decision processes (POMDPs) and one-input process functions, the classical limit of higher-order quantum operations. In this identification an agent's policy and memory update combine into a process function w that interacts with a POMDP environment via the link product. This suggests a dual interpretation: in the physics view, the process function acts as the environment into which local operations (agent interventions) are inserted, whereas in the AI view it encodes the agent and the inserted functions represent environments. We extend this perspective to multi-agent systems by identifying observation-independent decentralized POMDPs as natural domains for multi-input process functions.

</details>
