<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 71]
- [cs.CL](#cs.CL) [Total: 31]
- [cs.RO](#cs.RO) [Total: 30]
- [cs.AI](#cs.AI) [Total: 20]
- [cs.LG](#cs.LG) [Total: 47]
- [eess.SY](#eess.SY) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [DesignSense: A Human Preference Dataset and Reward Modeling Framework for Graphic Layout Generation](https://arxiv.org/abs/2602.23438)
*Varun Gopal,Rishabh Jain,Aradhya Mathur,Nikitha SR,Sohan Patnaik,Sudhir Yarram,Mayur Hemani,Balaji Krishnamurthy,Mausoom Sarkar*

Main category: cs.CV

TL;DR: 该研究提出了DesignSense-10k数据集和DesignSense模型，专门用于图形布局的审美偏好评估，显著提升了布局生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有布局生成模型虽然功能强大，但常常无法与人类细微的审美判断保持一致。现有的偏好数据集和奖励模型主要针对文本到图像生成，无法推广到布局评估领域，因为布局质量取决于相同元素的空间排列。

Method: 提出了一个五阶段策划流程：语义分组、布局预测、过滤、聚类和基于VLM的细化，生成高质量的比较对。使用4类标注方案（左好、右好、都好、都差）捕捉主观模糊性。基于此数据集训练了DesignSense，一个基于视觉语言模型的分类器。

Result: DesignSense在综合评估指标上显著优于现有开源和专有模型（在最强专有基线上Macro F1提升54.6%）。前沿VLM在四类任务上整体不可靠且表现灾难性。使用DesignSense进行RL训练时生成器胜率提升约3%，推理时缩放（生成多个候选并选择最佳）提供3.6%的改进。

Conclusion: 专业化的、布局感知的偏好建模对实际布局生成质量具有重要影响，DesignSense-10k数据集和DesignSense模型填补了图形布局评估的关键空白。

Abstract: Graphic layouts serve as an important and engaging medium for visual communication across different channels. While recent layout generation models have demonstrated impressive capabilities, they frequently fail to align with nuanced human aesthetic judgment. Existing preference datasets and reward models trained on text-to-image generation do not generalize to layout evaluation, where the spatial arrangement of identical elements determines quality. To address this critical gap, we introduce DesignSense-10k, a large-scale dataset of 10,235 human-annotated preference pairs for graphic layout evaluation. We propose a five-stage curation pipeline that generates visually coherent layout transformations across diverse aspect ratios, using semantic grouping, layout prediction, filtering, clustering, and VLM-based refinement to produce high-quality comparison pairs. Human preferences are annotated using a 4-class scheme (left, right, both good, both bad) to capture subjective ambiguity. Leveraging this dataset, we train DesignSense, a vision-language model-based classifier that substantially outperforms existing open-source and proprietary models across comprehensive evaluation metrics (54.6% improvement in Macro F1 over the strongest proprietary baseline). Our analysis shows that frontier VLMs remain unreliable overall and fail catastrophically on the full four-class task, underscoring the need for specialized, preference-aware models. Beyond the dataset, our reward model DesignSense yields tangible downstream gains in layout generation. Using our judge during RL based training improves generator win rate by about 3%, while inference-time scaling, which involves generating multiple candidates and selecting the best one, provides a 3.6% improvement. These results highlight the practical impact of specialized, layout-aware preference modeling on real-world layout generation quality.

</details>


### [2] [Modelling and Simulation of Neuromorphic Datasets for Anomaly Detection in Computer Vision](https://arxiv.org/abs/2602.23514)
*Mike Middleton,Teymoor Ali,Hakan Kayan,Basabdatta Sen Bhattacharya,Charith Perera,Oliver Rhodes,Elena Gheorghiu,Mark Vousden,Martin A. Trefzer*

Main category: cs.CV

TL;DR: ANTShapes是一个基于Unity引擎的神经形态视觉数据集模拟框架，用于生成可配置的3D场景和异常行为对象，解决DVS传感器数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 动态视觉传感器（DVS）的可用性有限，现有数据集样本数量少、场景单一，缺乏全面的神经形态视觉数据集模拟工具。

Method: 基于Unity引擎构建抽象可配置的3D场景，对象具有随机生成的运动和旋转等行为属性，通过中心极限定理原理进行行为采样和异常对象标记。

Result: ANTShapes能够通过调整少量参数创建任意数量的数据集样本，并导出相应的标签和帧数据，支持对象识别、定位和异常检测等多种应用。

Conclusion: ANTShapes解决了事件型计算机视觉研究中的数据可用性问题，允许研究人员模拟定制化数据集以满足特定研究需求。

Abstract: Limitations on the availability of Dynamic Vision Sensors (DVS) present a fundamental challenge to researchers of neuromorphic computer vision applications. In response, datasets have been created by the research community, but often contain a limited number of samples or scenarios. To address the lack of a comprehensive simulator of neuromorphic vision datasets, we introduce the Anomalous Neuromorphic Tool for Shapes (ANTShapes), a novel dataset simulation framework. Built in the Unity engine, ANTShapes simulates abstract, configurable 3D scenes populated by objects displaying randomly-generated behaviours describing attributes such as motion and rotation. The sampling of object behaviours, and the labelling of anomalously-acting objects, is a statistical process following central limit theorem principles. Datasets containing an arbitrary number of samples can be created and exported from ANTShapes, along with accompanying label and frame data, through the adjustment of a limited number of parameters within the software. ANTShapes addresses the limitations of data availability to researchers of event-based computer vision by allowing for the simulation of bespoke datasets to suit purposes including object recognition and localisation alongside anomaly detection.

</details>


### [3] [All in One: Unifying Deepfake Detection, Tampering Localization, and Source Tracing with a Robust Landmark-Identity Watermark](https://arxiv.org/abs/2602.23523)
*Junjiang Wu,Liejun Wang,Zhiqing Guo*

Main category: cs.CV

TL;DR: 提出LIDMark框架，通过152维地标-身份水印统一解决深度伪造检测、篡改定位和来源追踪三个任务，使用因子化头部解码器实现鲁棒提取。


<details>
  <summary>Details</summary>
Motivation: 现有主动取证方法通常将深度伪造检测、篡改定位和来源追踪视为独立任务，缺乏统一的联合处理框架。随着深度伪造技术的快速发展，恶意人脸操纵对个人隐私和社会安全构成重大威胁。

Method: 提出LIDMark框架，采用创新的152维地标-身份水印，将面部地标与唯一来源标识符结构交织。设计因子化头部解码器，将共享骨干特征分解为回归和分类两个专门头部，分别鲁棒重建嵌入的地标和标识符。

Result: 实验表明LIDMark框架为深度伪造内容的检测、定位和追踪提供了统一、鲁棒且不可察觉的解决方案。回归头部支持"内在-外在"一致性检查用于检测和定位，分类头部鲁棒解码来源标识符用于追踪。

Conclusion: LIDMark框架通过统一的水印方法成功解决了深度伪造检测、篡改定位和来源追踪三个核心取证任务，实现了"一体化"的三功能取证解决方案。

Abstract: With the rapid advancement of deepfake technology, malicious face manipulations pose a significant threat to personal privacy and social security. However, existing proactive forensics methods typically treat deepfake detection, tampering localization, and source tracing as independent tasks, lacking a unified framework to address them jointly. To bridge this gap, we propose a unified proactive forensics framework that jointly addresses these three core tasks. Our core framework adopts an innovative 152-dimensional landmark-identity watermark termed LIDMark, which structurally interweaves facial landmarks with a unique source identifier. To robustly extract the LIDMark, we design a novel Factorized-Head Decoder (FHD). Its architecture factorizes the shared backbone features into two specialized heads (i.e., regression and classification), robustly reconstructing the embedded landmarks and identifier, respectively, even when subjected to severe distortion or tampering. This design realizes an "all-in-one" trifunctional forensic solution: the regression head underlies an "intrinsic-extrinsic" consistency check for detection and localization, while the classification head robustly decodes the source identifier for tracing. Extensive experiments show that the proposed LIDMark framework provides a unified, robust, and imperceptible solution for the detection, localization, and tracing of deepfake content. The code is available at https://github.com/vpsg-research/LIDMark.

</details>


### [4] [Synthetic Visual Genome 2: Extracting Large-scale Spatio-Temporal Scene Graphs from Videos](https://arxiv.org/abs/2602.23543)
*Ziqi Gao,Jieyu Zhang,Wisdom Oluchi Ikezogwo,Jae Sung Park,Tario G. You,Daniel Ogbu,Chenhao Zheng,Weikai Huang,Yinuo Yang,Winson Han,Quan Kong,Rajat Saini,Ranjay Krishna*

Main category: cs.CV

TL;DR: SVG2是一个大规模全景视频场景图数据集，包含63.6万个视频、660万个对象、5200万个属性和670万个关系，规模比现有数据集大一个数量级。基于此数据集训练的TRaSER模型在视频场景图生成任务上显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有时空场景图数据集规模有限，缺乏多样性和大规模标注，限制了视频场景图生成模型的发展。需要构建更大规模、更多样化的数据集来推动该领域研究。

Method: 1) 创建SVG2数据集：采用全自动流水线，结合多尺度全景分割、在线-离线轨迹跟踪（含自动新对象发现）、每轨迹语义解析和GPT-5时空关系推理。2) 训练TRaSER模型：通过轨迹对齐的token排列机制，新增对象轨迹重采样器和时间窗口重采样器，将原始视频和全景轨迹转换为紧凑的时空场景图。

Result: TRaSER在PVSG、VIPSeg、VidOR和SVG2测试集上：关系检测提升15-20%，对象预测比最强开源基线提升30-40%（比GPT-5提升13%），属性预测提升15%。将TRaSER生成的场景图用于视频问答时，相比仅使用视频或视频加Qwen2.5-VL生成的场景图，准确率绝对提升1.5-4.6%。

Conclusion: SVG2数据集显著扩展了时空场景图数据的规模和多样性，TRaSER模型通过创新的轨迹对齐架构在视频场景图生成任务上取得显著性能提升，证明了显式时空场景图作为中间表示的有效性。

Abstract: We introduce Synthetic Visual Genome 2 (SVG2), a large-scale panoptic video scene graph dataset. SVG2 contains over 636K videos with 6.6M objects, 52.0M attributes, and 6.7M relations, providing an order-of-magnitude increase in scale and diversity over prior spatio-temporal scene graph datasets. To create SVG2, we design a fully automated pipeline that combines multi-scale panoptic segmentation, online-offline trajectory tracking with automatic new-object discovery, per-trajectory semantic parsing, and GPT-5-based spatio-temporal relation inference. Building on this resource, we train TRaSER, a video scene graph generation model. TRaSER augments VLMs with a trajectory-aligned token arrangement mechanism and new modules: an object-trajectory resampler and a temporal-window resampler to convert raw videos and panoptic trajectories into compact spatio-temporal scene graphs in a single forward pass. The temporal-window resampler binds visual tokens to short trajectory segments to preserve local motion and temporal semantics, while the object-trajectory resampler aggregates entire trajectories to maintain global context for objects. On the PVSG, VIPSeg, VidOR and SVG2 test datasets, TRaSER improves relation detection by +15 to 20%, object prediction by +30 to 40% over the strongest open-source baselines and by +13% over GPT-5, and attribute prediction by +15%. When TRaSER's generated scene graphs are sent to a VLM for video question answering, it delivers a +1.5 to 4.6% absolute accuracy gain over using video only or video augmented with Qwen2.5-VL's generated scene graphs, demonstrating the utility of explicit spatio-temporal scene graphs as an intermediate representation.

</details>


### [5] [LE-NeuS: Latency-Efficient Neuro-Symbolic Video Understanding via Adaptive Temporal Verification](https://arxiv.org/abs/2602.23553)
*Shawn Liang,Sahil Shah,Chengwei Zhou,SP Sharan,Harsh Goel,Arnab Sanyal,Sandeep Chinchali,Gourav Datta*

Main category: cs.CV

TL;DR: LE-NeuS是一个延迟高效的神经符号框架，通过自适应采样和批量命题检测优化，将LVQA的推理延迟从90倍降低到约10倍，同时保持时间复杂查询的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 现有神经符号方法在长视频问答中虽然准确率显著提升，但推理延迟过高（比基础VLM提示慢90倍），无法满足延迟敏感的边缘部署需求。

Method: 采用两种优化：1) CLIP引导的两阶段自适应采样，利用视觉冗余跳过语义相似帧同时保留时间边界；2) 批量命题检测，在时间窗口上并行化VLM推理。

Result: 在LongVideoBench和Video-MME基准测试中，LE-NeuS将延迟差距从90倍降低到约10倍，同时在时间复杂查询上保持超过10%的准确率提升。

Conclusion: LE-NeuS在保持神经符号方法准确率优势的同时，大幅降低了推理延迟，为延迟敏感的边缘部署提供了实用解决方案。

Abstract: Neuro-symbolic approaches to long-form video question answering (LVQA) have demonstrated significant accuracy improvements by grounding temporal reasoning in formal verification. However, existing methods incur prohibitive latency overheads, up to 90x slower than base VLM prompting, rendering them impractical for latency-sensitive edge deployments. We present LE-NeuS, a latency-efficient neuro-symbolic framework that preserves the accuracy benefits of temporal logic-guided video understanding while drastically reducing inference latency. Our key insight is that the dominant computational bottleneck arises from sequential and dense proposition detection across video frames during automaton construction. We address this through two principled optimizations: (1) CLIP guided two-stage adaptive sampling that exploits visual redundancy to skip semantically similar frames while preserving temporal boundaries, and (2) batched proposition detection that parallelizes VLM inference across temporal windows. Theoretically, we derive latency bounds as a function of video length, proposition complexity, and sampling density, establishing conditions under which latency efficiency is achievable. Empirically, on LongVideoBench and Video-MME benchmarks deployed on NVIDIA H100 GPUs, LE-NeuS reduces the latency gap from 90x to approximately 10x while maintaining >10% accuracy gains on temporally complex queries.

</details>


### [6] [No Calibration, No Depth, No Problem: Cross-Sensor View Synthesis with 3D Consistency](https://arxiv.org/abs/2602.23559)
*Cho-Ying Wu,Zixun Huang,Xinyu Huang,Liu Ren*

Main category: cs.CV

TL;DR: 提出首个跨传感器模态的视图合成研究，解决RGB-X数据对齐的校准难题，通过匹配-稠密化-整合方法实现无需3D先验的跨传感器学习


<details>
  <summary>Details</summary>
Motivation: 现有RGB-X研究大多假设对齐的RGB-X数据对存在，专注于模态融合，但实际校准需要大量工程努力。本文旨在消除各种RGB-X传感器的繁琐校准，通过可扩展解决方案突破大规模真实世界RGB-X数据收集的瓶颈

Method: 提出匹配-稠密化-整合方法：1) RGB-X图像匹配；2) 引导点稠密化（使用置信度感知稠密化和自匹配过滤）；3) 在3D高斯泼溅中整合视图合成结果。该方法对X传感器不使用3D先验，仅假设RGB使用近乎零成本的COLMAP

Result: 实现了更好的视图合成效果，能够处理各种RGB-X传感器组合，为跨传感器学习提供了可扩展的解决方案

Conclusion: 该方法消除了RGB-X传感器的繁琐校准需求，通过突破大规模真实世界RGB-X数据收集的瓶颈，推动了跨传感器学习的普及

Abstract: We present the first study of cross-sensor view synthesis across different modalities. We examine a practical, fundamental, yet widely overlooked problem: getting aligned RGB-X data, where most RGB-X prior work assumes such pairs exist and focuses on modality fusion, but it empirically requires huge engineering effort in calibration. We propose a match-densify-consolidate method. First, we perform RGB-X image matching followed by guided point densification. Using the proposed confidence-aware densification and self-matching filtering, we attain better view synthesis and later consolidate them in 3D Gaussian Splatting (3DGS). Our method uses no 3D priors for X-sensor and only assumes nearly no-cost COLMAP for RGB. We aim to remove the cumbersome calibration for various RGB-X sensors and advance the popularity of cross-sensor learning by a scalable solution that breaks through the bottleneck in large-scale real-world RGB-X data collection.

</details>


### [7] [Evidential Neural Radiance Fields](https://arxiv.org/abs/2602.23574)
*Ruxiao Duan,Alex Wong*

Main category: cs.CV

TL;DR: 提出Evidential Neural Radiance Fields，一种概率方法，可在单次前向传播中同时量化偶然性和认知性不确定性，在保持渲染质量的同时实现高效不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 神经辐射场（NeRF）在场景重建和新视角合成方面取得了显著进展，但缺乏不确定性估计限制了其在安全关键场景中的应用。现有不确定性量化方法要么无法同时捕捉偶然性和认知性不确定性，要么会损害渲染质量或带来显著计算开销。

Method: 提出Evidential Neural Radiance Fields，一种概率方法，无缝集成到NeRF渲染过程中，通过单次前向传播直接量化偶然性和认知性不确定性。

Result: 在三个标准化基准测试中，该方法展示了最先进的场景重建保真度和不确定性估计质量，优于其他不确定性量化方法。

Conclusion: Evidential Neural Radiance Fields提供了一种高效且准确的不确定性量化方法，能够同时估计偶然性和认知性不确定性，为安全关键应用中的可信三维场景建模提供了重要工具。

Abstract: Understanding sources of uncertainty is fundamental to trustworthy three-dimensional scene modeling. While recent advances in neural radiance fields (NeRFs) achieve impressive accuracy in scene reconstruction and novel view synthesis, the lack of uncertainty estimation significantly limits their deployment in safety-critical settings. Existing uncertainty quantification methods for NeRFs fail to capture both aleatoric and epistemic uncertainty. Among those that do quantify one or the other, many of them either compromise rendering quality or incur significant computational overhead to obtain uncertainty estimates. To address these issues, we introduce Evidential Neural Radiance Fields, a probabilistic approach that seamlessly integrates with the NeRF rendering process and enables direct quantification of both aleatoric and epistemic uncertainty from a single forward pass. We compare multiple uncertainty quantification methods on three standardized benchmarks, where our approach demonstrates state-of-the-art scene reconstruction fidelity and uncertainty estimation quality.

</details>


### [8] [Hyperdimensional Cross-Modal Alignment of Frozen Language and Image Models for Efficient Image Captioning](https://arxiv.org/abs/2602.23588)
*Abhishek Dalvi,Vasant Honavar*

Main category: cs.CV

TL;DR: HDFLIM提出了一种无需微调预训练模型的跨模态对齐方法，通过超维计算在冻结的视觉和语言模型之间建立映射关系


<details>
  <summary>Details</summary>
Motivation: 传统跨模态对齐需要计算密集的多模态微调，这会更新大量参数、消耗资源并可能破坏预训练表示。研究发现独立训练的基模型可能已存在潜在的语义兼容性，因此探索能否在不修改模型本身的情况下实现跨模态对齐

Method: HDFLIM将单模态嵌入投影到共享的超维空间，利用轻量级符号操作（绑定、捆绑和基于相似性的检索）在单次数据遍历中构建关联的跨模态表示。标题生成通过高维记忆检索而非迭代的基于梯度的优化实现

Result: HDFLIM实现了与端到端视觉语言训练方法相当的性能，生成的标题比零样本基线更具语义基础

Conclusion: 通过将对齐与参数调优解耦，研究表明跨基模型的语义映射可以通过对各自嵌入的超维编码进行符号操作来实现。这项工作指向了一种替代范式：通过结构化表示映射而非大规模重新训练来集成冻结模型

Abstract: Large unimodal foundation models for vision and language encode rich semantic structures, yet aligning them typically requires computationally intensive multimodal fine-tuning. Such approaches depend on large-scale parameter updates, are resource intensive, and can perturb pretrained representations. Emerging evidence suggests, however, that independently trained foundation models may already exhibit latent semantic compatibility, reflecting shared structures in the data they model. This raises a fundamental question: can cross-modal alignment be achieved without modifying the models themselves? Here we introduce HDFLIM (HyperDimensional computing with Frozen Language and Image Models), a framework that establishes cross-modal mappings while keeping pretrained vision and language models fully frozen. HDFLIM projects unimodal embeddings into a shared hyperdimensional space and leverages lightweight symbolic operations -- binding, bundling, and similarity-based retrieval to construct associative cross-modal representations in a single pass over the data. Caption generation emerges from high-dimensional memory retrieval rather than iterative gradient-based optimization. We show that HDFLIM achieves performance comparable to end-to-end vision-language training methods and produces captions that are more semantically grounded than zero-shot baselines. By decoupling alignment from parameter tuning, our results suggest that semantic mapping across foundation models can be realized through symbolic operations on hyperdimensional encodings of the respective embeddings. More broadly, this work points toward an alternative paradigm for foundation model alignment in which frozen models are integrated through structured representational mappings rather than through large-scale retraining. The codebase for our implementation can be found at https://github.com/Abhishek-Dalvi410/HDFLIM.

</details>


### [9] [Pseudo Contrastive Learning for Diagram Comprehension in Multimodal Models](https://arxiv.org/abs/2602.23589)
*Hiroshi Sasaki*

Main category: cs.CV

TL;DR: 提出一种新的训练范式，通过生成伪对比样本来增强视觉语言模型对图表的理解能力，在流程图数据集上显著优于标准CLIP和hard-negative CLIP训练


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型（如CLIP）在视觉和语言表示对齐方面表现优异，但在需要精细结构差异感知的领域（如图表理解）仍面临挑战，因为模型对细粒度结构变化的敏感性有限

Method: 提出新的训练范式，使用图表渲染器生成伪对比样本，这些样本通过随机选取文本元素创建合成图表，突出图表图像中的结构差异，无需修改原始数据，将这些伪对比样本纳入训练目标

Result: 在流程图基准数据集上的实证评估显示，在图像-文本匹配和视觉问答任务中，相比标准CLIP和hard-negative CLIP训练都有显著改进

Conclusion: 该研究强调了领域特定训练策略的价值，有助于在更广泛的视觉语言学习背景下推进图表理解能力的发展

Abstract: Recent multimodal models such as Contrastive Language-Image Pre-training (CLIP) have shown remarkable ability to align visual and linguistic representations. However, domains where small visual differences carry large semantic significance, such as diagram understanding, remain challenging due to the models' limited sensitivity to fine-grained structural variations.
  We propose a new training paradigm designed to enhance diagram comprehension in vision-language models. Our approach introduces pseudo contrastive samples generated by a diagram renderer that creates synthetic diagrams using randomly picked text elements. These samples highlight structural differences in diagrammatic imagery without requiring any modification or editing of the original data. By incorporating these pseudo contrastive samples into the training objective, the model learns to capture more precise and semantically consistent diagram structures.
  Empirical evaluations on a benchmark dataset of flowcharts demonstrate substantial improvements over standard CLIP and hard-negative CLIP training in both image-text matching and visual question answering tasks. The results underscore the value of domain-specific training strategies and contribute to advancing diagrammatic understanding within the broader context of vision-language learning.

</details>


### [10] [Annotation-Free Visual Reasoning for High-Resolution Large Multimodal Models via Reinforcement Learning](https://arxiv.org/abs/2602.23615)
*Jiacheng Yang,Anqi Chen,Yunkai Dang,Qi Fan,Cong Wang,Wenbin Li,Feng Miao,Yang Gao*

Main category: cs.CV

TL;DR: HART是一个无需标注的高分辨率视觉推理框架，通过自验证关键区域定位和策略优化，提升大模型在高分辨率视觉任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 当前大模型处理高分辨率视觉输入时面临token数量平方级增长、冗余信息多的问题。现有方法依赖昂贵的人工标注来识别关键区域，如何在不依赖额外标注的情况下提升模型的定位和推理能力是一个开放性问题。

Method: 提出HART框架，采用后训练范式，设计AP-GRPO（优势偏好组相对策略优化）来鼓励准确的关键区域定位，形成自验证的闭环系统，使模型能够聚焦并验证高分辨率输入的关键区域。

Result: 实验表明HART在多种高分辨率视觉任务上表现优异，持续超越强基线。应用于Qwen2.5-VL-7B后，甚至超越了Qwen2.5-VL-72B和LLaVA-OneVision-72B等更大规模模型在高分辨率视觉基准上的表现。

Conclusion: HART通过无需标注的自验证关键区域定位框架，有效解决了大模型处理高分辨率视觉输入的挑战，提供了可解释的推理路径，并在多个基准上取得了显著性能提升。

Abstract: Current Large Multimodal Models (LMMs) struggle with high-resolution visual inputs during the reasoning process, as the number of image tokens increases quadratically with resolution, introducing substantial redundancy and irrelevant information. A common practice is to identify key image regions and refer to their high-resolution counterparts during reasoning, typically trained with external visual supervision. However, such visual supervision cues require costly grounding labels from human annotators. Meanwhile, it remains an open question how to enhance a model's grounding abilities to support reasoning without relying on additional annotations. In this paper, we propose High-resolution Annotation-free Reasoning Technique (HART), a closed-loop framework that enables LMMs to focus on and self-verify key regions of high-resolution visual inputs. HART incorporates a post-training paradigm in which we design Advantage Preference Group Relative Policy Optimization (AP-GRPO) to encourage accurate localization of key regions. Notably, HART provides explainable reasoning pathways and enables efficient optimization of localization. Extensive experiments demonstrate that HART improves performance across a wide range of high-resolution visual tasks, consistently outperforming strong baselines. When applied to post-train Qwen2.5-VL-7B, HART even surpasses larger-scale models such as Qwen2.5-VL-72B and LLaVA-OneVision-72B on high-resolution, vision-centric benchmarks.

</details>


### [11] [Egocentric Visibility-Aware Human Pose Estimation](https://arxiv.org/abs/2602.23618)
*Peng Dai,Yu Zhang,Yiqiang Feng,Zhen Fan,Yang Zhang*

Main category: cs.CV

TL;DR: 本文提出了Eva-3M数据集和EvaPose方法，解决了第一人称视角人体姿态估计中关键点不可见性的问题，通过标注可见性标签和显式建模可见性信息来提升姿态估计精度。


<details>
  <summary>Details</summary>
Motivation: 第一人称视角人体姿态估计在VR/AR应用中很重要，但面临关键点不可见性的挑战。现有数据集缺乏关键点可见性标注，现有方法也忽视不可见性问题，导致可见关键点的预测精度受限。

Method: 1) 创建Eva-3M大规模数据集（300万帧，其中43.5万帧有可见性标注）；2) 为现有EMHI数据集添加可见性标注；3) 提出EvaPose方法，显式地整合可见性信息来提升姿态估计精度。

Result: 实验验证了地面真实可见性标签在第一人称视角姿态估计中的重要性，EvaPose方法在Eva-3M和EMHI数据集上都达到了最先进的性能。

Conclusion: 关键点可见性标注对第一人称视角人体姿态估计至关重要，提出的Eva-3M数据集和EvaPose方法有效解决了不可见性问题，显著提升了姿态估计精度。

Abstract: Egocentric human pose estimation (HPE) using a head-mounted device is crucial for various VR and AR applications, but it faces significant challenges due to keypoint invisibility. Nevertheless, none of the existing egocentric HPE datasets provide keypoint visibility annotations, and the existing methods often overlook the invisibility problem, treating visible and invisible keypoints indiscriminately during estimation. As a result, their capacity to accurately predict visible keypoints is compromised. In this paper, we first present Eva-3M, a large-scale egocentric visibility-aware HPE dataset comprising over 3.0M frames, with 435K of them annotated with keypoint visibility labels. Additionally, we augment the existing EMHI dataset with keypoint visibility annotations to further facilitate the research in this direction. Furthermore, we propose EvaPose, a novel egocentric visibility-aware HPE method that explicitly incorporates visibility information to enhance pose estimation accuracy. Extensive experiments validate the significant value of ground-truth visibility labels in egocentric HPE settings, and demonstrate that our EvaPose achieves state-of-the-art performance in both Eva-3M and EMHI datasets.

</details>


### [12] [DLEBench: Evaluating Small-scale Object Editing Ability for Instruction-based Image Editing Model](https://arxiv.org/abs/2602.23622)
*Shibo Hong,Boxian Ai,Jun Kuang,Wei Wang,FengJiao Chen,Zhongyuan Peng,Chenhao Huang,Yixin Cao*

Main category: cs.CV

TL;DR: 该论文提出了首个专门评估指令式图像编辑模型在小物体编辑能力上的基准测试DLEBench，包含1889个样本和7种指令类型，针对图像面积仅占1%-10%的小物体编辑场景。


<details>
  <summary>Details</summary>
Motivation: 当前指令式图像编辑模型在现有基准测试上表现良好，但在小物体编辑能力方面尚未得到充分探索，而这一能力对于精确局部编辑和细节优化至关重要。

Method: 构建了DeepLookEditBench基准测试，包含1889个样本覆盖7种指令类型，目标物体仅占图像面积的1%-10%，涵盖部分遮挡和多物体编辑等复杂场景。提出了包含精化评分标准的评估协议，并设计了双模式评估框架（工具驱动模式和Oracle引导模式）来解决LMM-as-a-Judge与人类判断之间的不一致问题。

Result: 在10个指令式图像编辑模型上的实证结果显示，在小物体编辑方面存在显著的性能差距，突显了专门基准测试的必要性。

Conclusion: 需要专门的基准测试来推动指令式图像编辑模型在小物体编辑能力方面的发展，DLEBench为此提供了有效的评估工具。

Abstract: Significant progress has been made in the field of Instruction-based Image Editing Models (IIEMs). However, while these models demonstrate plausible adherence to instructions and strong reasoning ability on current benchmarks, their ability to edit small objects remains underexplored, despite its importance for precise local editing and refining details in both real and generated images. In this paper, we introduce DeepLookEditBench (DLEBench), the first benchmark dedicated to assessing the abilities of IIEMs in editing small-scale objects. Specifically, we construct a challenging testbed comprising 1889 samples across seven instruction types. In these samples, target objects occupy only 1%-10% of the image area, covering complex scenarios such as partial occlusion and multi-object editing. To ensure robust evaluation on this benchmark, we propose an evaluation protocol with refined score rubrics to minimize subjectivity and ambiguity in two criteria: Instruction Following and Visual Consistency. This protocol also introduces a dual-mode evaluation framework (Tool-driven and Oracle-guided Modes) addressing the misalignment between LMM-as-a-Judge and human judgements on DLEBench. Empirical results on 10 IIEMs reveal significant performance gaps in small-scale object editing, highlighting the need for specialized benchmarks to advance this ability.

</details>


### [13] [BuildAnyPoint: 3D Building Structured Abstraction from Diverse Point Clouds](https://arxiv.org/abs/2602.23645)
*Tongyan Hua,Haoran Gong,Yuan Liu,Di Wang,Ying-Cong Chen,Wufan Zhao*

Main category: cs.CV

TL;DR: BuildAnyPoint是一个从点云进行结构化3D建筑重建的新框架，通过松散级联扩散变换器(Loca-DiT)从噪声或稀疏点云中恢复底层分布，然后自回归地将其封装为紧凑网格。


<details>
  <summary>Details</summary>
Motivation: 从具有不同分布的点云（如机载LiDAR和运动恢复结构）中进行结构化3D建筑重建是一个高度欠约束的问题，需要恢复艺术家创建的建筑抽象表示。

Method: 设计了松散级联扩散变换器(Loca-DiT)：1）首先将分布恢复作为条件生成任务，训练以输入点云为条件的潜在扩散模型；2）然后定制仅解码器变换器，基于恢复的点云进行条件自回归网格生成。

Result: 在建筑抽象方法上取得了显著的定性和定量改进，其恢复的点云在建筑点云补全基准测试中表现出色，具有改进的表面精度和分布均匀性。

Conclusion: BuildAnyPoint框架通过结合显式3D生成先验和自回归网格生成，有效解决了从多样化点云分布中进行结构化3D建筑重建的挑战。

Abstract: We introduce BuildAnyPoint, a novel generative framework for structured 3D building reconstruction from point clouds with diverse distributions, such as those captured by airborne LiDAR and Structure-from-Motion. To recover artist-created building abstraction in this highly underconstrained setting, we capitalize on the role of explicit 3D generative priors in autoregressive mesh generation. Specifically, we design a Loosely Cascaded Diffusion Transformer (Loca-DiT) that initially recovers the underlying distribution from noisy or sparse points, followed by autoregressively encapsulating them into compact meshes. We first formulate distribution recovery as a conditional generation task by training latent diffusion models conditioned on input point clouds, and then tailor a decoder-only transformer for conditional autoregressive mesh generation based on the recovered point clouds. Our method delivers substantial qualitative and quantitative improvements over prior building abstraction methods. Furthermore, the effectiveness of our approach is evidenced by the strong performance of its recovered point clouds on building point cloud completion benchmarks, which exhibit improved surface accuracy and distribution uniformity.

</details>


### [14] [3D Modality-Aware Pre-training for Vision-Language Model in MRI Multi-organ Abnormality Detection](https://arxiv.org/abs/2602.23652)
*Haowen Zhu,Ning Yin,Xiaogen Zhou*

Main category: cs.CV

TL;DR: MedMAP是一个医学模态感知预训练框架，通过模态感知的视觉-语言对齐和微调阶段，提升3D MRI多器官异常检测性能


<details>
  <summary>Details</summary>
Motivation: 将视觉语言模型应用于多器官医学影像面临两个主要挑战：模态特定的视觉-语言对齐和跨模态特征融合

Method: 提出MedMAP框架，包含模态感知视觉-语言对齐预训练阶段和下游任务微调阶段；创建了MedMoM-MRI3D数据集，包含7,392个3D MRI体积-报告对

Result: 在MedMoM-MRI3D数据集上的实验表明，MedMAP在3D MRI多器官异常检测任务上显著优于现有视觉语言模型

Conclusion: MedMAP通过模态感知的预训练方法有效解决了多器官医学影像中的视觉-语言对齐挑战，提升了3D MRI诊断性能

Abstract: Vision-language models (VLMs) show strong potential for complex diagnostic tasks in medical imaging. However, applying VLMs to multi-organ medical imaging introduces two principal challenges: (1) modality-specific vision-language alignment and (2) cross-modal feature fusion. In this work, we propose MedMAP, a Medical Modality-Aware Pretraining framework that enhances vision-language representation learning in 3D MRI. MedMAP comprises a modality-aware vision-language alignment stage and a fine-tuning stage for multi-organ abnormality detection. During the pre-training stage, the modality-aware encoders implicitly capture the joint modality distribution and improve alignment between visual and textual representations. We then fine-tune the pre-trained vision encoders (while keeping the text encoder frozen) for downstream tasks. To this end, we curated MedMoM-MRI3D, comprising 7,392 3D MRI volume-report pairs spanning twelve MRI modalities and nine abnormalities tailored for various 3D medical analysis tasks. Extensive experiments on MedMoM-MRI3D demonstrate that MedMAP significantly outperforms existing VLMs in 3D MRI-based multi-organ abnormality detection. Our code is available at https://github.com/RomantiDr/MedMAP.

</details>


### [15] [ProtoDCS: Towards Robust and Efficient Open-Set Test-Time Adaptation for Vision-Language Models](https://arxiv.org/abs/2602.23653)
*Wei Luo,Yangfan Ou,Jin Deng,Zeshuai Deng,Xiquan Yan,Zhiquan Wen,Mingkui Tan*

Main category: cs.CV

TL;DR: ProtoDCS：一种用于视觉语言模型的开集测试时适应框架，通过双重检查分离机制和证据驱动适应策略，有效处理协变量偏移的分布内和分布外数据。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型的测试时适应方法在开集场景下存在局限，无法有效区分协变量偏移的分布内和分布外数据，导致模型性能下降和计算成本过高。

Method: 提出原型双重检查分离框架，使用概率高斯混合模型验证替代脆弱的阈值方法，并结合证据驱动适应策略，采用不确定性感知损失和高效原型级更新。

Result: 在CIFAR-10/100-C和Tiny-ImageNet-C数据集上的实验表明，ProtoDCS在已知类别准确率和OOD检测指标上均达到最先进性能。

Conclusion: ProtoDCS为视觉语言模型提供了一种鲁棒、高效的开集测试时适应解决方案，显著提升了模型在真实世界分布偏移场景下的部署能力。

Abstract: Large-scale Vision-Language Models (VLMs) exhibit strong zero-shot recognition, yet their real-world deployment is challenged by distribution shifts. While Test-Time Adaptation (TTA) can mitigate this, existing VLM-based TTA methods operate under a closed-set assumption, failing in open-set scenarios where test streams contain both covariate-shifted in-distribution (csID) and out-of-distribution (csOOD) data. This leads to a critical difficulty: the model must discriminate unknown csOOD samples to avoid interference while simultaneously adapting to known csID classes for accuracy. Current open-set TTA (OSTTA) methods rely on hard thresholds for separation and entropy minimization for adaptation. These strategies are brittle, often misclassifying ambiguous csOOD samples and inducing overconfident predictions, and their parameter-update mechanism is computationally prohibitive for VLMs. To address these limitations, we propose Prototype-based Double-Check Separation (ProtoDCS), a robust framework for OSTTA that effectively separates csID and csOOD samples, enabling safe and efficient adaptation of VLMs to csID data. Our main contributions are: (1) a novel double-check separation mechanism employing probabilistic Gaussian Mixture Model (GMM) verification to replace brittle thresholding; and (2) an evidence-driven adaptation strategy utilizing uncertainty-aware loss and efficient prototype-level updates, mitigating overconfidence and reducing computational overhead. Extensive experiments on CIFAR-10/100-C and Tiny-ImageNet-C demonstrate that ProtoDCS achieves state-of-the-art performance, significantly boosting both known-class accuracy and OOD detection metrics. Code will be available at https://github.com/O-YangF/ProtoDCS.

</details>


### [16] [Suppressing Prior-Comparison Hallucinations in Radiology Report Generation via Semantically Decoupled Latent Steering](https://arxiv.org/abs/2602.23676)
*Ao Li,Rui Liu,Mingjie Li,Sheng Liu,Lei Wang,Xiaodan Liang,Lina Yao,Xiaojun Chang,Lei Xing*

Main category: cs.CV

TL;DR: 提出SDLS框架，通过语义解耦的潜在空间操控，在推理时无训练地减少放射学报告生成中的历史比较幻觉，同时保持临床准确性。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉语言模型的自动放射学报告生成存在历史比较幻觉问题，即模型会生成当前研究中不存在的历史发现。现有方法在抑制幻觉和保持临床准确性之间存在权衡。

Method: 提出语义解耦潜在操控（SDLS）框架：1）使用大语言模型进行语义分解；2）通过QR正交化构建语义无关的干预向量；3）利用几何约束过滤临床语义纠缠，专门针对"历史比较"轴进行操控。

Result: 在BiomedGPT模型上验证：1）历史幻觉概率显著降低（FilBERT分数从0.2373降至0.1889）；2）临床标签保真度提高（CheXpert宏F1从0.2242提升至0.3208）；3）在MIMIC-CXR、CheXpert Plus和IU-Xray数据集上均表现稳健。

Conclusion: SDLS框架成功解决了放射学报告生成中的历史比较幻觉问题，打破了幻觉抑制与临床准确性之间的权衡，同时保持了临床叙述的结构完整性。

Abstract: Automated radiology report generation using vision-language models (VLMs) is limited by the risk of prior-comparison hallucination, where the model generates historical findings unsupported by the current study. We address this challenge with a training-free, inference-time control framework termed Semantically Decoupled Latent Steering (SDLS). Unlike generic activation steering, which often suffers from semantic entanglement, our approach constructs a semantic-free intervention vector via large language model (LLM)-driven semantic decomposition followed by $QR$-based orthogonalization. This orthogonalization step is critical. It leverages geometric constraints to filter out the clinical semantics often entangled in standard principal component analysis (PCA) directions, ensuring that the steering vector targets only the ``historical comparison" axis. We validate our method on the BiomedGPT foundation model, demonstrating that it overcomes the trade-off between hallucination suppression and clinical accuracy. Extensive experiments on MIMIC-CXR, and zero-shot transfer evaluation on CheXpert Plus and IU-Xray, demonstrate the robustness of our approach. Quantitative evaluations on MIMIC-CXR show that our approach significantly reduces the probability of historical hallucinations (FilBERT score decreases from 0.2373 to 0.1889) and improves clinical label fidelity (CheXpert macro-F1 increases from 0.2242 to 0.3208). Supplementary evaluations confirm that the structural integrity of the clinical narrative is maintained.

</details>


### [17] [Vision-Language Semantic Grounding for Multi-Domain Crop-Weed Segmentation](https://arxiv.org/abs/2602.23677)
*Nazia Hossain,Xintong Jiang,Yu Tian,Philippe Seguin,O. Grant Clark,Shangpeng Sun*

Main category: cs.CV

TL;DR: VL-WS：基于视觉-语言对齐的细粒度杂草分割框架，通过CLIP嵌入和自然语言描述引导的特征调制，在异构农业环境中实现更好的泛化性能


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型依赖数据集特定的视觉特征，难以在异构农业环境中泛化。需要一种能够利用语义对齐、领域不变表示的方法来改进细粒度作物-杂草分割

Method: 提出VL-WS框架，采用双编码器设计：冻结的CLIP嵌入与任务特定空间特征通过FiLM层融合，该层由自然语言描述条件化。在包含地面图像和无人机图像的统一数据集上训练

Result: 在四个基准数据集上平均Dice分数达91.64%，比CNN基线提升4.98%。最具挑战性的杂草类别提升15.42%（80.45% vs 65.03%）。在有限目标域监督下保持稳定性能

Conclusion: 视觉-语言对齐能够实现可扩展、标签高效的跨领域分割模型，为实际农业应用提供更好的泛化能力和数据效率

Abstract: Fine-grained crop-weed segmentation is essential for enabling targeted herbicide application in precision agriculture. However, existing deep learning models struggle to generalize across heterogeneous agricultural environments due to reliance on dataset-specific visual features. We propose Vision-Language Weed Segmentation (VL-WS), a novel framework that addresses this limitation by grounding pixel-level segmentation in semantically aligned, domain-invariant representations. Our architecture employs a dual-encoder design, where frozen Contrastive Language-Image Pretraining (CLIP) embeddings and task-specific spatial features are fused and modulated via Feature-wise Linear Modulation (FiLM) layers conditioned on natural language captions. This design enables image level textual descriptions to guide channel-wise feature refinement while preserving fine-grained spatial localization. Unlike prior works restricted to training and evaluation on single-source datasets, VL-WS is trained on a unified corpus that includes close-range ground imagery (robotic platforms) and high-altitude UAV imagery, covering diverse crop types, weed species, growth stages, and sensing conditions. Experimental results across four benchmark datasets demonstrate the effectiveness of our framework, with VL-WS achieving a mean Dice score of 91.64% and outperforming the CNN baseline by 4.98%. The largest gains occur on the most challenging weed class, where VL-WS attains 80.45% Dice score compared to 65.03% for the best baseline, representing a 15.42% improvement. VL-WS further maintains stable weed segmentation performance under limited target-domain supervision, indicating improved generalization and data efficiency. These findings highlight the potential of vision-language alignment to enable scalable, label-efficient segmentation models deployable across diverse real-world agricultural domains.

</details>


### [18] [Any Model, Any Place, Any Time: Get Remote Sensing Foundation Model Embeddings On Demand](https://arxiv.org/abs/2602.23678)
*Dingqi Ye,Daniel Kiv,Wei Hu,Jimeng Shi,Shaowen Wang*

Main category: cs.CV

TL;DR: rs-embed是一个Python库，为遥感基础模型提供统一的ROI中心接口，简化嵌入获取和比较过程


<details>
  <summary>Details</summary>
Motivation: 遥感基础模型快速增长，但模型发布格式、平台接口和数据规范的异构性导致实际应用和公平比较困难，增加了获取、使用和基准测试的成本

Method: 开发rs-embed Python库，提供统一的ROI中心接口，支持单行代码从任何支持模型获取任何位置和时间范围的嵌入，并提供高效的批量处理功能

Result: 代码已在GitHub开源，实现了简化模型嵌入获取、使用和比较的目标

Conclusion: rs-embed解决了遥感基础模型生态中的互操作性问题，降低了使用门槛，促进了公平比较和大规模嵌入生成与评估

Abstract: The remote sensing community is witnessing a rapid growth of foundation models, which provide powerful embeddings for a wide range of downstream tasks. However, practical adoption and fair comparison remain challenging due to substantial heterogeneity in model release formats, platforms and interfaces, and input data specifications. These inconsistencies significantly increase the cost of obtaining, using, and benchmarking embeddings across models. To address this issue, we propose rs-embed, a Python library that offers a unified, region of interst (ROI) centric interface: with a single line of code, users can retrieve embeddings from any supported model for any location and any time range. The library also provides efficient batch processing to enable large-scale embedding generation and evaluation. The code is available at: https://github.com/cybergis/rs-embed

</details>


### [19] [Towards Source-Aware Object Swapping with Initial Noise Perturbation](https://arxiv.org/abs/2602.23697)
*Jiahui Zhan,Xianbing Sun,Xiangnan Zhu,Yikun Ji,Ruitong Liu,Liqing Zhang,Jianfu Zhang*

Main category: cs.CV

TL;DR: SourceSwap是一个自监督的源感知框架，通过频率分离扰动在初始噪声空间合成高质量伪对，实现跨对象对齐，无需逐对象微调即可进行零样本推理


<details>
  <summary>Details</summary>
Motivation: 现有对象交换方法要么需要逐对象微调和慢速推理，要么依赖额外配对数据（通常描绘相同对象在不同上下文中的情况），迫使模型依赖背景线索而非学习跨对象对齐

Method: 提出SourceSwap框架：1）通过频率分离扰动在初始噪声空间合成高质量伪对，改变外观同时保持姿态、粗形状和场景布局；2）训练具有全源条件化和无噪声参考编码器的双U-Net；3）引入SourceBench高质量基准测试集

Result: SourceSwap在保真度、场景保持和自然和谐度方面表现优异，能够良好地迁移到主题驱动细化和人脸交换等编辑任务，支持零样本推理无需逐对象微调

Conclusion: SourceSwap通过自监督学习和源感知框架成功解决了对象交换中的跨对象对齐问题，实现了高质量的对象交换效果，并在多个指标上超越了现有方法

Abstract: Object swapping aims to replace a source object in a scene with a reference object while preserving object fidelity, scene fidelity, and object-scene harmony. Existing methods either require per-object finetuning and slow inference or rely on extra paired data that mostly depict the same object across contexts, forcing models to rely on background cues rather than learning cross-object alignment. We propose SourceSwap, a self-supervised and source-aware framework that learns cross-object alignment. Our key insight is to synthesize high-quality pseudo pairs from any image via a frequency-separated perturbation in the initial-noise space, which alters appearance while preserving pose, coarse shape, and scene layout, requiring no videos, multi-view data, or additional images. We then train a dual U-Net with full-source conditioning and a noise-free reference encoder, enabling direct inter-object alignment, zero-shot inference without per-object finetuning, and lightweight iterative refinement. We further introduce SourceBench, a high-quality benchmark with higher resolution, more categories, and richer interactions. Experiments demonstrate that SourceSwap achieves superior fidelity, stronger scene preservation, and more natural harmony, and it transfers well to edits such as subject-driven refinement and face swapping.

</details>


### [20] [HiDrop: Hierarchical Vision Token Reduction in MLLMs via Late Injection, Concave Pyramid Pruning, and Early Exit](https://arxiv.org/abs/2602.23699)
*Hao Wu,Yingqi Fan,Jinyang Dai,Junlong Tong,Yunpu Ma,Xiaoyu Shen*

Main category: cs.CV

TL;DR: HiDrop是一个高效的多模态大语言模型训练框架，通过层次化视觉token剪枝，压缩约90%视觉token，保持性能的同时加速训练1.72倍。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型中视觉token的二次计算成本阻碍了其广泛应用。现有的渐进式视觉token剪枝方法误解了浅层功能并使用刚性调度，未能充分发挥效率潜力。

Method: 提出HiDrop框架，包含两个关键创新：1) 延迟注入：绕过被动的浅层，在主动融合开始处引入视觉token；2) 凹金字塔剪枝与早期退出机制：通过层间相似性度量和可微分top-k算子动态调整中间层和深层的剪枝率。还包含持久位置编码、FlashAttention兼容的token选择和并行解耦视觉计算等技术。

Result: 实验表明，HiDrop压缩约90%视觉token，同时匹配原始性能，训练加速1.72倍，在高效MLLM训练和推理方面达到新的最先进水平。

Conclusion: HiDrop不仅为高效MLLM训练和推理设定了新的最先进水平，还提供了对多模态融合层次性质的有价值见解。

Abstract: The quadratic computational cost of processing vision tokens in Multimodal Large Language Models (MLLMs) hinders their widespread adoption. While progressive vision token pruning offers a promising solution, current methods misinterpret shallow layer functions and use rigid schedules, which fail to unlock the full efficiency potential. To address these issues, we propose HiDrop, a framework that aligns token pruning with the true hierarchical function of MLLM layers. HiDrop features two key innovations: (1) Late Injection, which bypasses passive shallow layers to introduce visual tokens exactly where active fusion begins; and (2) Concave Pyramid Pruning with an Early Exit mechanism to dynamically adjust pruning rates across middle and deep layers. This process is optimized via an inter-layer similarity measure and a differentiable top-k operator. To ensure practical efficiency, HiDrop further incorporates persistent positional encoding, FlashAttention-compatible token selection, and parallel decoupling of vision computation to eliminate hidden overhead associated with dynamic token reduction. Extensive experiments show that HiDrop compresses about 90% visual tokens while matching the original performance and accelerating training by 1.72 times. Our work not only sets a new state-of-the-art for efficient MLLM training and inference but also provides valuable insights into the hierarchical nature of multimodal fusion. The code is released at https://github.com/EIT-NLP/HiDrop.

</details>


### [21] [EgoGraph: Temporal Knowledge Graph for Egocentric Video Understanding](https://arxiv.org/abs/2602.23709)
*Shitong Sun,Ke Han,Yukai Huang,Weitong Cai,Jifei Song*

Main category: cs.CV

TL;DR: EgoGraph：一种无需训练的动态知识图谱构建框架，用于超长第一人称视频理解，通过编码跨实体长期依赖关系实现更好的时序推理


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理跨越多天的超长第一人称视频时，仍然依赖碎片化的局部处理和有限的时序建模，无法有效推理这种超长序列。需要一种能够编码长期跨实体依赖关系的新方法。

Method: 提出EgoGraph框架：1）采用新颖的第一人称模式统一提取和抽象核心实体（人物、物体、位置、事件）；2）结构化推理实体属性和交互；3）开发时序关系建模策略捕捉跨实体时序依赖；4）积累多天的稳定长期记忆。

Result: 在EgoLifeQA和EgoR1-bench基准测试中，EgoGraph在长期视频问答任务上取得了最先进的性能，验证了其作为超长第一人称视频理解新范式的有效性。

Conclusion: EgoGraph通过构建动态知识图谱，显式编码长期跨实体依赖关系，为超长第一人称视频理解提供了更丰富、更连贯的语义表示，实现了复杂的时序推理能力。

Abstract: Ultra-long egocentric videos spanning multiple days present significant challenges for video understanding. Existing approaches still rely on fragmented local processing and limited temporal modeling, restricting their ability to reason over such extended sequences. To address these limitations, we introduce EgoGraph, a training-free and dynamic knowledge-graph construction framework that explicitly encodes long-term, cross-entity dependencies in egocentric video streams. EgoGraph employs a novel egocentric schema that unifies the extraction and abstraction of core entities, such as people, objects, locations, and events, and structurally reasons about their attributes and interactions, yielding a significantly richer and more coherent semantic representation than traditional clip-based video models. Crucially, we develop a temporal relational modeling strategy that captures temporal dependencies across entities and accumulates stable long-term memory over multiple days, enabling complex temporal reasoning. Extensive experiments on the EgoLifeQA and EgoR1-bench benchmarks demonstrate that EgoGraph achieves state-of-the-art performance on long-term video question answering, validating its effectiveness as a new paradigm for ultra-long egocentric video understanding.

</details>


### [22] [Can Unified Generation and Understanding Models Maintain Semantic Equivalence Across Different Output Modalities?](https://arxiv.org/abs/2602.23711)
*Hongbo Jiang,Jie Li,Yunhang Shen,Pingyang Dai,Xing Sun,Haoyu Cao,Liujuan Cao*

Main category: cs.CV

TL;DR: 研究发现统一多模态大语言模型在文本推理上表现良好，但在需要将相同推理结果以图像形式呈现时，无法保持语义一致性，存在跨模态语义对齐问题。


<details>
  <summary>Details</summary>
Motivation: 现有统一多模态大语言模型评估通常将理解和生成能力分开评估，忽略了语义等价性——即无论输出模态如何都能表现一致推理结果的能力。本研究旨在探究当前U-MLLMs是否满足这一前提。

Method: 引入VGUBench框架，将推理逻辑与生成保真度解耦。包含三个诊断任务：1)文本生成理解，建立文本响应的推理准确性基线；2)视觉生成理解，评估生成正确视觉答案的能力；3)视觉渲染控制任务，评估直接将明确视觉描述渲染为图像的能力。

Result: 评估显示显著差异：尽管在文本理解和视觉渲染方面表现强劲，但U-MLLMs在需要生成视觉答案时出现明显性能崩溃。视觉回答性能与基本渲染质量之间几乎没有相关性。

Conclusion: 失败原因不是生成保真度不足，而是跨模态语义对齐的崩溃。研究提供了诊断见解，以解决未来统一生成和理解模型中的这一挑战。

Abstract: Unified Multimodal Large Language Models (U-MLLMs) integrate understanding and generation within a single architecture. However, existing evaluations typically assess these capabilities separately, overlooking semantic equivalence, i.e., the ability to manifest consistent reasoning results regardless of the output modality. In this work, we investigate whether current U-MLLMs satisfy this premise. We observe that while models demonstrate robust textual reasoning, they fail to maintain semantic equivalence when required to render the same results in the image modality. To rigorously diagnose this discrepancy, we introduce VGUBench, a framework to decouple reasoning logic from generation fidelity. VGUBench comprises three diagnostic tasks: (1)Textual Generative Understanding, establishing a baseline for reasoning accuracy in textual response; (2)Visual Generative Understanding, evaluating the ability to generate visual responses that represent the correct answer; and (3)a Visual Rendering control task, which assesses the ability to directly render explicit visual descriptions into images without complex reasoning. Our evaluation reveals a significant disparity: despite strong performance in textual understanding and visual rendering, U-MLLMs exhibit a marked performance collapse when required to generate visual answers to questions. Furthermore, we find a negligible correlation between visual answering performance and basic rendering quality. These results suggest that the failure stems not from insufficient generation fidelity, but from a breakdown in cross-modal semantic alignment. We provide diagnostic insights to address this challenge in future Unified Generation and Understanding Models.

</details>


### [23] [A Difference-in-Difference Approach to Detecting AI-Generated Images](https://arxiv.org/abs/2602.23732)
*Xinyi Qi,Kai Ye,Chengchun Shi,Ying Yang,Hongyi Zhou,Jin Zhu*

Main category: cs.CV

TL;DR: 提出基于二阶差分（重建误差之差）的方法来检测AI生成图像，相比传统的一阶差分（重建误差）方法在生成图像越来越逼真的情况下表现更好。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型生成的图像越来越逼真，传统的基于重建误差的检测方法效果下降，需要更有效的检测技术来应对AI生成图像的潜在滥用问题。

Method: 提出差分中的差分方法，不直接使用重建误差（一阶差分），而是计算重建误差的差异（二阶差分），通过方差减少来提高检测准确率。

Result: 大量实验表明该方法具有强大的泛化性能，能够在生成式AI时代可靠地检测AI生成的图像。

Conclusion: 二阶差分方法相比传统的一阶差分方法能更有效地检测越来越逼真的AI生成图像，为解决生成式AI带来的检测挑战提供了新思路。

Abstract: Diffusion models are able to produce AI-generated images that are almost indistinguishable from real ones. This raises concerns about their potential misuse and poses substantial challenges for detecting them. Many existing detectors rely on reconstruction error -- the difference between the input image and its reconstructed version -- as the basis for distinguishing real from fake images. However, these detectors become less effective as modern AI-generated images become increasingly similar to real ones. To address this challenge, we propose a novel difference-in-difference method. Instead of directly using the reconstruction error (a first-order difference), we compute the difference in reconstruction error -- a second-order difference -- for variance reduction and improving detection accuracy. Extensive experiments demonstrate that our method achieves strong generalization performance, enabling reliable detection of AI-generated images in the era of generative AI.

</details>


### [24] [UTPTrack: Towards Simple and Unified Token Pruning for Visual Tracking](https://arxiv.org/abs/2602.23734)
*Hao Wu,Xudong Wang,Jialiang Zhang,Junlong Tong,Xinghao Chen,Junyan Lin,Yunpu Ma,Xiaoyu Shen*

Main category: cs.CV

TL;DR: UTPTrack是一个统一的Transformer令牌剪枝框架，首次联合压缩搜索区域、动态模板和静态模板三个组件，在保持性能的同时大幅减少计算开销


<details>
  <summary>Details</summary>
Motivation: 现有的单流Transformer跟踪器虽然性能先进，但计算开销大，难以实时部署。现有的令牌剪枝方法通常是孤立地剪枝各个组件，忽略了组件间的依赖关系，导致次优剪枝和精度下降

Method: 提出UTPTrack框架，采用注意力引导、令牌类型感知的策略，统一建模所有三个组件的冗余性，支持多模态和语言引导的统一跟踪任务

Result: 在10个基准测试中，UTPTrack在剪枝类跟踪器中实现了精度-效率权衡的新SOTA：在RGB跟踪中剪枝65.4%视觉令牌，保持99.7%基线性能；在统一跟踪中剪枝67.5%令牌，保持100.5%基线性能

Conclusion: UTPTrack通过统一的令牌剪枝框架，在RGB和多模态场景下都表现出色，为高效视觉跟踪的未来研究提供了坚实基础

Abstract: One-stream Transformer-based trackers achieve advanced performance in visual object tracking but suffer from significant computational overhead that hinders real-time deployment. While token pruning offers a path to efficiency, existing methods are fragmented. They typically prune the search region, dynamic template, and static template in isolation, overlooking critical inter-component dependencies, which yields suboptimal pruning and degraded accuracy. To address this, we introduce UTPTrack, a simple and Unified Token Pruning framework that, for the first time, jointly compresses all three components. UTPTrack employs an attention-guided, token type-aware strategy to holistically model redundancy, a design that seamlessly supports unified tracking across multimodal and language-guided tasks within a single model. Extensive evaluations on 10 benchmarks demonstrate that UTPTrack achieves a new state-of-the-art in the accuracy-efficiency trade-off for pruning-based trackers, pruning 65.4% of vision tokens in RGB-based tracking and 67.5% in unified tracking while preserving 99.7% and 100.5% of baseline performance, respectively. This strong performance across both RGB and multimodal scenarios underlines its potential as a robust foundation for future research in efficient visual tracking. Code will be released at https://github.com/EIT-NLP/UTPTrack.

</details>


### [25] [Learning Accurate Segmentation Purely from Self-Supervision](https://arxiv.org/abs/2602.23759)
*Zuyao You,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: Selfment是一个完全自监督的框架，无需人工标注、预训练分割模型或后处理，直接从原始图像分割前景对象，在多个基准测试中达到新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 在没有人工标注的情况下准确分割对象是计算机视觉的核心挑战之一。现有方法通常依赖人工标注、预训练模型或复杂的后处理，而Selfment旨在实现完全自监督的前景对象分割。

Method: 1. 从自监督特征构建补丁级亲和力图，应用NCut获得初始的粗粒度前景-背景分离；2. 引入迭代补丁优化(IPO)，通过迭代补丁聚类在特征空间中进行细化，增强空间一致性和语义一致性；3. 使用细化的掩码作为监督信号，通过对比学习和区域一致性目标训练轻量级分割头。

Result: 在多个基准测试中达到新的SOTA：ECSSD上F_max提升4.0%，HKUIS提升4.6%，PASCAL-S提升5.7%。在伪装对象检测任务中表现出卓越的零样本泛化能力：CHAMELEON上Sm达到0.910，CAMO上Fβ^ω达到0.792，超越所有现有无监督方法，甚至媲美全监督SOTA方法。

Conclusion: Selfment证明了完全自监督对象分割的可行性，通过简单的框架实现了卓越性能，在无监督分割和零样本泛化方面取得了突破性进展，为无标注视觉理解开辟了新途径。

Abstract: Accurately segmenting objects without any manual annotations remains one of the core challenges in computer vision. In this work, we introduce Selfment, a fully self-supervised framework that segments foreground objects directly from raw images without human labels, pretrained segmentation models, or any post-processing. Selfment first constructs patch-level affinity graphs from self-supervised features and applies NCut to obtain an initial coarse foreground--background separation. We then introduce Iterative Patch Optimization (IPO), a feature-space refinement procedure that progressively enforces spatial coherence and semantic consistency through iterative patch clustering. The refined masks are subsequently used as supervisory signals to train a lightweight segmentation head with contrastive and region-consistency objectives, allowing the model to learn stable and transferable object representations. Despite its simplicity and complete absence of manual supervision, Selfment sets new state-of-the-art (SoTA) results across multiple benchmarks. It achieves substantial improvements on $F_{\max}$ over previous unsupervised saliency detection methods on ECSSD ($+4.0\%$), HKUIS ($+4.6\%$), and PASCAL-S ($+5.7\%$). Moreover, without any additional fine-tuning, Selfment demonstrates remarkable zero-shot generalization to camouflaged object detection tasks (e.g., $0.910$ $S_m$ on CHAMELEON and $0.792$ $F_β^ω$ on CAMO), outperforming all existing unsupervised approaches and even rivaling the SoTA fully supervised methods.

</details>


### [26] [Fourier Angle Alignment for Oriented Object Detection in Remote Sensing](https://arxiv.org/abs/2602.23790)
*Changyu Gu,Linwei Chen,Lin Gu,Ying Fu*

Main category: cs.CV

TL;DR: 本文提出Fourier Angle Alignment方法，通过傅里叶旋转等变性分析角度信息，解决遥感旋转目标检测中的方向不一致和任务冲突问题，在多个数据集上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 遥感旋转目标检测中的两个瓶颈：检测器颈部存在方向不一致问题，检测头部存在任务冲突问题。需要一种能够有效处理旋转目标角度信息的方法。

Method: 提出傅里叶角度对齐方法，通过频率谱分析角度信息并将主方向对齐到特定方向。设计两个即插即用模块：FAAFusion（在检测器颈部工作，将高层特征主方向与低层特征对齐并融合）和FAA Head（作为新检测头，将RoI特征预对齐到规范角度后添加到原始特征中）。

Result: 在DOTA-v1.0、DOTA-v1.5和HRSC2016数据集上显著提升现有方法性能。单尺度训练和测试下，在DOTA-v1.0上达到78.72% mAP，在DOTA-v1.5上达到72.28% mAP，均创下新的SOTA记录。

Conclusion: 傅里叶角度对齐方法有效解决了遥感旋转目标检测中的方向不一致和任务冲突问题，通过频率域的角度分析和特征对齐，显著提升了检测性能，验证了该方法的有效性。

Abstract: In remote sensing rotated object detection, mainstream methods suffer from two bottlenecks, directional incoherence at detector neck and task conflict at detecting head. Ulitising fourier rotation equivariance, we introduce Fourier Angle Alignment, which analyses angle information through frequency spectrum and aligns the main direction to a certain orientation. Then we propose two plug and play modules : FAAFusion and FAA Head. FAAFusion works at the detector neck, aligning the main direction of higher-level features to the lower-level features and then fusing them. FAA Head serves as a new detection head, which pre-aligns RoI features to a canonical angle and adds them to the original features before classification and regression. Experiments on DOTA-v1.0, DOTA-v1.5 and HRSC2016 show that our method can greatly improve previous work. Particularly, our method achieves new state-of-the-art results of 78.72% mAP on DOTA-v1.0 and 72.28% mAP on DOTA-v1.5 datasets with single scale training and testing, validating the efficacy of our approach in remote sensing object detection. The code is made publicly available at https://github.com/gcy0423/Fourier-Angle-Alignment .

</details>


### [27] [Action-Geometry Prediction with 3D Geometric Prior for Bimanual Manipulation](https://arxiv.org/abs/2602.23814)
*Chongyang Xu,Haipeng Li,Shen Cheng,Jingyu Hu,Haoqiang Fan,Ziliang Feng,Shuaicheng Liu*

Main category: cs.CV

TL;DR: 提出一个基于预训练3D几何基础模型的双手操作框架，通过融合几何感知潜在特征、2D语义特征和本体感知，使用扩散模型联合预测未来动作块和3D潜在表示，实现仅用RGB观测的强空间理解和预测能力。


<details>
  <summary>Details</summary>
Motivation: 现有双手操作方法通常依赖空间感知有限的2D特征，或需要难以在真实场景中可靠获取的显式点云。同时，最近的3D几何基础模型表明可以直接从RGB图像快速稳健地重建准确多样的3D结构。

Method: 构建在预训练3D几何基础模型上的框架，将几何感知潜在特征、2D语义特征和本体感知融合为统一状态表示，使用扩散模型联合预测未来动作块和可解码为密集点图的未来3D潜在表示。

Result: 在RoboTwin基准的仿真和真实机器人执行中评估，方法在操作成功率、双臂协调性和3D空间预测准确性方面一致优于基于2D和点云的基线，达到最先进性能。

Conclusion: 通过利用3D几何基础模型并联合预测动作和3D场景演化，仅使用RGB观测即可获得强大的空间理解和预测能力，为双手操作提供了有效的解决方案。

Abstract: Bimanual manipulation requires policies that can reason about 3D geometry, anticipate how it evolves under action, and generate smooth, coordinated motions. However, existing methods typically rely on 2D features with limited spatial awareness, or require explicit point clouds that are difficult to obtain reliably in real-world settings. At the same time, recent 3D geometric foundation models show that accurate and diverse 3D structure can be reconstructed directly from RGB images in a fast and robust manner. We leverage this opportunity and propose a framework that builds bimanual manipulation directly on a pre-trained 3D geometric foundation model. Our policy fuses geometry-aware latents, 2D semantic features, and proprioception into a unified state representation, and uses diffusion model to jointly predict a future action chunk and a future 3D latent that decodes into a dense pointmap. By explicitly predicting how the 3D scene will evolve together with the action sequence, the policy gains strong spatial understanding and predictive capability using only RGB observations. We evaluate our method both in simulation on the RoboTwin benchmark and in real-world robot executions. Our approach consistently outperforms 2D-based and point-cloud-based baselines, achieving state-of-the-art performance in manipulation success, inter-arm coordination, and 3D spatial prediction accuracy. Code is available at https://github.com/Chongyang-99/GAP.git.

</details>


### [28] [Footprint-Guided Exemplar-Free Continual Histopathology Report Generation](https://arxiv.org/abs/2602.23817)
*Pratibha Kumari,Daniel Reisenbüchler,Afshin Bozorgpour,yousef Sadegheih,Priyankar Choudhary,Dorit Merhof*

Main category: cs.CV

TL;DR: 提出了一种无示例的持续学习框架，用于从全切片图像生成病理报告，通过构建紧凑的领域足迹来避免灾难性遗忘，无需存储原始数据。


<details>
  <summary>Details</summary>
Motivation: 临床部署中，新的器官、机构和报告规范会随时间出现，传统的顺序微调会导致灾难性遗忘，而现有方法假设静态训练并同时访问所有数据，不适用于实际临床环境。

Method: 核心是构建紧凑的领域足迹：在冻结的补丁嵌入空间中，使用小型代表性形态标记码本、切片级共现摘要和轻量级补丁计数先验。通过生成式重放合成伪WSI表示，同时使用教师快照生成伪报告监督更新模型。为处理报告规范变化，将领域特定语言特征蒸馏到紧凑的风格描述符中。

Result: 在多个公开持续学习基准测试中，该方法优于无示例和有限缓冲区重放基线，展示了足迹基生成式重放在不断演化的临床环境中的实用性。

Conclusion: 提出的无示例持续学习框架通过紧凑领域足迹和生成式重放，有效解决了病理报告生成中的灾难性遗忘问题，为临床部署提供了实用解决方案。

Abstract: Rapid progress in vision-language modeling has enabled pathology report generation from gigapixel whole-slide images, but most approaches assume static training with simultaneous access to all data. In clinical deployment, however, new organs, institutions, and reporting conventions emerge over time, and sequential fine-tuning can cause catastrophic forgetting. We introduce an exemplar-free continual learning framework for WSI-to-report generation that avoids storing raw slides or patch exemplars. The core idea is a compact domain footprint built in a frozen patch-embedding space: a small codebook of representative morphology tokens together with slide-level co-occurrence summaries and lightweight patch-count priors. These footprints support generative replay by synthesizing pseudo-WSI representations that reflect domain-specific morphological mixtures, while a teacher snapshot provides pseudo-reports to supervise the updated model without retaining past data. To address shifting reporting conventions, we distill domain-specific linguistic characteristics into a compact style descriptor and use it to steer generation. At inference, the model identifies the most compatible descriptor directly from the slide signal, enabling domain-agnostic setup without requiring explicit domain identifiers. Evaluated across multiple public continual learning benchmarks, our approach outperforms exemplar-free and limited-buffer rehearsal baselines, highlighting footprint-based generative replay as a practical solution for deployment in evolving clinical settings.

</details>


### [29] [Denoising-Enhanced YOLO for Robust SAR Ship Detection](https://arxiv.org/abs/2602.23820)
*Xiaojing Zhao,Shiyang Li,Zena Chu,Ying Zhang,Peinan Hao,Tianzi Yan,Jiajia Chen,Huicong Ning*

Main category: cs.CV

TL;DR: CPN-YOLO：基于YOLOv8改进的高精度SAR图像船舶检测框架，通过可学习大核去噪模块、PPA注意力机制和NWD高斯相似度损失，在复杂场景下提升检测性能


<details>
  <summary>Details</summary>
Motivation: SAR图像船舶检测在复杂场景下面临挑战：杂波和斑点噪声导致误报，小目标容易漏检。现有方法在复杂场景下的鲁棒性不足，需要改进检测精度

Method: 1. 引入可学习大核去噪模块进行输入预处理，生成更干净的表示和更具区分性的特征；2. 基于PPA注意力机制设计特征提取增强策略，加强多尺度建模和小船敏感性；3. 采用基于归一化Wasserstein距离的高斯相似度损失，更好地处理复杂边界框分布

Result: 在HRSID和SSDD数据集上的实验表明，CPN-YOLO显著优于基线YOLOv8。在SSDD数据集上达到97.0%精确率、95.1%召回率和98.9% mAP，整体性能优于其他代表性深度学习检测器

Conclusion: CPN-YOLO通过针对性的改进有效解决了SAR图像船舶检测中的挑战，在复杂场景下实现了高精度检测，为SAR图像分析提供了有效的解决方案

Abstract: With the rapid advancement of deep learning, synthetic aperture radar (SAR) imagery has become a key modality for ship detection. However, robust performance remains challenging in complex scenes, where clutter and speckle noise can induce false alarms and small targets are easily missed. To address these issues, we propose CPN-YOLO, a high-precision ship detection framework built upon YOLOv8 with three targeted improvements. First, we introduce a learnable large-kernel denoising module for input pre-processing, producing cleaner representations and more discriminative features across diverse ship types. Second, we design a feature extraction enhancement strategy based on the PPA attention mechanism to strengthen multi-scale modeling and improve sensitivity to small ships. Third, we incorporate a Gaussian similarity loss derived from the normalized Wasserstein distance (NWD) to better measure similarity under complex bounding-box distributions and improve generalization. Extensive experiments on HRSID and SSDD demonstrate the effectiveness of our method. On SSDD, CPN-YOLO surpasses the YOLOv8 baseline, achieving 97.0% precision, 95.1% recall, and 98.9% mAP, and consistently outperforms other representative deep-learning detectors in overall performance.

</details>


### [30] [APPO: Attention-guided Perception Policy Optimization for Video Reasoning](https://arxiv.org/abs/2602.23823)
*Henghui Du,Chang Zhou,Xi Chen,Di Hu*

Main category: cs.CV

TL;DR: 该论文发现复杂视频推理中感知能力比推理能力更重要，提出了APPO算法通过注意力引导优化感知令牌来提升模型细粒度感知能力，在多个基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 研究发现复杂视频推理过度依赖细粒度感知而非专家级推理能力。当感知能力基本固定时，提升推理能力（从Qwen3-8B到OpenAI-o3）仅带来0.7%性能提升；而感知模型规模微小变化（从7B到32B）却能带来1.4%性能提升，表明增强感知比增强推理对性能提升更关键。因此需要探索如何通过推理增强感知能力，同时避免昂贵的细粒度标注成本。

Method: 提出了APPO（Attention-guided Perception Policy Optimization）算法，利用令牌级密集奖励来提升模型的细粒度感知能力。核心思想是优化那些来自不同响应但主要关注相同关键视频帧的令牌（称为组内感知令牌）。通过注意力引导的策略优化来增强模型对视频关键帧的感知能力。

Result: 在多样化的视频基准测试和不同规模模型（3B/7B）上的实验结果表明，APPO一致性地优于GRPO和DAPO方法，性能提升幅度在0.5%到4%之间。证明了该方法能有效通过推理增强感知能力。

Conclusion: 该工作提供了一种有前景的低成本方法，通过推理有效增强模型的感知能力，能够服务于多样化的场景和需求。强调了在复杂视频推理任务中，提升感知能力比单纯增强推理能力更为重要。

Abstract: Complex video reasoning, actually, relies excessively on fine-grained perception rather than on expert (e.g., Ph.D, Science)-level reasoning. Through extensive empirical observation, we have recognized the critical impact of perception. In particular, when perception ability is almost fixed, enhancing reasoning from Qwen3-8B to OpenAI-o3 yields only 0.7% performance improvement. Conversely, even minimal change in perception model scale (from 7B to 32B) boosts performance by 1.4%, indicating enhancing perception, rather than reasoning, is more critical to improve performance. Therefore, exploring how to enhance perception ability through reasoning without the need for expensive fine-grained annotation information is worthwhile. To achieve this goal, we specially propose APPO, the Attention-guided Perception Policy Optimization algorithm that leverages token-level dense rewards to improve model's fine-grained perception. The core idea behind APPO is to optimize those tokens from different responses that primarily focus on the same crucial video frame (called intra-group perception tokens). Experimental results on diverse video benchmarks and models with different scales (3/7B) demonstrate APPO consistently outperforms GRPO and DAPO (0.5%~4%). We hope our work provides a promising approach to effectively enhance model's perception abilities through reasoning in a low-cost manner, serving diverse scenarios and demands.

</details>


### [31] [NAU-QMUL: Utilizing BERT and CLIP for Multi-modal AI-Generated Image Detection](https://arxiv.org/abs/2602.23863)
*Xiaoyu Guo,Arkaitz Zubiaga*

Main category: cs.CV

TL;DR: 提出多模态多任务模型检测AI生成图像并识别生成模型，使用BERT和CLIP编码器提取特征，通过跨模态融合和多任务损失函数，在竞赛中获得第五名。


<details>
  <summary>Details</summary>
Motivation: 为了检测AI生成的图像并识别生成这些图像的具体模型，需要开发有效的多模态检测方法。

Method: 使用预训练的BERT和CLIP Vision编码器分别提取文本和图像特征，采用跨模态特征融合和定制的多任务损失函数，并利用伪标签数据增强策略扩展训练数据集。

Result: 在CT2竞赛的Task A和Task B中均获得第五名，F1分数分别为83.16%和48.88%。

Conclusion: 提出的架构在AI生成内容检测方面具有有效性，在现实场景中有应用潜力。

Abstract: With the aim of detecting AI-generated images and identifying the specific models responsible for their generation, we propose a multi-modal multi-task model. The model leverages pre-trained BERT and CLIP Vision encoders for text and image feature extraction, respectively, and employs cross-modal feature fusion with a tailored multi-task loss function. Additionally, a pseudo-labeling-based data augmentation strategy was utilized to expand the training dataset with high-confidence samples. The model achieved fifth place in both Tasks A and B of the `CT2: AI-Generated Image Detection' competition, with F1 scores of 83.16\% and 48.88\%, respectively. These findings highlight the effectiveness of the proposed architecture and its potential for advancing AI-generated content detection in real-world scenarios. The source code for our method is published on https://github.com/xxxxxxxxy/AIGeneratedImageDetection.

</details>


### [32] [Altitude-Aware Visual Place Recognition in Top-Down View](https://arxiv.org/abs/2602.23872)
*Xingyu Shao,Mengfan He,Chunyu Li,Liangzheng Sun,Ziyang Meng*

Main category: cs.CV

TL;DR: 提出一种基于地面特征密度分析和图像分类的视觉地点识别方法，通过分析图像中地面特征密度估计相对高度，生成规范化查询图像，实现大高度变化下的空中视觉定位。


<details>
  <summary>Details</summary>
Motivation: 解决空中视觉地点识别在显著高度变化下的挑战，传统方法依赖气压高度计或ToF传感器，需要额外硬件，而单目度量深度估计方法精度有限，需要一种无需额外硬件的视觉解决方案。

Method: 通过分析图像中地面特征密度估计相对高度，基于相对高度进行图像裁剪生成规范化查询图像，然后采用基于分类的视觉地点识别策略进行定位。

Result: 在多种地形和高度条件下，该方法在高度估计和视觉地点识别方面均表现出高精度和鲁棒性。相比传统VPR检索，R@1和R@5分别提升29.85%和60.20%；相比单目度量深度估计方法，平均误差减少202.1米，R@1和R@5分别额外提升31.4%和44%。

Conclusion: 该方法建立了一个稳健的纯视觉三维视觉地点识别框架，为大高度变化和传感器受限条件下的空中平台定位提供了实用且可扩展的解决方案。

Abstract: To address the challenge of aerial visual place recognition (VPR) problem under significant altitude variations, this study proposes an altitude-adaptive VPR approach that integrates ground feature density analysis with image classification techniques. The proposed method estimates airborne platforms' relative altitude by analyzing the density of ground features in images, then applies relative altitude-based cropping to generate canonical query images, which are subsequently used in a classification-based VPR strategy for localization. Extensive experiments across diverse terrains and altitude conditions demonstrate that the proposed approach achieves high accuracy and robustness in both altitude estimation and VPR under significant altitude changes. Compared to conventional methods relying on barometric altimeters or Time-of-Flight (ToF) sensors, this solution requires no additional hardware and offers a plug-and-play solution for downstream applications, {making it suitable for small- and medium-sized airborne platforms operating in diverse environments, including rural and urban areas.} Under significant altitude variations, incorporating our relative altitude estimation module into the VPR retrieval pipeline boosts average R@1 and R@5 by 29.85\% and 60.20\%, respectively, compared with applying VPR retrieval alone. Furthermore, compared to traditional {Monocular Metric Depth Estimation (MMDE) methods}, the proposed method reduces the mean error by 202.1 m, yielding average additional improvements of 31.4\% in R@1 and 44\% in R@5. These results demonstrate that our method establishes a robust, vision-only framework for three-dimensional visual place recognition, offering a practical and scalable solution for accurate airborne platforms localization under large altitude variations and limited sensor availability.

</details>


### [33] [Open-Vocabulary Semantic Segmentation in Remote Sensing via Hierarchical Attention Masking and Model Composition](https://arxiv.org/abs/2602.23869)
*Mohammadreza Heidarianbaei,Mareike Dorozynski,Hubert Kanyamahanga,Max Mehltretter,Franz Rottensteiner*

Main category: cs.CV

TL;DR: ReSeg-CLIP是一种无需训练的开放词汇遥感语义分割方法，通过SAM生成的掩码约束自注意力层交互，并组合多个遥感专用CLIP变体参数，在三个遥感基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 针对CLIP等视觉语言模型在语义分割任务中因自注意力层不适当交互导致的问题，特别是在遥感数据领域，需要一种无需额外训练就能提升开放词汇语义分割性能的方法。

Method: 1. 引入分层方案：利用SAM生成的掩码在多个尺度上约束自注意力层的交互；2. 模型组合方法：平均多个遥感专用CLIP变体的参数，采用新的加权方案评估不同文本提示下的表示质量。

Result: 该方法在三个遥感基准测试中取得了最先进的结果，且无需额外训练。

Conclusion: ReSeg-CLIP通过约束自注意力交互和组合多个CLIP变体，有效提升了遥感开放词汇语义分割性能，证明了训练无关方法的有效性。

Abstract: In this paper, we propose ReSeg-CLIP, a new training-free Open-Vocabulary Semantic Segmentation method for remote sensing data. To compensate for the problems of vision language models, such as CLIP in semantic segmentation caused by inappropriate interactions within the self-attention layers, we introduce a hierarchical scheme utilizing masks generated by SAM to constrain the interactions at multiple scales. We also present a model composition approach that averages the parameters of multiple RS-specific CLIP variants, taking advantage of a new weighting scheme that evaluates representational quality using varying text prompts. Our method achieves state-of-the-art results across three RS benchmarks without additional training.

</details>


### [34] [Ref-Adv: Exploring MLLM Visual Reasoning in Referring Expression Tasks](https://arxiv.org/abs/2602.23898)
*Qihua Dong,Kuo Yang,Lin Ju,Handong Zhao,Yitian Zhang,Yizhou Wang,Huimin Zeng,Jianglin Lu,Yun Fu*

Main category: cs.CV

TL;DR: 研究者提出了Ref-Adv基准测试，通过设计具有挑战性的语言表达和视觉干扰物来抑制现有REC基准中的捷径解决方案，从而更真实地评估多模态大模型的视觉推理和接地能力。


<details>
  <summary>Details</summary>
Motivation: 现有REC基准（RefCOCO、RefCOCO+、RefCOCOg）虽然推动了多模态LLMs的发展，但存在三个主要问题：1）许多表达过于简短，推理需求低；2）图像中干扰物少，目标容易识别；3）冗余描述符使模型可以通过捷径绕过真正的文本理解和视觉推理。这些基准不能充分测试模型的视觉推理和接地能力。

Method: 研究者创建了Ref-Adv基准，包含真实图像上的指代表达，通过精心设计具有挑战性的干扰物和包含否定等推理要素的标注来抑制捷径。进行了全面的消融实验（词序扰动和描述符删除充分性分析）来验证基准的严谨性，并评估了当代多模态LLMs在该基准上的表现。

Result: 尽管模型在RefCOCO、RefCOCO+和RefCOCOg上表现强劲，但在Ref-Adv上性能显著下降，揭示了模型对捷径的依赖以及在视觉推理和接地能力上的不足。研究者提供了深入的失败分析。

Conclusion: Ref-Adv基准能够更真实地评估多模态大模型的视觉推理和接地能力，揭示了现有模型在这些方面的局限性，旨在指导未来多模态LLMs在视觉推理和接地方面的研究工作。

Abstract: Referring Expression Comprehension (REC) links language to region level visual perception. Standard benchmarks (RefCOCO, RefCOCO+, RefCOCOg) have progressed rapidly with multimodal LLMs but remain weak tests of visual reasoning and grounding: (i) many expressions are very short, leaving little reasoning demand; (ii) images often contain few distractors, making the target easy to find; and (iii) redundant descriptors enable shortcut solutions that bypass genuine text understanding and visual reasoning. We introduce Ref-Adv, a modern REC benchmark that suppresses shortcuts by pairing linguistically nontrivial expressions with only the information necessary to uniquely identify the target. The dataset contains referring expressions on real images, curated with hard distractors and annotated with reasoning facets including negation. We conduct comprehensive ablations (word order perturbations and descriptor deletion sufficiency) to show that solving Ref-Adv requires reasoning beyond simple cues, and we evaluate a broad suite of contemporary multimodal LLMs on Ref-Adv. Despite strong results on RefCOCO, RefCOCO+, and RefCOCOg, models drop markedly on Ref-Adv, revealing reliance on shortcuts and gaps in visual reasoning and grounding. We provide an in depth failure analysis and aim for Ref-Adv to guide future work on visual reasoning and grounding in MLLMs.

</details>


### [35] [AgenticOCR: Parsing Only What You Need for Efficient Retrieval-Augmented Generation](https://arxiv.org/abs/2602.24134)
*Zhengren Wang,Dongsheng Ma,Huaping Zhong,Jiayu Li,Wentao Zhang,Bin Wang,Conghui He*

Main category: cs.CV

TL;DR: AgenticOCR是一种动态OCR解析范式，将传统静态OCR转变为查询驱动的按需提取系统，通过选择性识别感兴趣区域来优化视觉文档RAG系统的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 多模态检索增强生成在视觉文档处理中面临挑战：页面级分块检索会向生成器引入过多无关上下文，不仅过载注意力机制还稀释关键证据，同时将信息丰富的页面压缩到有限视觉token预算会增加幻觉风险。

Method: 提出AgenticOCR动态解析范式，通过"thinking with images"方式自主分析文档布局，识别并选择性识别感兴趣区域，实现按需视觉token解压缩，将检索粒度与刚性页面级分块解耦。

Result: 实验结果表明AgenticOCR提高了视觉RAG系统的效率和准确性，在长文档理解任务中达到专家级性能。

Conclusion: AgenticOCR有潜力成为视觉文档RAG堆栈的"第三个构建模块"，与标准嵌入和重排序模块协同工作，增强多模态文档处理能力。

Abstract: The expansion of retrieval-augmented generation (RAG) into multimodal domains has intensified the challenge for processing complex visual documents, such as financial reports. While page-level chunking and retrieval is a natural starting point, it creates a critical bottleneck: delivering entire pages to the generator introduces excessive extraneous context. This not only overloads the generator's attention mechanism but also dilutes the most salient evidence. Moreover, compressing these information-rich pages into a limited visual token budget further increases the risk of hallucinations. To address this, we introduce AgenticOCR, a dynamic parsing paradigm that transforms optical character recognition (OCR) from a static, full-text process into a query-driven, on-demand extraction system. By autonomously analyzing document layout in a "thinking with images" manner, AgenticOCR identifies and selectively recognizes regions of interest. This approach performs on-demand decompression of visual tokens precisely where needed, effectively decoupling retrieval granularity from rigid page-level chunking. AgenticOCR has the potential to serve as the "third building block" of the visual document RAG stack, operating alongside and enhancing standard Embedding and Reranking modules. Experimental results demonstrate that AgenticOCR improves both the efficiency and accuracy of visual RAG systems, achieving expert-level performance in long document understanding. Code and models are available at https://github.com/OpenDataLab/AgenticOCR.

</details>


### [36] [SelfOccFlow: Towards end-to-end self-supervised 3D Occupancy Flow prediction](https://arxiv.org/abs/2602.23894)
*Xavier Timoneda,Markus Herb,Fabian Duerr,Daniel Goehring*

Main category: cs.CV

TL;DR: 提出了一种用于3D占用流估计的自监督方法，无需人工标注或外部流监督，通过分离静态和动态场景并利用时间聚合学习运动


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要准确估计车辆周围的3D占用和运动，现有方法依赖昂贵的3D占用和流标注、速度标签或预训练光流模型，需要消除这些依赖

Method: 将场景解耦为静态和动态的有符号距离场，通过时间聚合隐式学习运动，并引入基于特征余弦相似度的自监督流线索

Result: 在SemanticKITTI、KITTI-MOT和nuScenes数据集上验证了方法的有效性

Conclusion: 提出的自监督3D占用流估计方法能够在不依赖人工标注或外部监督的情况下有效学习场景几何和运动

Abstract: Estimating 3D occupancy and motion at the vehicle's surroundings is essential for autonomous driving, enabling situational awareness in dynamic environments. Existing approaches jointly learn geometry and motion but rely on expensive 3D occupancy and flow annotations, velocity labels from bounding boxes, or pretrained optical flow models. We propose a self-supervised method for 3D occupancy flow estimation that eliminates the need for human-produced annotations or external flow supervision. Our method disentangles the scene into separate static and dynamic signed distance fields and learns motion implicitly through temporal aggregation. Additionally, we introduce a strong self-supervised flow cue derived from features' cosine similarities. We demonstrate the efficacy of our 3D occupancy flow method on SemanticKITTI, KITTI-MOT, and nuScenes.

</details>


### [37] [Experience-Guided Self-Adaptive Cascaded Agents for Breast Cancer Screening and Diagnosis with Reduced Biopsy Referrals](https://arxiv.org/abs/2602.23899)
*Pramit Saha,Mohammad Alsharid,Joshua Strong,J. Alison Noble*

Main category: cs.CV

TL;DR: BUSD-Agent是一个经验引导的级联多智能体框架，通过两阶段选择性决策流程减少乳腺超声筛查中的诊断升级和不必要活检转诊，利用记忆库中的历史决策轨迹进行检索条件化上下文适应。


<details>
  <summary>Details</summary>
Motivation: 减少乳腺超声筛查中的诊断升级和不必要活检转诊，降低医疗资源浪费和患者心理负担。

Method: 采用两阶段级联多智能体框架：1) 筛查诊所智能体使用分类模型筛选低风险病例；2) 高风险病例升级到诊断诊所智能体，集成更丰富的感知和放射学描述工具。利用记忆库存储历史决策轨迹，通过检索相似病例进行条件化上下文适应。

Result: 在10个乳腺超声数据集上的评估显示，相比无轨迹条件化的相同架构，BUSD-Agent将诊断升级率从84.95%降至58.72%，总体活检转诊率从59.50%降至37.08%，筛查特异性平均提高68.48%，诊断特异性提高6.33%。

Conclusion: 经验引导的级联多智能体框架能有效减少乳腺超声筛查中的过度诊断和不必要活检，通过检索条件化上下文适应实现动态调整模型信任和升级阈值，提高临床决策效率。

Abstract: We propose an experience-guided cascaded multi-agent framework for Breast Ultrasound Screening and Diagnosis, called BUSD-Agent, that aims to reduce diagnostic escalation and unnecessary biopsy referrals. Our framework models screening and diagnosis as a two-stage, selective decision-making process. A lightweight `screening clinic' agent, restricted to classification models as tools, selectively filters out benign and normal cases from further diagnostic escalation when malignancy risk and uncertainty are estimated as low. Cases that have higher risks are escalated to the `diagnostic clinic' agent, which integrates richer perception and radiological description tools to make a secondary decision on biopsy referral. To improve agent performance, past records of pathology-confirmed outcomes along with image embeddings, model predictions, and historical agent actions are stored in a memory bank as structured decision trajectories. For each new case, BUSD-Agent retrieves similar past cases based on image, model response and confidence similarity to condition the agent's current decision policy. This enables retrieval-conditioned in-context adaptation that dynamically adjusts model trust and escalation thresholds from prior experiences without parameter updates. Evaluation across 10 breast ultrasound datasets shows that the proposed experience-guided workflow reduces diagnostic escalation in BUSD-Agent from 84.95% to 58.72% and overall biopsy referrals from 59.50% to 37.08%, compared to the same architecture without trajectory conditioning, while improving average screening specificity by 68.48% and diagnostic specificity by 6.33%.

</details>


### [38] [Half-Truths Break Similarity-Based Retrieval](https://arxiv.org/abs/2602.23906)
*Bora Kargi,Arnas Uselis,Seong Joon Oh*

Main category: cs.CV

TL;DR: CLIP模型在图像-文本匹配中存在"半真"漏洞：给正确描述添加错误细节反而提高相似度得分，CS-CLIP通过组件监督训练解决此问题


<details>
  <summary>Details</summary>
Motivation: CLIP等双编码器模型在图像-文本相似度评估中存在反直觉现象：给正确描述添加错误细节反而提高相似度得分，这暴露了模型对文本组件（实体和关系）缺乏细粒度监督的问题

Method: 提出CS-CLIP（组件监督CLIP），将描述分解为实体和关系单元，为每个单元构建最小编辑的虚假版本，通过微调使模型正确单元得分高于虚假版本，同时保持标准双编码器推理

Result: 在COCO数据集上，CS-CLIP将半真准确率从40.6%提升到69.3%，在组合理解基准测试中平均性能提升5.7个百分点

Conclusion: 减少半真错误与提升组合理解能力一致，组件监督训练能有效改善CLIP模型对文本组件的细粒度理解，同时保持标准推理效率

Abstract: When a text description is extended with an additional detail, image-text similarity should drop if that detail is wrong. We show that CLIP-style dual encoders often violate this intuition: appending a plausible but incorrect object or relation to an otherwise correct description can increase the similarity score. We call such cases half-truths. On COCO, CLIP prefers the correct shorter description only 40.6% of the time, and performance drops to 32.9% when the added detail is a relation. We trace this vulnerability to weak supervision on caption parts: contrastive training aligns full sentences but does not explicitly enforce that individual entities and relations are grounded. We propose CS-CLIP (Component-Supervised CLIP), which decomposes captions into entity and relation units, constructs a minimally edited foil for each unit, and fine-tunes the model to score the correct unit above its foil while preserving standard dual-encoder inference. CS-CLIP raises half-truth accuracy to 69.3% and improves average performance on established compositional benchmarks by 5.7 points, suggesting that reducing half-truth errors aligns with broader gains in compositional understanding. Code is publicly available at: https://github.com/kargibora/CS-CLIP

</details>


### [39] [PointCoT: A Multi-modal Benchmark for Explicit 3D Geometric Reasoning](https://arxiv.org/abs/2602.23945)
*Dongxu Zhang,Yiding Sun,Pengcheng Li,Yumou Liu,Hongqiang Lin,Haoran Xu,Xiaoxuan Mu,Liang Lin,Wenbiao Yan,Ning Yang,Chaowei Fang,Juanjuan Zhao,Jihua Zhu,Conghui He,Cheng Tan*

Main category: cs.CV

TL;DR: PointCoT：一种通过显式思维链推理增强MLLMs在3D点云理解能力的新框架，采用"观察-思考-回答"范式，在预测答案前生成几何基础推理，显著减少几何幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在2D场景表现出色，但在3D点云理解方面存在局限。现有方法主要关注3D特征与预训练模型的对齐，将几何推理视为隐式映射过程，导致几何幻觉问题——模型会生成看似合理但缺乏精确结构细节基础的响应。

Method: 提出PointCoT框架，采用"观察-思考-回答"范式，监督模型在预测最终答案前生成几何基础推理。构建Point-Reason-Instruct大规模基准数据集（约86k指令调优样本，包含分层思维链标注）。采用双流多模态架构，协同整合语义外观与几何真值。

Result: PointCoT在复杂推理任务上实现了最先进的性能表现，通过显式思维链推理显著提升了3D点云理解的准确性和可靠性。

Conclusion: 通过引入显式思维链推理机制，PointCoT成功将MLLMs的感知智能扩展到3D点云理解，解决了现有方法中的几何幻觉问题，为3D场景理解提供了更可靠的基础。

Abstract: While Multimodal Large Language Models (MLLMs) demonstrate proficiency in 2D scenes, extending their perceptual intelligence to 3D point cloud understanding remains a significant challenge. Current approaches focus primarily on aligning 3D features with pre-trained models. However, they typically treat geometric reasoning as an implicit mapping process. These methods bypass intermediate logical steps and consequently suffer from geometric hallucinations. They confidently generate plausible responses that fail to ground in precise structural details. To bridge this gap, we present PointCoT, a novel framework that empowers MLLMs with explicit Chain-of-Thought (CoT) reasoning for 3D data. We advocate for a \textit{Look, Think, then Answer} paradigm. In this approach, the model is supervised to generate geometry-grounded rationales before predicting final answers. To facilitate this, we construct Point-Reason-Instruct, a large-scale benchmark comprising $\sim$86k instruction-tuning samples with hierarchical CoT annotations. By leveraging a dual-stream multi-modal architecture, our method synergizes semantic appearance with geometric truth. Extensive experiments demonstrate that PointCoT achieves state-of-the-art performance on complex reasoning tasks.

</details>


### [40] [CC-VQA: Conflict- and Correlation-Aware Method for Mitigating Knowledge Conflict in Knowledge-Based Visual Question Answering](https://arxiv.org/abs/2602.23952)
*Yuyang Hong,Jiaqi Gu,Yujin Lou,Lubin Fan,Qi Yang,Ying Wang,Kun Ding,Yue Wu,Shiming Xiang,Jieping Ye*

Main category: cs.CV

TL;DR: 提出CC-VQA方法，通过视觉中心冲突推理和相关性引导编解码，解决KB-VQA中静态模型知识与动态检索信息之间的冲突问题，无需训练即可提升性能。


<details>
  <summary>Details</summary>
Motivation: KB-VQA中视觉语言模型的静态参数知识与动态检索信息之间存在冲突，导致模型要么忽略检索上下文，要么与参数知识整合不一致。现有方法主要从语言角度出发，忽略了视觉信息在冲突中的关键作用，且检索上下文冗余影响冲突识别和缓解效果。

Method: 提出CC-VQA方法，包含两个核心组件：1) 视觉中心上下文冲突推理，在内部和外部知识上下文中进行视觉语义冲突分析；2) 相关性引导编码和解码，包括对低相关性语句的位置编码压缩，以及使用相关性加权冲突评分的自适应解码。

Result: 在E-VQA、InfoSeek和OK-VQA基准测试中，CC-VQA实现了最先进的性能，相比现有方法绝对准确率提升3.3%到6.4%。

Conclusion: CC-VQA通过视觉中心冲突分析和相关性引导机制，有效解决了KB-VQA中的知识冲突问题，无需训练即可显著提升性能，为知识密集型视觉问答任务提供了有效的解决方案。

Abstract: Knowledge-based visual question answering (KB-VQA) demonstrates significant potential for handling knowledge-intensive tasks. However, conflicts arise between static parametric knowledge in vision language models (VLMs) and dynamically retrieved information due to the static model knowledge from pre-training. The outputs either ignore retrieved contexts or exhibit inconsistent integration with parametric knowledge, posing substantial challenges for KB-VQA. Current knowledge conflict mitigation methods primarily adapted from language-based approaches, focusing on context-level conflicts through engineered prompting strategies or context-aware decoding mechanisms. However, these methods neglect the critical role of visual information in conflicts and suffer from redundant retrieved contexts, which impair accurate conflict identification and effective mitigation. To address these limitations, we propose \textbf{CC-VQA}: a novel training-free, conflict- and correlation-aware method for KB-VQA. Our method comprises two core components: (1) Vision-Centric Contextual Conflict Reasoning, which performs visual-semantic conflict analysis across internal and external knowledge contexts; and (2) Correlation-Guided Encoding and Decoding, featuring positional encoding compression for low-correlation statements and adaptive decoding using correlation-weighted conflict scoring. Extensive evaluations on E-VQA, InfoSeek, and OK-VQA benchmarks demonstrate that CC-VQA achieves state-of-the-art performance, yielding absolute accuracy improvements of 3.3\% to 6.4\% compared to existing methods. Code is available at https://github.com/cqu-student/CC-VQA.

</details>


### [41] [GDA-YOLO11: Amodal Instance Segmentation for Occlusion-Robust Robotic Fruit Harvesting](https://arxiv.org/abs/2602.23953)
*Caner Beldek,Emre Sariyildiz,Son Lam Phung,Gursel Alici*

Main category: cs.CV

TL;DR: 提出GDA-YOLO11模型用于水果采摘中的遮挡处理，通过非模态分割和欧几里得距离变换实现遮挡区域的水果定位，在柑橘数据集上性能优于YOLO11n，在模拟遮挡环境中取得良好采摘成功率。


<details>
  <summary>Details</summary>
Motivation: 遮挡是机器人水果采摘中的关键挑战，未检测或定位不准确的水果会导致大量作物损失。现有方法在处理遮挡水果时存在局限性，需要更鲁棒的感知系统。

Method: 提出基于GDA-YOLO11的采摘框架，该模型包含架构改进和更新的非对称掩码损失。使用改进的公共柑橘数据集训练，通过非模态实例分割推断完整水果掩码（包括不可见区域），然后使用欧几里得距离变换估计采摘点，最后将点投影到3D坐标进行机器人采摘执行。

Result: GDA-YOLO11达到精度0.844、召回率0.846、mAP@50为0.914、mAP@50:95为0.636，在精度、mAP@50和mAP@50:95上分别比YOLO11n提升5.1%、1.3%和1.0%。框架在零到高遮挡水平下的采摘成功率分别为92.59%、85.18%、48.14%和22.22%，在中高遮挡下成功率提升3.5%。

Conclusion: GDA-YOLO11增强了遮挡鲁棒性分割，简化了感知到动作的集成，为农业中更可靠的自主系统铺平了道路。这是首个在机器人水果采摘中实际演示非模态实例分割的研究。

Abstract: Occlusion remains a critical challenge in robotic fruit harvesting, as undetected or inaccurately localised fruits often results in substantial crop losses. To mitigate this issue, we propose a harvesting framework using a new amodal segmentation model, GDA-YOLO11, which incorporates architectural improvements and an updated asymmetric mask loss. The proposed model is trained on a modified version of a public citrus dataset and evaluated on both the base dataset and occlusion-sensitive subsets with varying occlusion levels. Within the framework, full fruit masks, including invisible regions, are inferred by GDA-YOLO11, and picking points are subsequently estimated using the Euclidean distance transform. These points are then projected into 3D coordinates for robotic harvesting execution. Experiments were conducted using real citrus fruits in a controlled environment simulating occlusion scenarios. Notably, to the best of our knowledge, this study provides the first practical demonstration of amodal instance segmentation in robotic fruit harvesting. GDA-YOLO11 achieves a precision of 0.844, recall of 0.846, mAP@50 of 0.914, and mAP@50:95 of 0.636, outperforming YOLO11n by 5.1%, 1.3%, and 1.0% in precision, mAP@50, and mAP@50:95, respectively. The framework attains harvesting success rates of 92.59%, 85.18%, 48.14%, and 22.22% at zero to high occlusion levels, improving success by 3.5% under medium and high occlusion. These findings demonstrate that GDA-YOLO11 enhances occlusion robust segmentation and streamlines perception-to-action integration, paving the way for more reliable autonomous systems in agriculture.

</details>


### [42] [SwitchCraft: Training-Free Multi-Event Video Generation with Attention Controls](https://arxiv.org/abs/2602.23956)
*Qianxun Xu,Chenxi Song,Yujun Cai,Chi Zhang*

Main category: cs.CV

TL;DR: SwitchCraft是一个无需训练的多事件视频生成框架，通过事件对齐查询引导和自适应平衡强度求解器解决现有文本到视频扩散模型在多事件提示下产生混合或崩溃场景的问题。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频扩散模型主要针对单事件生成进行优化，在处理多事件提示时，由于缺乏明确的时间定位，往往会产生混合或崩溃的场景，破坏了预期的叙事结构。

Method: 提出SwitchCraft框架，包含两个核心组件：1) 事件对齐查询引导(EAQS)，引导帧级注意力与相关事件提示对齐；2) 自适应平衡强度求解器(ABSS)，自适应平衡引导强度以保持时间一致性和视觉保真度。

Result: 大量实验表明，SwitchCraft在提示对齐、事件清晰度和场景一致性方面相比现有基线方法有显著提升。

Conclusion: SwitchCraft为多事件视频生成提供了一个简单而有效的解决方案，无需额外训练即可显著改善多事件提示下的视频生成质量。

Abstract: Recent advances in text-to-video diffusion models have enabled high-fidelity and temporally coherent videos synthesis. However, current models are predominantly optimized for single-event generation. When handling multi-event prompts, without explicit temporal grounding, such models often produce blended or collapsed scenes that break the intended narrative. To address this limitation, we present SwitchCraft, a training-free framework for multi-event video generation. Our key insight is that uniform prompt injection across time ignores the correspondence between events and frames. To this end, we introduce Event-Aligned Query Steering (EAQS), which steers frame-level attention to align with relevant event prompts. Furthermore, we propose Auto-Balance Strength Solver (ABSS), which adaptively balances steering strength to preserve temporal consistency and visual fidelity. Extensive experiments demonstrate that SwitchCraft substantially improves prompt alignment, event clarity, and scene consistency compared with existing baselines, offering a simple yet effective solution for multi-event video generation.

</details>


### [43] [Thinking with Images as Continuous Actions: Numerical Visual Chain-of-Thought](https://arxiv.org/abs/2602.23959)
*Kesen Zhao,Beier Zhu,Junbao Zhou,Xingyu Zhu,Zhongqi Yue,Hanwang Zhang*

Main category: cs.CV

TL;DR: NV-CoT是一个让多模态大语言模型使用连续数值坐标进行视觉推理的框架，通过将动作空间从离散词汇扩展到连续欧几里得空间，显著提高了定位精度和答案准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在模态不匹配、语义碎片化或粒度固定等问题，限制了精确区域选择和推理能力，需要一种更自然、更精确的视觉推理方法。

Method: 提出数值视觉思维链框架，将MLLM动作空间扩展到连续坐标空间，使用高斯或拉普拉斯策略生成边界框坐标，支持监督微调和强化学习，与GRPO风格策略优化完全兼容。

Result: 在三个基准测试中对比八个代表性视觉推理基线，NV-CoT显著提高了定位精度和最终答案准确性，同时加速了训练收敛。

Conclusion: 连续动作视觉推理在多模态大语言模型中具有有效性，为视觉推理提供了更精确、更自然的解决方案。

Abstract: Recent multimodal large language models (MLLMs) increasingly rely on visual chain-of-thought to perform region-grounded reasoning over images. However, existing approaches ground regions via either textified coordinates-causing modality mismatch and semantic fragmentation or fixed-granularity patches that both limit precise region selection and often require non-trivial architectural changes. In this paper, we propose Numerical Visual Chain-of-Thought (NV-CoT), a framework that enables MLLMs to reason over images using continuous numerical coordinates. NV-CoT expands the MLLM action space from discrete vocabulary tokens to a continuous Euclidean space, allowing models to directly generate bounding-box coordinates as actions with only minimal architectural modification. The framework supports both supervised fine-tuning and reinforcement learning. In particular, we replace categorical token policies with a Gaussian (or Laplace) policy over coordinates and introduce stochasticity via reparameterized sampling, making NV-CoT fully compatible with GRPO-style policy optimization. Extensive experiments on three benchmarks against eight representative visual reasoning baselines demonstrate that NV-CoT significantly improves localization precision and final answer accuracy, while also accelerating training convergence, validating the effectiveness of continuous-action visual reasoning in MLLMs. The code is available in https://github.com/kesenzhao/NV-CoT.

</details>


### [44] [Venus: Benchmarking and Empowering Multimodal Large Language Models for Aesthetic Guidance and Cropping](https://arxiv.org/abs/2602.23980)
*Tianxiang Du,Hulingxiao He,Yuxin Peng*

Main category: cs.CV

TL;DR: 该论文提出了AesGuide数据集和Venus框架，旨在解决智能手机摄影中普通用户与专业摄影师之间的美学指导差距，通过两阶段方法提升多模态大语言模型的美学指导能力，并在美学裁剪任务上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 智能手机摄影普及，但普通用户与专业摄影师之间存在明显差距，后者能在拍摄过程中识别美学问题并提供可操作的指导。现有多模态大语言模型主要提供过于积极的反馈，无法识别问题或提供可操作指导，缺乏美学指导能力。

Method: 1. 引入AesGuide数据集：包含10,748张照片，标注了美学评分、分析和指导；2. 提出Venus两阶段框架：第一阶段通过渐进复杂的美学问题赋予MLLMs美学指导能力；第二阶段通过基于CoT的推理激活其美学裁剪能力。

Result: Venus显著提升了美学指导能力，并在美学裁剪任务上取得了最先进的性能，实现了在照片创作两个阶段的可解释和交互式美学优化。

Conclusion: 该研究填补了计算美学中美学指导这一重要但未充分探索的领域，通过AesGuide数据集和Venus框架，使MLLMs能够提供专业的美学指导和裁剪建议，缩小了普通用户与专业摄影师之间的差距。

Abstract: The widespread use of smartphones has made photography ubiquitous, yet a clear gap remains between ordinary users and professional photographers, who can identify aesthetic issues and provide actionable shooting guidance during capture. We define this capability as aesthetic guidance (AG) -- an essential but largely underexplored domain in computational aesthetics. Existing multimodal large language models (MLLMs) primarily offer overly positive feedback, failing to identify issues or provide actionable guidance. Without AG capability, they cannot effectively identify distracting regions or optimize compositional balance, thus also struggling in aesthetic cropping, which aims to refine photo composition through reframing after capture. To address this, we introduce AesGuide, the first large-scale AG dataset and benchmark with 10,748 photos annotated with aesthetic scores, analyses, and guidance. Building upon it, we propose Venus, a two-stage framework that first empowers MLLMs with AG capability through progressively complex aesthetic questions and then activates their aesthetic cropping power via CoT-based rationales. Extensive experiments show that Venus substantially improves AG capability and achieves state-of-the-art (SOTA) performance in aesthetic cropping, enabling interpretable and interactive aesthetic refinement across both stages of photo creation. Code is available at https://github.com/PKU-ICST-MIPL/Venus_CVPR2026.

</details>


### [45] [Accelerating Masked Image Generation by Learning Latent Controlled Dynamics](https://arxiv.org/abs/2602.23996)
*Kaiwen Zhu,Quansheng Zeng,Yuandong Pu,Shuo Cao,Xiaohui Li,Yi Xin,Qi Qin,Jiayang Li,Yu Qiao,Jinjin Gu,Yihao Liu*

Main category: cs.CV

TL;DR: 提出MIGM-Shortcut方法，通过轻量级模型学习特征演化的平均速度场，在保持生成质量的同时实现4倍加速


<details>
  <summary>Details</summary>
Motivation: 掩码图像生成模型存在计算冗余问题：采样离散令牌时会丢失连续特征的丰富语义；现有缓存特征方法在激进加速率下近似误差较大

Method: 学习一个轻量级模型，结合先前特征和采样令牌，回归特征演化的平均速度场；模型复杂度适中，能捕捉微妙动态同时保持轻量

Result: 在Lumina-DiMOO上实现文本到图像生成超过4倍加速，同时保持生成质量，显著推进掩码图像生成的帕累托前沿

Conclusion: MIGM-Shortcut方法有效解决了掩码图像生成模型的计算效率问题，在保持质量的同时实现显著加速

Abstract: Masked Image Generation Models (MIGMs) have achieved great success, yet their efficiency is hampered by the multiple steps of bi-directional attention. In fact, there exists notable redundancy in their computation: when sampling discrete tokens, the rich semantics contained in the continuous features are lost. Some existing works attempt to cache the features to approximate future features. However, they exhibit considerable approximation error under aggressive acceleration rates. We attribute this to their limited expressivity and the failure to account for sampling information. To fill this gap, we propose to learn a lightweight model that incorporates both previous features and sampled tokens, and regresses the average velocity field of feature evolution. The model has moderate complexity that suffices to capture the subtle dynamics while keeping lightweight compared to the original base model. We apply our method, MIGM-Shortcut, to two representative MIGM architectures and tasks. In particular, on the state-of-the-art Lumina-DiMOO, it achieves over 4x acceleration of text-to-image generation while maintaining quality, significantly pushing the Pareto frontier of masked image generation. The code and model weights are available at https://github.com/Kaiwen-Zhu/MIGM-Shortcut.

</details>


### [46] [Ordinal Diffusion Models for Color Fundus Images](https://arxiv.org/abs/2602.24013)
*Gustav Schmidt,Philipp Berens,Sarah Müller*

Main category: cs.CV

TL;DR: 提出了一种序数潜在扩散模型，用于生成糖尿病视网膜病变（DR）的彩色眼底图像，该模型将DR严重程度的顺序结构显式地整合到生成过程中，实现了相邻阶段间的平滑过渡。


<details>
  <summary>Details</summary>
Motivation: 当前大多数条件扩散模型将疾病阶段视为独立类别，忽略了疾病进展的连续性本质。这种不匹配在医学成像中存在问题，因为连续的病理过程通常只能通过粗粒度、离散但有序的标签来观察，如糖尿病视网膜病变（DR）的分级。

Method: 提出了一种序数潜在扩散模型，使用标量疾病表示代替分类条件，将DR严重程度的顺序结构显式地整合到生成过程中，实现了相邻疾病阶段间的平滑过渡。

Result: 在EyePACS数据集上的评估显示，与标准条件扩散模型相比，该模型在五个DR阶段中的四个阶段降低了Fréchet起始距离，并将二次加权κ从0.79提高到0.87。插值实验表明模型能够从有序的粗粒度类别标签中学习到连续的疾病进展谱。

Conclusion: 序数潜在扩散模型能够更好地捕捉疾病进展的连续性，为医学图像生成提供了更符合临床实际的方法，特别是在处理有序疾病阶段标签时表现出优越性能。

Abstract: It has been suggested that generative image models such as diffusion models can improve performance on clinically relevant tasks by offering deep learning models supplementary training data. However, most conditional diffusion models treat disease stages as independent classes, ignoring the continuous nature of disease progression. This mismatch is problematic in medical imaging because continuous pathological processes are typically only observed through coarse, discrete but ordered labels as in ophthalmology for diabetic retinopathy (DR). We propose an ordinal latent diffusion model for generating color fundus images that explicitly incorporates the ordered structure of DR severity into the generation process. Instead of categorical conditioning, we used a scalar disease representation, enabling a smooth transition between adjacent stages. We evaluated our approach using visual realism metrics and classification-based clinical consistency analysis on the EyePACS dataset. Compared to a standard conditional diffusion model, our model reduced the Fréchet inception distance for four of the five DR stages and increased the quadratic weighted $κ$ from 0.79 to 0.87. Furthermore, interpolation experiments showed that the model captured a continuous spectrum of disease progression learned from ordered, coarse class labels.

</details>


### [47] [Interpretable Debiasing of Vision-Language Models for Social Fairness](https://arxiv.org/abs/2602.24014)
*Na Min An,Yoonna Jang,Yusuke Hirota,Ryo Hachiuma,Isabelle Augenstein,Hyunjung Shim*

Main category: cs.CV

TL;DR: DeBiasLens：一种通过稀疏自编码器定位视觉语言模型中社会属性神经元，并选择性去激活来缓解偏见的可解释、模型无关的偏见缓解框架


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型的黑盒推理过程可能导致意外的社会偏见，现有方法仅缓解表面偏见信号，未深入探索模型内部动态

Method: 使用稀疏自编码器在多模态编码器上定位社会属性神经元，通过无标签的面部图像或字幕数据集训练，选择性去激活与偏见最相关的神经元

Result: 有效缓解视觉语言模型的社会偏见行为，同时不损害其语义知识，为未来审计工具奠定基础

Conclusion: DeBiasLens框架为新兴AI系统的社会公平性提供了可解释的偏见缓解方法，为未来审计工具开发奠定基础

Abstract: The rapid advancement of Vision-Language models (VLMs) has raised growing concerns that their black-box reasoning processes could lead to unintended forms of social bias. Current debiasing approaches focus on mitigating surface-level bias signals through post-hoc learning or test-time algorithms, while leaving the internal dynamics of the model largely unexplored. In this work, we introduce an interpretable, model-agnostic bias mitigation framework, DeBiasLens, that localizes social attribute neurons in VLMs through sparse autoencoders (SAEs) applied to multimodal encoders. Building upon the disentanglement ability of SAEs, we train them on facial image or caption datasets without corresponding social attribute labels to uncover neurons highly responsive to specific demographics, including those that are underrepresented. By selectively deactivating the social neurons most strongly tied to bias for each group, we effectively mitigate socially biased behaviors of VLMs without degrading their semantic knowledge. Our research lays the groundwork for future auditing tools, prioritizing social fairness in emerging real-world AI systems.

</details>


### [48] [Steering and Rectifying Latent Representation Manifolds in Frozen Multi-modal LLMs for Video Anomaly Detection](https://arxiv.org/abs/2602.24021)
*Zhaolin Cai,Fan Li,Huiyu Duan,Lijun He,Guangtao Zhai*

Main category: cs.CV

TL;DR: SteerVAD：一种新的干预框架，通过主动引导和修正多模态大语言模型的内部表示来改进视频异常检测，仅需1%训练数据即可达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 传统视频异常检测方法需要大量标注数据和完整训练，成本高昂。现有的免调优MLLM方法直接继承预训练偏见，无法适应特定视频上下文，难以处理细微或模糊的异常。

Method: 提出SteerVAD框架：1）使用无梯度的表示可分性分析识别最具有判别性的注意力头作为潜在异常专家；2）设计分层元控制器，基于全局上下文和LAE输出生成动态修正信号；3）在LAE表示流形上执行有针对性的各向异性缩放，放大异常相关维度并抑制固有偏见。

Result: 在主流基准测试中，该方法在仅需1%训练数据的免调优方法中实现了最先进的性能。

Conclusion: SteerVAD通过从被动读取转向主动引导和修正内部表示，为视频异常检测提供了一个强大的新方向，有效解决了现有MLLM方法的局限性。

Abstract: Video anomaly detection (VAD) aims to identify abnormal events in videos. Traditional VAD methods generally suffer from the high costs of labeled data and full training, thus some recent works have explored leveraging frozen multi-modal large language models (MLLMs) in a tuning-free manner to perform VAD. However, their performance is limited as they directly inherit pre-training biases and cannot adapt internal representations to specific video contexts, leading to difficulties in handling subtle or ambiguous anomalies. To address these limitations, we propose a novel intervention framework, termed SteerVAD, which advances MLLM-based VAD by shifting from passively reading to actively steering and rectifying internal representations. Our approach first leverages the gradient-free representational separability analysis (RSA) to identify top attention heads as latent anomaly experts (LAEs) which are most discriminative for VAD. Then a hierarchical meta-controller (HMC) generates dynamic rectification signals by jointly conditioning on global context and these LAE outputs. The signals execute targeted, anisotropic scaling directly upon the LAE representation manifolds, amplifying anomaly-relevant dimensions while suppressing inherent biases. Extensive experiments on mainstream benchmarks demonstrate our method achieves state-of-the-art performance among tuning-free approaches requiring only 1% of training data, establishing it as a powerful new direction for video anomaly detection. The code will be released upon the publication.

</details>


### [49] [GuardAlign: Test-time Safety Alignment in Multimodal Large Language Models](https://arxiv.org/abs/2602.24027)
*Xingyu Zhu,Beier Zhu,Junfeng Fang,Shuo Wang,Yin Zhang,Xiang Wang,Xiangnan He*

Main category: cs.CV

TL;DR: GuardAlign是一个无需训练的防御框架，通过最优传输增强的安全检测和跨模态注意力校准，有效降低大型视觉语言模型的不安全响应率。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在视觉语言推理任务上取得了显著进展，但确保其安全性仍然是一个关键挑战。现有的输入侧防御方法使用CLIP检测不安全图像并在提示前添加安全前缀，但在复杂场景中检测不准确，且在解码过程中安全信号不稳定。

Method: GuardAlign采用两种策略：1）OT增强的安全检测，利用最优传输测量图像块与不安全语义之间的分布距离，无需额外计算成本即可准确识别恶意区域；2）跨模态注意力校准，通过自适应地在各层重新分配注意力来加强安全前缀的影响，确保安全信号在生成过程中持续激活。

Result: 在六个代表性多模态大语言模型上的广泛评估表明，GuardAlign在SPA-VL上将不安全响应率降低了高达39%，同时保持实用性，在VQAv2上从78.51%提升到79.21%。

Conclusion: GuardAlign是一个有效的训练免费防御框架，能够准确检测复杂场景中的不安全内容，并通过跨模态注意力校准确保安全信号的稳定性，显著提升大型视觉语言模型的安全性。

Abstract: Large vision-language models (LVLMs) have achieved remarkable progress in vision-language reasoning tasks, yet ensuring their safety remains a critical challenge. Recent input-side defenses detect unsafe images with CLIP and prepend safety prefixes to prompts, but they still suffer from inaccurate detection in complex scenes and unstable safety signals during decoding. To address these issues, we propose GuardAlign, a training-free defense framework that integrates two strategies. First, OT-enhanced safety detection leverages optimal transport to measure distribution distances between image patches and unsafe semantics, enabling accurate identification of malicious regions without additional computational cost. Second, cross-modal attentive calibration strengthens the influence of safety prefixes by adaptively reallocating attention across layers, ensuring that safety signals remain consistently activated throughout generation. Extensive evaluations on six representative MLLMs demonstrate that GuardAlign reduces unsafe response rates by up to 39% on SPA-VL, while preserving utility, achieving an improvement on VQAv2 from 78.51% to 79.21%.

</details>


### [50] [Look Carefully: Adaptive Visual Reinforcements in Multimodal Large Language Models for Hallucination Mitigation](https://arxiv.org/abs/2602.24041)
*Xingyu Zhu,Kesen Zhao,Liang Yi,Shuo Wang,Zhicai Wang,Beier Zhu,Hanwang Zhang*

Main category: cs.CV

TL;DR: 提出自适应视觉增强(AIR)框架，无需训练即可减少多模态大语言模型的幻觉问题，通过原型化token压缩和最优传输引导的patch增强来选择性强化关键视觉信息。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉语言推理方面取得显著进展，但仍存在幻觉问题，生成的文本内容偏离视觉证据。现有缓解策略要么需要昂贵的训练监督，要么在推理时引入额外延迟。最近的视觉增强方法试图通过强化解码过程中的视觉token来解决这个问题，但它们通常不加区分地注入所有token，导致背景区域干扰并分散模型对关键线索的注意力。

Method: 提出自适应视觉增强(AIR)框架，包含两个组件：1) 基于原型的token压缩：将大量视觉token压缩为紧凑子集以抑制冗余；2) OT引导的patch增强：量化隐藏状态与patch嵌入之间的对齐程度，选择性地将最一致的patch集成到前馈层中。

Result: 在代表性多模态大语言模型上的广泛实验表明，AIR显著减少了幻觉问题，同时保留了一般能力，证明其是构建可靠多模态大语言模型的有效解决方案。

Conclusion: AIR是一个无需训练的多模态大语言模型框架，通过选择性增强关键视觉信息来有效缓解幻觉问题，在保持模型通用能力的同时提高了可靠性。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable progress in vision-language reasoning, yet they remain vulnerable to hallucination, where generated content deviates from visual evidence. Existing mitigation strategies either require costly supervision during training or introduce additional latency at inference time. Recent vision enhancement methods attempt to address this issue by reinforcing visual tokens during decoding, but they typically inject all tokens indiscriminately, which causes interference from background regions and distracts the model from critical cues. To overcome this challenge, we propose Adaptive Visual Reinforcement (AIR), a training-free framework for MLLMs. AIR consists of two components. Prototype-based token reduction condenses the large pool of visual tokens into a compact subset to suppress redundancy. OT-guided patch reinforcement quantifies the alignment between hidden states and patch embeddings to selectively integrate the most consistent patches into feed-forward layers. As a result, AIR enhances the model's reliance on salient visual information and effectively mitigates hallucination. Extensive experiments across representative MLLMs demonstrate that AIR substantially reduces hallucination while preserving general capabilities, establishing it as an effective solution for building reliable MLLMs.

</details>


### [51] [Spatio-Temporal Garment Reconstruction Using Diffusion Mapping via Pattern Coordinates](https://arxiv.org/abs/2602.24043)
*Yingxuan You,Ren Li,Corentin Dumery,Cong Cao,Hao Li,Pascal Fua*

Main category: cs.CV

TL;DR: 提出统一框架，从单张图像和视频序列重建高保真3D服装，结合隐式缝纫模式和生成扩散模型，在2D UV空间学习服装形状先验，实现准确详细的服装重建。


<details>
  <summary>Details</summary>
Motivation: 从单目图像和视频重建3D着装人体是虚拟试穿、虚拟人创建和混合现实应用的基础问题。尽管人体恢复取得显著进展，但准确重建服装几何（特别是宽松服装）仍然是一个开放挑战。

Method: 结合隐式缝纫模式（ISP）与生成扩散模型，在2D UV空间学习表达性服装形状先验；引入映射模型建立图像像素、UV图案坐标和3D几何之间的对应关系；扩展到动态重建时，引入时空扩散方案和测试时指导以保持长期时间一致性；开发基于分析的投影约束，在可见区域保持图像对齐几何，同时在遮挡区域随时间强制执行一致补全。

Result: 尽管仅在合成模拟布料数据上训练，但方法能很好地泛化到真实世界图像，在紧身和宽松服装上都持续优于现有方法。重建的服装保留精细几何细节，同时展现逼真的动态运动。

Conclusion: 该方法支持纹理编辑、服装重定向和动画等下游应用，为从单目图像和视频重建高保真3D服装提供了有效的统一框架。

Abstract: Reconstructing 3D clothed humans from monocular images and videos is a fundamental problem with applications in virtual try-on, avatar creation, and mixed reality. Despite significant progress in human body recovery, accurately reconstructing garment geometry, particularly for loose-fitting clothing, remains an open challenge. We propose a unified framework for high-fidelity 3D garment reconstruction from both single images and video sequences. Our approach combines Implicit Sewing Patterns (ISP) with a generative diffusion model to learn expressive garment shape priors in 2D UV space. Leveraging these priors, we introduce a mapping model that establishes correspondences between image pixels, UV pattern coordinates, and 3D geometry, enabling accurate and detailed garment reconstruction from single images. We further extend this formulation to dynamic reconstruction by introducing a spatio-temporal diffusion scheme with test-time guidance to enforce long-range temporal consistency. We also develop analytic projection-based constraints that preserve image-aligned geometry in visible regions while enforcing coherent completion in occluded areas over time. Although trained exclusively on synthetically simulated cloth data, our method generalizes well to real-world imagery and consistently outperforms existing approaches on both tight- and loose-fitting garments. The reconstructed garments preserve fine geometric detail while exhibiting realistic dynamic motion, supporting downstream applications such as texture editing, garment retargeting, and animation.

</details>


### [52] [Quant Experts: Token-aware Adaptive Error Reconstruction with Mixture of Experts for Large Vision-Language Models Quantization](https://arxiv.org/abs/2602.24059)
*Chenwei Jia,Baoting Li,Xuchong Zhang,Mingzhuo Wei,Bochen Lin,Hongbin Sun*

Main category: cs.CV

TL;DR: 本文提出QE方法，通过token感知的自适应误差补偿和专家混合机制来改进视觉语言模型的训练后量化，解决了现有方法忽视重要通道分布差异的问题。


<details>
  <summary>Details</summary>
Motivation: 现有PTQ方法主要依赖静态识别和全局补偿敏感或异常通道，但忽视了这些重要通道在不同输入间的分布差异，导致量化效果不理想。研究发现重要通道的分布和出现频率在不同模态和token间存在显著差异。

Method: 提出Quant Experts (QE)方法：1）将重要通道分为token无关和token相关两组；2）对前者设计共享专家，使用低秩适配器补偿全局量化误差；3）对后者设计路由专家，包含多个路由低秩适配器补偿与特定token相关的局部量化误差。

Result: 实验表明，QE在各种量化设置和模型规模（从2B到70B参数）下都能持续提升任务精度，同时保持与全精度模型相当的性能。

Conclusion: QE通过token感知的自适应误差补偿和专家混合机制，有效解决了视觉语言模型量化中重要通道分布差异的问题，显著提升了量化效果。

Abstract: Post-Training Quantization (PTQ) has emerged as an effective technique for alleviating the substantial computational and memory overheads of Vision-Language Models (VLMs) by compressing both weights and activations without retraining the full model. Existing PTQ methods primarily rely on static identification and global compensation of sensitive or outlier channels, yet they often overlook the distributional differences of these important channels across inputs, leading to unsatisfactory quantization. In this work, we observe that the distributions and occurrence frequencies of important channels vary significantly both across modalities and among tokens, even within the same modality. Accordingly, we propose \textbf{Quant Experts (QE)}, a token-aware adaptive error compensation with mixture-of-experts for VLMs quantization. QE divides the important channels into token-independent and token-dependent groups. For the former, a shared expert is designed for most tokens to compensate for global quantization error using a low-rank adapter. For the latter, routed experts including multiple routed low-rank adapters are elaborated to compensate for local quantization error related to specific tokens. Extensive experiments demonstrate that QE consistently enhances task accuracy across various quantization settings and model scales, ranging from 2B to 70B parameters, while maintaining performance comparable to full-precision models.

</details>


### [53] [EvalMVX: A Unified Benchmarking for Neural 3D Reconstruction under Diverse Multiview Setups](https://arxiv.org/abs/2602.24065)
*Zaiyan Yang,Jieji Ren,Xiangyi Wang,zonglin li,Xu Cao,Heng Guo,Zhanyu Ma,Boxin Shi*

Main category: cs.CV

TL;DR: EvalMVX是一个包含25个物体、8500张图像的真实世界数据集，用于同时评估多视角立体视觉(MVS)、多视角偏振形状重建(MVSfP)和多视角光度立体视觉(MVPS)三种技术，填补了现有数据集仅关注RGB输入的空白。


<details>
  <summary>Details</summary>
Motivation: 当前真实世界数据集主要关注基于RGB输入的多视角立体视觉(MVS)基准测试，而多视角光度立体视觉(MVPS)和多视角偏振形状重建(MVSfP)虽然在高保真表面重建和稀疏输入方面不可或缺，但尚未与MVS一起进行定量评估。需要确定不同MVX技术的工作范围。

Method: 提出EvalMVX数据集，包含25个物体，每个物体使用偏振相机在20个不同视角和17种光照条件（包括OLAT和自然光照）下拍摄，共8500张图像。每个物体都包含对齐的真实3D网格，便于同时定量评估MVX方法。

Result: 基于EvalMVX评估了近年来发表的13种MVX方法，记录了性能最佳的方法，并在不同几何细节和反射类型下识别了开放性问题。

Conclusion: EvalMVX数据集和基准测试结果有望激发多视角3D重建领域的未来研究，为同时评估MVS、MVSfP和MVPS技术提供了统一的平台。

Abstract: Recent advancements in neural surface reconstruction have significantly enhanced 3D reconstruction. However, current real world datasets mainly focus on benchmarking multiview stereo (MVS) based on RGB inputs. Multiview photometric stereo (MVPS) and multiview shape from polarization (MVSfP), though indispensable on high-fidelity surface reconstruction and sparse inputs, have not been quantitatively assessed together with MVS. To determine the working range of different MVX (MVS, MVSfP, and MVPS) techniques, we propose EvalMVX, a real-world dataset containing $25$ objects, each captured with a polarized camera under $20$ varying views and $17$ light conditions including OLAT and natural illumination, leading to $8,500$ images. Each object includes aligned ground-truth 3D mesh, facilitating quantitative benchmarking of MVX methods simultaneously. Based on our EvalMVX, we evaluate $13$ MVX methods published in recent years, record the best-performing methods, and identify open problems under diverse geometric details and reflectance types. We hope EvalMVX and the benchmarking results can inspire future research on multiview 3D reconstruction.

</details>


### [54] [DiffusionHarmonizer: Bridging Neural Reconstruction and Photorealistic Simulation with Online Diffusion Enhancer](https://arxiv.org/abs/2602.24096)
*Yuxuan Zhang,Katarína Tóthová,Zian Wang,Kangxue Yin,Haithem Turki,Riccardo de Lutio,Yen-Yu Chang,Or Litany,Sanja Fidler,Zan Gojcic*

Main category: cs.CV

TL;DR: DiffusionHarmonizer是一个在线生成增强框架，用于提升神经重建场景的渲染质量，解决新视角渲染中的伪影问题，并改善动态物体插入的真实感。


<details>
  <summary>Details</summary>
Motivation: 神经重建方法（如NeRF和3D高斯溅射）虽然能从真实世界数据自动生成各种场景，但在渲染新视角时经常出现伪影，并且难以真实地集成来自不同场景的动态物体，这限制了其在自主机器人（如自动驾驶车辆）仿真中的应用。

Method: 提出DiffusionHarmonizer框架，核心是一个单步时间条件增强器，从预训练的多步图像扩散模型转换而来，能够在单GPU上在线运行。通过定制数据管理流程构建合成-真实对，强调外观协调、伪影校正和光照真实感。

Result: 该系统能够将不完美场景的渲染转换为时间一致且更真实的输出，显著提升了仿真保真度，适用于研究和生产环境。

Conclusion: DiffusionHarmonizer是一个可扩展的系统，能够有效解决神经重建场景中的渲染质量问题，为自主机器人仿真提供了更高质量的视觉环境。

Abstract: Simulation is essential to the development and evaluation of autonomous robots such as self-driving vehicles. Neural reconstruction is emerging as a promising solution as it enables simulating a wide variety of scenarios from real-world data alone in an automated and scalable way. However, while methods such as NeRF and 3D Gaussian Splatting can produce visually compelling results, they often exhibit artifacts particularly when rendering novel views, and fail to realistically integrate inserted dynamic objects, especially when they were captured from different scenes. To overcome these limitations, we introduce DiffusionHarmonizer, an online generative enhancement framework that transforms renderings from such imperfect scenes into temporally consistent outputs while improving their realism. At its core is a single-step temporally-conditioned enhancer that is converted from a pretrained multi-step image diffusion model, capable of running in online simulators on a single GPU. The key to training it effectively is a custom data curation pipeline that constructs synthetic-real pairs emphasizing appearance harmonization, artifact correction, and lighting realism. The result is a scalable system that significantly elevates simulation fidelity in both research and production environments.

</details>


### [55] [FocusTrack: One-Stage Focus-and-Suppress Framework for 3D Point Cloud Object Tracking](https://arxiv.org/abs/2602.24133)
*Sifan Zhou,Jiahao Nie,Ziyu Zhao,Yichao Cao,Xiaobo Lu*

Main category: cs.CV

TL;DR: FocusTrack提出了一种单阶段3D点云目标跟踪框架，通过帧间运动建模和聚焦-抑制注意力机制统一运动-语义协同建模，解决了现有两阶段方法中的误差累积和计算瓶颈问题，在多个基准测试中达到SOTA性能且运行速度达105 FPS。


<details>
  <summary>Details</summary>
Motivation: 现有两阶段运动中心方法存在两个基本限制：1) 由于在运动估计前进行显式前景分割导致的解耦优化引起的误差累积；2) 顺序处理带来的计算瓶颈。需要一种更高效、更准确的3D点云跟踪方法。

Method: 提出FocusTrack单阶段跟踪框架，包含两个核心创新：1) 帧间运动建模(IMM)模块，使用时差孪生编码器捕捉相邻帧间的全局运动模式；2) 聚焦-抑制注意力机制，通过运动显著特征门控增强前景语义，并基于IMM的时序感知运动上下文抑制背景噪声，无需显式分割。

Result: 在KITTI、nuScenes和Waymo等主要3D跟踪基准测试中，FocusTrack实现了新的SOTA性能，同时以105 FPS的高速度运行。

Conclusion: FocusTrack通过统一运动-语义协同建模的单阶段范式，有效解决了现有两阶段方法的误差累积和计算瓶颈问题，在保持高运行速度的同时实现了最先进的跟踪性能。

Abstract: In 3D point cloud object tracking, the motion-centric methods have emerged as a promising avenue due to its superior performance in modeling inter-frame motion. However, existing two-stage motion-based approaches suffer from fundamental limitations: (1) error accumulation due to decoupled optimization caused by explicit foreground segmentation prior to motion estimation, and (2) computational bottlenecks from sequential processing. To address these challenges, we propose FocusTrack, a novel one-stage paradigms tracking framework that unifies motion-semantics co-modeling through two core innovations: Inter-frame Motion Modeling (IMM) and Focus-and-Suppress Attention. The IMM module employs a temp-oral-difference siamese encoder to capture global motion patterns between adjacent frames. The Focus-and-Suppress attention that enhance the foreground semantics via motion-salient feature gating and suppress the background noise based on the temporal-aware motion context from IMM without explicit segmentation. Based on above two designs, FocusTrack enables end-to-end training with compact one-stage pipeline. Extensive experiments on prominent 3D tracking benchmarks, such as KITTI, nuScenes, and Waymo, demonstrate that the FocusTrack achieves new SOTA performance while running at a high speed with 105 FPS.

</details>


### [56] [Prune Wisely, Reconstruct Sharply: Compact 3D Gaussian Splatting via Adaptive Pruning and Difference-of-Gaussian Primitives](https://arxiv.org/abs/2602.24136)
*Haoran Wang,Guoxi Huang,Fan Zhang,David Bull,Nantheera Anantrasirichai*

Main category: cs.CV

TL;DR: 提出一种高效的3D高斯泼溅优化方法，通过重建感知的剪枝策略和新型3D差分高斯基元，在保持视觉质量的同时将高斯数量减少高达90%。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅技术虽然实现了实时渲染和照片级真实感，但通常需要大量基元才能达到高保真度，导致冗余表示和高资源消耗，限制了其在复杂或大规模场景中的可扩展性。

Method: 1) 提出高效、集成的重建感知剪枝策略，根据重建质量自适应确定剪枝时机和细化间隔；2) 引入3D差分高斯基元，在单个基元中联合建模正负密度，提高紧凑配置下高斯的表达能力。

Result: 该方法显著提高了模型紧凑性，实现了高达90%的高斯数量减少，同时提供的视觉质量与最先进方法相似，在某些情况下甚至更好。

Conclusion: 通过重建感知剪枝和差分高斯基元的结合，有效解决了3D高斯泼溅的冗余问题，为实际部署提供了更高效的解决方案。

Abstract: Recent significant advances in 3D scene representation have been driven by 3D Gaussian Splatting (3DGS), which has enabled real-time rendering with photorealistic quality. 3DGS often requires a large number of primitives to achieve high fidelity, leading to redundant representations and high resource consumption, thereby limiting its scalability for complex or large-scale scenes. Consequently, effective pruning strategies and more expressive primitives that can reduce redundancy while preserving visual quality are crucial for practical deployment. We propose an efficient, integrated reconstruction-aware pruning strategy that adaptively determines pruning timing and refining intervals based on reconstruction quality, thus reducing model size while enhancing rendering quality. Moreover, we introduce a 3D Difference-of-Gaussians primitive that jointly models both positive and negative densities in a single primitive, improving the expressiveness of Gaussians under compact configurations. Our method significantly improves model compactness, achieving up to 90\% reduction in Gaussian-count while delivering visual quality that is similar to, or in some cases better than, that produced by state-of-the-art methods. Code will be made publicly available.

</details>


### [57] [Multimodal Optimal Transport for Unsupervised Temporal Segmentation in Surgical Robotics](https://arxiv.org/abs/2602.24138)
*Omar Mohamed,Edoardo Fazzari,Ayah Al-Naji,Hamdan Alhadhrami,Khalfan Hableel,Saif Alkindi,Cesare Stefanini*

Main category: cs.CV

TL;DR: TASOT是一种无监督的手术阶段和步骤识别方法，通过结合视频生成的文本信息，避免了大规模预训练的需求，在多个手术数据集上显著优于现有零样本方法。


<details>
  <summary>Details</summary>
Motivation: 当前手术视频识别方法依赖大规模预训练，计算和数据收集成本高昂。本文质疑这种重型预训练的必要性，探索是否可以利用视频中已有的视觉和文本信息实现有效的手术理解。

Method: 提出文本增强的动作分割最优传输（TASOT），将时序动作分割建模为多模态最优传输问题。匹配成本定义为视觉和文本成本的加权组合：视觉项捕捉帧级外观相似性，文本项提供补充语义线索，两者通过时间一致的不平衡Gromov-Wasserstein公式进行联合正则化。

Result: 在多个手术基准数据集上评估，TASOT相比现有零样本方法取得显著改进：StrasBypass70 (+23.7)、BernBypass70 (+4.5)、Cholec80 (+16.5)、AutoLaparo (+19.6)。

Conclusion: 通过利用标准视觉和文本表示中已有的信息，无需复杂预训练管道即可实现精细的手术理解。这挑战了当前依赖大规模预训练的主流方法，为手术视频分析提供了更高效、成本更低的替代方案。

Abstract: Recognizing surgical phases and steps from video is a fundamental problem in computer-assisted interventions. Recent approaches increasingly rely on large-scale pre-training on thousands of labeled surgical videos, followed by zero-shot transfer to specific procedures. While effective, this strategy incurs substantial computational and data collection costs. In this work, we question whether such heavy pre-training is truly necessary. We propose Text-Augmented Action Segmentation Optimal Transport (TASOT), an unsupervised method for surgical phase and step recognition that extends Action Segmentation Optimal Transport (ASOT) by incorporating textual information generated directly from the videos. TASOT formulates temporal action segmentation as a multimodal optimal transport problem, where the matching cost is defined as a weighted combination of visual and text-based costs. The visual term captures frame-level appearance similarity, while the text term provides complementary semantic cues, and both are jointly regularized through a temporally consistent unbalanced Gromov-Wasserstein formulation. This design enables effective alignment between video frames and surgical actions without surgical-specific pretraining or external web-scale supervision. We evaluate TASOT on multiple benchmark surgical datasets and observe consistent and substantial improvements over existing zero-shot methods, including StrasBypass70 (+23.7), BernBypass70 (+4.5), Cholec80 (+16.5), and AutoLaparo (+19.6). These results demonstrate that fine-grained surgical understanding can be achieved by exploiting information already present in standard visual and textual representations, without resorting to increasingly complex pre-training pipelines. The code will be available at https://github.com/omar8ahmed9/TASOT.

</details>


### [58] [Fixed Anchors Are Not Enough: Dynamic Retrieval and Persistent Homology for Dataset Distillation](https://arxiv.org/abs/2602.24144)
*Muquan Li,Hang Gou,Yingyi Ma,Rongzheng Wang,Ke Qin,Tao He*

Main category: cs.CV

TL;DR: RETA框架通过动态检索连接和持续拓扑对齐改进解耦数据集蒸馏，解决了现有方法中的拟合复杂度差距和锚点牵引效应问题，在多个数据集上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前解耦数据集蒸馏方法使用静态真实图像块，导致拟合复杂度差距和锚点牵引效应，降低了类内多样性和泛化能力。

Method: 提出RETA框架：1) 动态检索连接(DRC)从预建池中选择真实图像块，最小化教师特征空间的拟合复杂度分数；2) 持续拓扑对齐(PTA)使用持续同调正则化合成过程，构建互k-NN特征图并计算持久性图像，惩罚真实与合成集之间的拓扑差异。

Result: 在CIFAR-100、Tiny-ImageNet、ImageNet-1K等多个数据集上，RETA始终优于各种基线方法，在ImageNet-1K上达到64.3%的top-1准确率（每类50张图像，ResNet-18），比之前最佳方法提升3.1%。

Conclusion: RETA框架通过动态检索连接和持续拓扑对齐有效解决了现有解耦数据集蒸馏方法的局限性，显著提升了合成数据集的多样性和泛化能力。

Abstract: Decoupled dataset distillation (DD) compresses large corpora into a few synthetic images by matching a frozen teacher's statistics. However, current residual-matching pipelines rely on static real patches, creating a fit-complexity gap and a pull-to-anchor effect that reduce intra-class diversity and hurt generalization. To address these issues, we introduce RETA -- a Retrieval and Topology Alignment framework for decoupled DD. First, Dynamic Retrieval Connection (DRC) selects a real patch from a prebuilt pool by minimizing a fit-complexity score in teacher feature space; the chosen patch is injected via a residual connection to tighten feature fit while controlling injected complexity. Second, Persistent Topology Alignment (PTA) regularizes synthesis with persistent homology: we build a mutual k-NN feature graph, compute persistence images of components and loops, and penalize topology discrepancies between real and synthetic sets, mitigating pull-to-anchor effect. Across CIFAR-100, Tiny-ImageNet, ImageNet-1K, and multiple ImageNet subsets, RETA consistently outperforms various baselines under comparable time and memory, especially reaching 64.3% top-1 accuracy on ImageNet-1K with ResNet-18 at 50 images per class, +3.1% over the best prior.

</details>


### [59] [HumanOrbit: 3D Human Reconstruction as 360° Orbit Generation](https://arxiv.org/abs/2602.24148)
*Keito Suzuki,Kunyao Chen,Lei Wang,Bang Du,Runfa Blark Li,Peng Liu,Ning Bi,Truong Nguyen*

Main category: cs.CV

TL;DR: HumanOrbit：从单张图像生成360度环绕人物视频的扩散模型方法


<details>
  <summary>Details</summary>
Motivation: 现有方法基于图像扩散模型进行多视角合成，但存在视角间不一致和身份保持问题。视频扩散模型在生成逼真结果方面表现出色，因此探索将其用于多视角人物图像生成。

Method: 提出HumanOrbit视频扩散模型，能够合成围绕人物的连续相机旋转，生成几何一致的新视角同时保持人物外观和身份。进一步提出重建流程，从生成的多视角帧中恢复带纹理的网格模型。

Result: 实验验证了HumanOrbit在多视角图像生成方面的有效性，重建的3D模型在完整性和保真度方面优于现有最先进基线方法。

Conclusion: HumanOrbit能够从单张输入图像生成360度环绕人物视频，并在多视角一致性和身份保持方面表现出色，同时能够重建高质量的3D模型。

Abstract: We present a method for generating a full 360° orbit video around a person from a single input image. Existing methods typically adapt image-based diffusion models for multi-view synthesis, but yield inconsistent results across views and with the original identity. In contrast, recent video diffusion models have demonstrated their ability in generating photorealistic results that align well with the given prompts. Inspired by these results, we propose HumanOrbit, a video diffusion model for multi-view human image generation. Our approach enables the model to synthesize continuous camera rotations around the subject, producing geometrically consistent novel views while preserving the appearance and identity of the person. Using the generated multi-view frames, we further propose a reconstruction pipeline that recovers a textured mesh of the subject. Experimental results validate the effectiveness of HumanOrbit for multi-view image generation and that the reconstructed 3D models exhibit superior completeness and fidelity compared to those from state-of-the-art baselines.

</details>


### [60] [Manifold-Preserving Superpixel Hierarchies and Embeddings for the Exploration of High-Dimensional Images](https://arxiv.org/abs/2602.24160)
*Alexander Vieth,Boudewijn Lelieveldt,Elmar Eisemann,Anna Vilanova,Thomas Höllt*

Main category: cs.CV

TL;DR: 本文提出了一种考虑高维属性流形和图像空间布局的超像素层次结构，用于大规模高维图像的可视化探索，解决了传统层次嵌入方法忽略图像空间布局的问题。


<details>
  <summary>Details</summary>
Motivation: 当前高维图像（每像素具有高维属性向量）通常通过属性空间的低维嵌入和传统图像表示进行协调视图探索。对于数百万像素的大规模数据集，层次嵌入技术比平面降维方法更适合表示高维属性空间。然而，现有的层次降维方法仅基于属性信息构建层次结构，忽略了像素在图像中的空间布局，这阻碍了图像空间中感兴趣区域的探索，因为图像空间中的感兴趣区域与层次结构中的相关属性抽象之间缺乏一致性。

Method: 提出了一种超像素层次结构方法，该方法在构建过程中同时考虑高维属性流形和图像空间布局。通过这种方法，实现了高维图像在图像空间和属性空间中的一致探索。

Result: 在两个使用案例中，通过与传统基于层次嵌入的图像探索方法进行比较，展示了这种新的图像引导层次结构的有效性。

Conclusion: 提出的超像素层次结构方法能够更好地支持大规模高维图像的可视化探索，通过在层次构建中同时考虑属性信息和空间布局，实现了图像空间和属性空间之间更一致的探索体验。

Abstract: High-dimensional images, or images with a high-dimensional attribute vector per pixel, are commonly explored with coordinated views of a low-dimensional embedding of the attribute space and a conventional image representation. Nowadays, such images can easily contain several million pixels. For such large datasets, hierarchical embedding techniques are better suited to represent the high-dimensional attribute space than flat dimensionality reduction methods. However, available hierarchical dimensionality reduction methods construct the hierarchy purely based on the attribute information and ignore the spatial layout of pixels in the images. This impedes the exploration of regions of interest in the image space, since there is no congruence between a region of interest in image space and the associated attribute abstractions in the hierarchy. In this paper, we present a superpixel hierarchy for high-dimensional images that takes the high-dimensional attribute manifold into account during construction. Through this, our method enables consistent exploration of high-dimensional images in both image and attribute space. We show the effectiveness of this new image-guided hierarchy in the context of embedding exploration by comparing it with classical hierarchical embedding-based image exploration in two use cases.

</details>


### [61] [GeoDiff4D: Geometry-Aware Diffusion for 4D Head Avatar Reconstruction](https://arxiv.org/abs/2602.24161)
*Chao Xu,Xiaochen Zhao,Xiang Deng,Jingxiang Sun,Zhuo Su,Donglin Di,Yebin Liu*

Main category: cs.CV

TL;DR: 提出基于几何感知扩散模型的单图像4D头部化身重建框架，通过联合合成肖像图像和表面法线，结合3D高斯表示实现高质量、可动画的头部重建。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的化身重建方法主要依赖2D先验，难以实现一致的3D几何结构。从单张肖像图像重建逼真且可动画的4D头部化身仍然是计算机视觉中的基本挑战。

Method: 提出几何感知扩散框架，联合合成肖像图像和对应的表面法线；使用无姿态表情编码器捕捉隐式表情表示；将合成图像和表情潜在编码整合到基于3D高斯的化身中。

Result: 在视觉质量、表情保真度和跨身份泛化能力方面显著优于现有最先进方法，同时支持实时渲染。

Conclusion: 该框架通过几何感知扩散学习强大的几何先验，实现了从单张肖像图像重建高质量、可动画的4D头部化身，在多个评估指标上表现出色。

Abstract: Reconstructing photorealistic and animatable 4D head avatars from a single portrait image remains a fundamental challenge in computer vision. While diffusion models have enabled remarkable progress in image and video generation for avatar reconstruction, existing methods primarily rely on 2D priors and struggle to achieve consistent 3D geometry. We propose a novel framework that leverages geometry-aware diffusion to learn strong geometry priors for high-fidelity head avatar reconstruction. Our approach jointly synthesizes portrait images and corresponding surface normals, while a pose-free expression encoder captures implicit expression representations. Both synthesized images and expression latents are incorporated into 3D Gaussian-based avatars, enabling photorealistic rendering with accurate geometry. Extensive experiments demonstrate that our method substantially outperforms state-of-the-art approaches in visual quality, expression fidelity, and cross-identity generalization, while supporting real-time rendering.

</details>


### [62] [A Mixed Diet Makes DINO An Omnivorous Vision Encoder](https://arxiv.org/abs/2602.24181)
*Rishabh Kabra,Maks Ovsjanikov,Drew A. Hudson,Ye Xia,Skanda Koppula,Andre Araujo,Joao Carreira,Niloy J. Mitra*

Main category: cs.CV

TL;DR: 提出Omnivorous Vision Encoder框架，解决预训练视觉编码器（如DINOv2）在不同模态特征表示对齐不佳的问题，通过学习模态无关的特征空间，使编码器能够为同一场景的不同模态输入（RGB、深度、分割等）生成一致且强大的嵌入。


<details>
  <summary>Details</summary>
Motivation: 预训练的视觉编码器（如DINOv2）在单模态任务上表现出色，但研究发现它们的特征表示在不同模态之间对齐效果很差。例如，同一场景的RGB图像和其对应的深度图之间的特征嵌入余弦相似度几乎与两个随机不相关图像相同，这表明现有模型缺乏跨模态一致性。

Method: 提出Omnivorous Vision Encoder框架，采用双重训练目标：1）最大化同一场景不同模态之间的特征对齐；2）使用蒸馏目标将学习到的表示锚定到完全冻结的教师模型（如DINOv2）的输出。这种方法使学生编码器能够为给定场景生成一致的嵌入，无论输入模态如何。

Result: 训练得到的"全能"学生编码器能够为同一场景的不同模态输入（RGB、深度、分割等）产生一致且强大的特征嵌入，实现了稳健的跨模态理解，同时保留了原始基础模型的判别语义能力。

Conclusion: Omnivorous Vision Encoder通过双重训练目标成功解决了预训练视觉编码器跨模态特征对齐问题，创建了一个模态无关的特征空间，使模型能够处理多种输入模态并保持特征一致性，同时继承基础模型的强大语义表示能力。

Abstract: Pre-trained vision encoders like DINOv2 have demonstrated exceptional performance on unimodal tasks. However, we observe that their feature representations are poorly aligned across different modalities. For instance, the feature embedding for an RGB image and its corresponding depth map of the same scene exhibit a cosine similarity that is nearly identical to that of two random, unrelated images. To address this, we propose the Omnivorous Vision Encoder, a novel framework that learns a modality-agnostic feature space. We train the encoder with a dual objective: first, to maximize the feature alignment between different modalities of the same scene; and second, a distillation objective that anchors the learned representations to the output of a fully frozen teacher such as DINOv2. The resulting student encoder becomes "omnivorous" by producing a consistent, powerful embedding for a given scene, regardless of the input modality (RGB, Depth, Segmentation, etc.). This approach enables robust cross-modal understanding while retaining the discriminative semantics of the original foundation model.

</details>


### [63] [A multimodal slice discovery framework for systematic failure detection and explanation in medical image classification](https://arxiv.org/abs/2602.24183)
*Yixuan Liu,Kanwal K. Bhatia,Ahmed E. Fetit*

Main category: cs.CV

TL;DR: 提出了首个用于医学图像分类器的多模态自动审计框架，扩展了切片发现方法，在MIMIC-CXR-JPG数据集上验证了其在故障发现和解释生成方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管机器学习医学图像分类器取得进展，但其安全性和可靠性仍是实际应用中的主要问题。现有审计方法主要依赖单模态特征或基于元数据的子组分析，解释性有限且难以发现隐藏的系统性故障。

Method: 引入了首个自动审计框架，将切片发现方法扩展到多模态表示，专门针对医学应用。该框架利用多模态信息进行更全面的分类器审计。

Result: 在MIMIC-CXR-JPG数据集上进行了综合实验，展示了框架在故障发现和解释生成方面的强大能力。结果表明多模态信息通常能实现更全面有效的分类器审计，而图像之外的单模态变体在资源受限场景中显示出强大潜力。

Conclusion: 多模态审计框架能够更有效地发现和解释医学图像分类器的系统性故障，为实际应用中的安全性和可靠性提供了重要保障。

Abstract: Despite advances in machine learning-based medical image classifiers, the safety and reliability of these systems remain major concerns in practical settings. Existing auditing approaches mainly rely on unimodal features or metadata-based subgroup analyses, which are limited in interpretability and often fail to capture hidden systematic failures. To address these limitations, we introduce the first automated auditing framework that extends slice discovery methods to multimodal representations specifically for medical applications. Comprehensive experiments were conducted under common failure scenarios using the MIMIC-CXR-JPG dataset, demonstrating the framework's strong capability in both failure discovery and explanation generation. Our results also show that multimodal information generally allows more comprehensive and effective auditing of classifiers, while unimodal variants beyond image-only inputs exhibit strong potential in scenarios where resources are constrained.

</details>


### [64] [SenCache: Accelerating Diffusion Model Inference via Sensitivity-Aware Caching](https://arxiv.org/abs/2602.24208)
*Yasaman Haghighi,Alexandre Alahi*

Main category: cs.CV

TL;DR: SenCache：基于敏感度感知的动态缓存框架，通过分析扩散模型输出对去噪输入的敏感性，自适应选择缓存时间步，在保持视觉质量的同时加速视频生成推理。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在视频生成方面达到最先进质量，但其推理过程因需要大量顺序去噪步骤而计算昂贵。现有缓存方法依赖启发式标准选择缓存/重用时间步，需要大量调优，缺乏理论依据。

Method: 提出敏感性感知缓存框架，通过分析模型输出对噪声潜变量和时间步扰动的敏感性，将敏感性作为缓存误差的关键预测指标。基于此提出SenCache动态缓存策略，在每样本基础上自适应选择缓存时间步。

Result: 在Wan 2.1、CogVideoX和LTX-Video上的实验表明，在相似计算预算下，SenCache比现有缓存方法获得更好的视觉质量。

Conclusion: SenCache为自适应缓存提供了理论基础，解释了先前经验启发式方法为何部分有效，并将其扩展为动态、样本特定的方法，在保持视觉质量的同时加速扩散模型推理。

Abstract: Diffusion models achieve state-of-the-art video generation quality, but their inference remains expensive due to the large number of sequential denoising steps. This has motivated a growing line of research on accelerating diffusion inference. Among training-free acceleration methods, caching reduces computation by reusing previously computed model outputs across timesteps. Existing caching methods rely on heuristic criteria to choose cache/reuse timesteps and require extensive tuning. We address this limitation with a principled sensitivity-aware caching framework. Specifically, we formalize the caching error through an analysis of the model output sensitivity to perturbations in the denoising inputs, i.e., the noisy latent and the timestep, and show that this sensitivity is a key predictor of caching error. Based on this analysis, we propose Sensitivity-Aware Caching (SenCache), a dynamic caching policy that adaptively selects caching timesteps on a per-sample basis. Our framework provides a theoretical basis for adaptive caching, explains why prior empirical heuristics can be partially effective, and extends them to a dynamic, sample-specific approach. Experiments on Wan 2.1, CogVideoX, and LTX-Video show that SenCache achieves better visual quality than existing caching methods under similar computational budgets.

</details>


### [65] [MuViT: Multi-Resolution Vision Transformers for Learning Across Scales in Microscopy](https://arxiv.org/abs/2602.24222)
*Albert Dominguez Mantes,Gioele La Manno,Martin Weigert*

Main category: cs.CV

TL;DR: MuViT是一种用于多分辨率显微镜图像分析的Transformer架构，通过共享世界坐标系嵌入和旋转位置编码，能够融合不同分辨率的观察信息，在多种生物医学图像分析任务中优于传统单分辨率模型。


<details>
  <summary>Details</summary>
Motivation: 现代显微镜产生包含多尺度结构（从细胞形态到组织组织）的千兆像素图像，但现有视觉模型通常只处理单一分辨率或从单一视图提取多尺度特征，无法充分利用显微镜数据固有的多分辨率特性。

Method: 提出MuViT Transformer架构，将所有图像块嵌入共享的世界坐标系，并将旋转位置编码扩展到这些坐标，使注意力机制能够在单个编码器中整合广域上下文和高分辨率细节。采用多分辨率MAE预训练方法。

Result: 在合成基准测试、肾脏组织病理学和高分辨率小鼠脑显微镜图像分析中，MuViT相比强大的ViT和CNN基线模型取得了持续改进。多分辨率MAE预训练产生了尺度一致的表征，增强了下游任务性能。

Conclusion: 显式的世界坐标建模为大规模显微镜分析中的多分辨率信息利用提供了一种简单而强大的机制，MuViT架构能够有效融合多分辨率观察，提升生物医学图像分析性能。

Abstract: Modern microscopy routinely produces gigapixel images that contain structures across multiple spatial scales, from fine cellular morphology to broader tissue organization. Many analysis tasks require combining these scales, yet most vision models operate at a single resolution or derive multi-scale features from one view, limiting their ability to exploit the inherently multi-resolution nature of microscopy data. We introduce MuViT, a transformer architecture built to fuse true multi-resolution observations from the same underlying image. MuViT embeds all patches into a shared world-coordinate system and extends rotary positional embeddings to these coordinates, enabling attention to integrate wide-field context with high-resolution detail within a single encoder. Across synthetic benchmarks, kidney histopathology, and high-resolution mouse-brain microscopy, MuViT delivers consistent improvements over strong ViT and CNN baselines. Multi-resolution MAE pretraining further produces scale-consistent representations that enhance downstream tasks. These results demonstrate that explicit world-coordinate modelling provides a simple yet powerful mechanism for leveraging multi-resolution information in large-scale microscopy analysis.

</details>


### [66] [Enhancing Spatial Understanding in Image Generation via Reward Modeling](https://arxiv.org/abs/2602.24233)
*Zhenyu Tang,Chaoran Feng,Yufan Deng,Jie Wu,Xiaojie Li,Rui Wang,Yunpeng Chen,Daquan Zhou*

Main category: cs.CV

TL;DR: 提出SpatialScore奖励模型，通过强化学习提升文本到图像生成模型的空间关系理解能力


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成虽然视觉保真度和创造力有所提升，但对复杂空间关系的编码要求更高，往往需要多次采样才能获得满意结果

Method: 构建包含8万多个偏好对的SpatialReward-Dataset，基于此数据集开发SpatialScore奖励模型，用于评估文本到图像生成中的空间关系准确性，并利用该模型进行在线强化学习

Result: SpatialScore在空间关系评估方面表现优异，甚至超过领先的专有模型；通过强化学习显著提升了图像生成模型的空间理解能力

Conclusion: 专门设计的奖励模型能够有效提升文本到图像生成模型对复杂空间关系的理解和生成能力

Abstract: Recent progress in text-to-image generation has greatly advanced visual fidelity and creativity, but it has also imposed higher demands on prompt complexity-particularly in encoding intricate spatial relationships. In such cases, achieving satisfactory results often requires multiple sampling attempts. To address this challenge, we introduce a novel method that strengthens the spatial understanding of current image generation models. We first construct the SpatialReward-Dataset with over 80k preference pairs. Building on this dataset, we build SpatialScore, a reward model designed to evaluate the accuracy of spatial relationships in text-to-image generation, achieving performance that even surpasses leading proprietary models on spatial evaluation. We further demonstrate that this reward model effectively enables online reinforcement learning for the complex spatial generation. Extensive experiments across multiple benchmarks show that our specialized reward model yields significant and consistent gains in spatial understanding for image generation.

</details>


### [67] [Joint Geometric and Trajectory Consistency Learning for One-Step Real-World Super-Resolution](https://arxiv.org/abs/2602.24240)
*Chengyan Deng,Zhangquan Chen,Li Yu,Kai Zhang,Xue Zhou,Wang Zhang*

Main category: cs.CV

TL;DR: GTASR提出了一种用于真实世界图像超分辨率的几何轨迹对齐一致性训练方法，通过轨迹对齐和双参考结构校正机制，解决了传统一致性模型中的一致性漂移和几何解耦问题，在保持低延迟的同时实现了优越性能。


<details>
  <summary>Details</summary>
Motivation: 基于扩散模型的真实世界图像超分辨率虽然感知质量出色，但存在计算成本高的问题。一致性模型虽然推理高效，但面临一致性漂移累积和"几何解耦"问题（像素对齐但结构不连贯）。

Method: 提出GTASR方法：1）轨迹对齐策略通过全路径投影修正切向量场；2）双参考结构校正机制施加严格的结构约束，确保生成轨迹保持结构连贯性。

Result: 大量实验验证GTASR在保持最小延迟的同时，性能优于代表性基线方法。代码和模型将在GitHub上发布。

Conclusion: GTASR为真实世界图像超分辨率提供了一种简单有效的解决方案，解决了传统一致性模型的关键限制，实现了高效且高质量的图像重建。

Abstract: Diffusion-based Real-World Image Super-Resolution (Real-ISR) achieves impressive perceptual quality but suffers from high computational costs due to iterative sampling. While recent distillation approaches leveraging large-scale Text-to-Image (T2I) priors have enabled one-step generation, they are typically hindered by prohibitive parameter counts and the inherent capability bounds imposed by teacher models. As a lightweight alternative, Consistency Models offer efficient inference but struggle with two critical limitations: the accumulation of consistency drift inherent to transitive training, and a phenomenon we term "Geometric Decoupling" - where the generative trajectory achieves pixel-wise alignment yet fails to preserve structural coherence. To address these challenges, we propose GTASR (Geometric Trajectory Alignment Super-Resolution), a simple yet effective consistency training paradigm for Real-ISR. Specifically, we introduce a Trajectory Alignment (TA) strategy to rectify the tangent vector field via full-path projection, and a Dual-Reference Structural Rectification (DRSR) mechanism to enforce strict structural constraints. Extensive experiments verify that GTASR delivers superior performance over representative baselines while maintaining minimal latency. The code and model will be released at https://github.com/Blazedengcy/GTASR.

</details>


### [68] [Compositional Generalization Requires Linear, Orthogonal Representations in Vision Embedding Models](https://arxiv.org/abs/2602.24264)
*Arnas Uselis,Andrea Dittadi,Seong Joon Oh*

Main category: cs.CV

TL;DR: 论文提出组合泛化的三个必要条件（可分性、可迁移性、稳定性），证明这些条件要求神经表示必须线性分解为概念组件且组件间正交，为线性表示假说提供理论依据，并通过视觉模型验证了该结构的存在及其与组合泛化的相关性。


<details>
  <summary>Details</summary>
Motivation: 尽管现代模型在大规模数据上训练，但只能覆盖组合空间中极小部分输入，需要探究支持未见组合泛化的表示结构。研究旨在形式化组合泛化的必要条件，并揭示这些条件对表示几何结构的约束。

Method: 形式化组合泛化的三个必要条件（可分性、可迁移性、稳定性），证明这些条件导致表示必须线性分解为概念组件且组件正交的几何约束。推导维度界限，将可组合概念数量与嵌入几何联系起来。在CLIP、SigLIP、DINO等现代视觉模型上进行实证评估。

Result: 理论分析表明组合泛化要求表示线性分解且概念组件正交。实证发现现代视觉模型表示呈现部分线性分解，具有低秩、近正交的概念因子，且这种结构程度与未见组合上的组合泛化能力相关。

Conclusion: 线性表示假说得到理论支持：神经表示中广泛观察到的线性结构是组合泛化的必然结果。随着模型规模扩大，这些条件预测了它们可能收敛的表示几何结构。

Abstract: Compositional generalization, the ability to recognize familiar parts in novel contexts, is a defining property of intelligent systems. Although modern models are trained on massive datasets, they still cover only a tiny fraction of the combinatorial space of possible inputs, raising the question of what structure representations must have to support generalization to unseen combinations. We formalize three desiderata for compositional generalization under standard training (divisibility, transferability, stability) and show they impose necessary geometric constraints: representations must decompose linearly into per-concept components, and these components must be orthogonal across concepts. This provides theoretical grounding for the Linear Representation Hypothesis: the linear structure widely observed in neural representations is a necessary consequence of compositional generalization. We further derive dimension bounds linking the number of composable concepts to the embedding geometry. Empirically, we evaluate these predictions across modern vision models (CLIP, SigLIP, DINO) and find that representations exhibit partial linear factorization with low-rank, near-orthogonal per-concept factors, and that the degree of this structure correlates with compositional generalization on unseen combinations. As models continue to scale, these conditions predict the representational geometry they may converge to. Code is available at https://github.com/oshapio/necessary-compositionality.

</details>


### [69] [Hierarchical Action Learning for Weakly-Supervised Action Segmentation](https://arxiv.org/abs/2602.24275)
*Junxian Huang,Ruichu Cai,Hao Zhu,Juntao Fang,Boyan Xu,Weilin Chen,Zijian Li,Shenghua Gao*

Main category: cs.CV

TL;DR: HAL模型通过分层因果生成过程和确定性时间对齐，利用高低层潜在变量不同演化速率，在弱监督动作分割任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 人类通过关键转换点在不同抽象层次上感知动作，而机器依赖视觉特征容易过分割。高低层潜在变量演化速率不同：低层视觉变量变化快，高层动作变量变化慢，这为识别高层动作变量提供了机会。

Method: 提出分层动作学习（HAL）模型，引入分层因果数据生成过程，高层潜在动作控制低层视觉特征动态。使用确定性过程对齐时间尺度，采用分层金字塔transformer捕获视觉特征和潜在变量，应用稀疏转换约束强制高层动作变量的慢动态。

Result: 在温和假设下证明潜在动作变量严格可识别。在多个基准测试中，HAL模型在弱监督动作分割任务上显著优于现有方法。

Conclusion: HAL模型通过建模高低层潜在变量的不同演化速率，有效解决了弱监督动作分割问题，在理论和实践上都表现出优越性。

Abstract: Humans perceive actions through key transitions that structure actions across multiple abstraction levels, whereas machines, relying on visual features, tend to over-segment. This highlights the difficulty of enabling hierarchical reasoning in video understanding. Interestingly, we observe that lower-level visual and high-level action latent variables evolve at different rates, with low-level visual variables changing rapidly, while high-level action variables evolve more slowly, making them easier to identify. Building on this insight, we propose the Hierarchical Action Learning (\textbf{HAL}) model for weakly-supervised action segmentation. Our approach introduces a hierarchical causal data generation process, where high-level latent action governs the dynamics of low-level visual features. To model these varying timescales effectively, we introduce deterministic processes to align these latent variables over time. The \textbf{HAL} model employs a hierarchical pyramid transformer to capture both visual features and latent variables, and a sparse transition constraint is applied to enforce the slower dynamics of high-level action variables. This mechanism enhances the identification of these latent variables over time. Under mild assumptions, we prove that these latent action variables are strictly identifiable. Experimental results on several benchmarks show that the \textbf{HAL} model significantly outperforms existing methods for weakly-supervised action segmentation, confirming its practical effectiveness in real-world applications.

</details>


### [70] [Mode Seeking meets Mean Seeking for Fast Long Video Generation](https://arxiv.org/abs/2602.24289)
*Shengqu Cai,Weili Nie,Chao Liu,Julius Berner,Lvmin Zhang,Nanye Ma,Hansheng Chen,Maneesh Agrawala,Leonidas Guibas,Gordon Wetzstein,Arash Vahdat*

Main category: cs.CV

TL;DR: 提出一种结合模式寻求与均值寻求的训练范式，通过解耦扩散Transformer统一表示，分离局部保真度与长期连贯性，实现分钟级视频生成。


<details>
  <summary>Details</summary>
Motivation: 视频生成从秒级扩展到分钟级面临关键瓶颈：短视频数据丰富且保真度高，但连贯的长视频数据稀缺且局限于狭窄领域。

Method: 采用解耦扩散Transformer统一表示，使用全局流匹配头通过长视频监督学习捕捉叙事结构，同时使用局部分布匹配头通过模式寻求的反向KL散度将滑动窗口与冻结的短视频教师对齐。

Result: 该方法有效缩小了保真度-时间跨度差距，联合提升了局部清晰度、运动效果和长期一致性，实现了快速生成分钟级视频。

Conclusion: 通过模式寻求与均值寻求的解耦训练范式，能够在有限长视频数据下学习长期连贯性，同时继承短视频教师的局部真实感，实现高质量分钟级视频生成。

Abstract: Scaling video generation from seconds to minutes faces a critical bottleneck: while short-video data is abundant and high-fidelity, coherent long-form data is scarce and limited to narrow domains. To address this, we propose a training paradigm where Mode Seeking meets Mean Seeking, decoupling local fidelity from long-term coherence based on a unified representation via a Decoupled Diffusion Transformer. Our approach utilizes a global Flow Matching head trained via supervised learning on long videos to capture narrative structure, while simultaneously employing a local Distribution Matching head that aligns sliding windows to a frozen short-video teacher via a mode-seeking reverse-KL divergence. This strategy enables the synthesis of minute-scale videos that learns long-range coherence and motions from limited long videos via supervised flow matching, while inheriting local realism by aligning every sliding-window segment of the student to a frozen short-video teacher, resulting in a few-step fast long video generator. Evaluations show that our method effectively closes the fidelity-horizon gap by jointly improving local sharpness, motion and long-range consistency. Project website: https://primecai.github.io/mmm/.

</details>


### [71] [UFO-4D: Unposed Feedforward 4D Reconstruction from Two Images](https://arxiv.org/abs/2602.24290)
*Junhwa Hur,Charles Herrmann,Songyou Peng,Philipp Henzler,Zeyu Ma,Todd Zickler,Deqing Sun*

Main category: cs.CV

TL;DR: UFO-4D是一个统一的feedforward框架，仅需一对未标定图像即可重建密集的4D表示，直接估计动态3D高斯泼溅，实现几何、运动和相机姿态的联合一致估计。


<details>
  <summary>Details</summary>
Motivation: 当前密集4D重建方法依赖缓慢的测试时优化或碎片化的任务特定前馈模型，需要一种统一的feedforward框架来处理未标定图像。

Method: 使用动态3D高斯表示，通过可微分渲染多个信号实现自监督图像合成损失，紧密耦合外观、深度和运动，所有模态共享相同几何基元。

Result: 在联合几何、运动和相机姿态估计方面比先前工作提升高达3倍，支持跨新视角和时间的高保真4D插值。

Conclusion: UFO-4D通过统一的feedforward框架和动态3D高斯表示，有效解决了未标定图像的密集4D重建问题，克服了数据稀缺性，实现了多模态的协同提升。

Abstract: Dense 4D reconstruction from unposed images remains a critical challenge, with current methods relying on slow test-time optimization or fragmented, task-specific feedforward models. We introduce UFO-4D, a unified feedforward framework to reconstruct a dense, explicit 4D representation from just a pair of unposed images. UFO-4D directly estimates dynamic 3D Gaussian Splats, enabling the joint and consistent estimation of 3D geometry, 3D motion, and camera pose in a feedforward manner. Our core insight is that differentiably rendering multiple signals from a single Dynamic 3D Gaussian representation offers major training advantages. This approach enables a self-supervised image synthesis loss while tightly coupling appearance, depth, and motion. Since all modalities share the same geometric primitives, supervising one inherently regularizes and improves the others. This synergy overcomes data scarcity, allowing UFO-4D to outperform prior work by up to 3 times in joint geometry, motion, and camera pose estimation. Our representation also enables high-fidelity 4D interpolation across novel views and time. Please visit our project page for visual results: https://ufo-4d.github.io/

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [72] [Toward General Semantic Chunking: A Discriminative Framework for Ultra-Long Documents](https://arxiv.org/abs/2602.23370)
*Kaifeng Wu,Junyan Wu,Qiang Liu,Jiarui Zhang,Wen Xu*

Main category: cs.CL

TL;DR: 基于Qwen3-0.6B的长文档主题分割模型，通过跨窗口上下文融合层和边界分类头，支持13k令牌单次输入，相比生成式模型在WIKI-727K数据集上获得更好的F1分数和快两个数量级的推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有长文档主题分割方法存在明显不足：传统判别式模型受限于固定窗口无法建模文档级语义；生成式大语言模型推理成本高且难以支持长输入。需要一种既高效又能处理超长文档的解决方案。

Method: 基于Qwen3-0.6B构建判别式分割模型，添加跨窗口上下文融合层和边界分类头，结合重叠滑动窗口策略。支持13k令牌单次输入，可扩展到超长文档。还提出带标量校正的向量融合方法，将超长段落表示压缩为单个向量而无语义损失。

Result: 在WIKI-727K数据集上，相比Jina发布的三个基于Qwen2-0.5B的生成式模型，该方法获得了更好的宏观平均F1分数，推理速度快两个数量级，显著提升了长文档处理的实用性和可扩展性。

Conclusion: 提出的判别式分割模型有效解决了长文档主题分割的效率和可扩展性问题，在保持高准确率的同时大幅提升推理速度，为信息检索和文档理解提供了实用解决方案。

Abstract: Long-document topic segmentation plays an important role in information retrieval and document understanding, yet existing methods still show clear shortcomings in ultra-long text settings. Traditional discriminative models are constrained by fixed windows and cannot model document-level semantics; generative large language models can output paragraph boundaries, but inference is expensive and long inputs are difficult to support. To address these issues, we propose a discriminative segmentation model based on Qwen3-0.6B. On top of the backbone network, we add a cross-window context fusion layer and a boundary classification head, and combine them with an overlapping sliding-window strategy. Our model supports single-pass inputs of up to 13k tokens and can be extended to ultra-long documents for paragraph boundary detection. To further enhance downstream retrieval efficiency, we derive a vector fusion method with scalar correction, which compresses the representation of ultra-long segments into a single vector without semantic loss. Experiments on the Wikipedia long-document topic segmentation dataset WIKI-727K show that, compared with three generative models based on Qwen2-0.5B released by Jina, our method achieves a better macro-averaged F1 and delivers two orders of magnitude faster inference, substantially improving the practicality and scalability of long-document processing.

</details>


### [73] [Task-Lens: Cross-Task Utility Based Speech Dataset Profiling for Low-Resource Indian Languages](https://arxiv.org/abs/2602.23388)
*Swati Sharma,Divya V. Sharma,Anubha Gupta*

Main category: cs.CL

TL;DR: Task-Lens是一个跨任务调查，评估了50个印度语音数据集在9个下游语音任务中的准备情况，揭示了未充分利用的元数据可以支持多个任务，并识别了服务不足的任务和语言。


<details>
  <summary>Details</summary>
Motivation: 包容性语音技术需求增长需要多语言数据集，但低资源语言中现有任务特定资源意识有限，特别是在印度这样的语言多样性国家。跨任务分析现有数据集可以缓解数据稀缺问题。

Method: 提出Task-Lens跨任务调查方法：1) 分析哪些数据集包含适合特定任务的元数据和属性；2) 提出任务对齐的增强建议以释放数据集的下游潜力；3) 识别当前资源严重不足的任务和印度语言。

Result: 研究发现许多印度语音数据集包含未充分利用的元数据，可以支持多个下游任务。通过揭示跨任务联系和差距，Task-Lens使研究人员能够探索现有数据集的更广泛应用，并优先为服务不足的任务和语言创建数据集。

Conclusion: 跨任务分析现有语音数据集可以缓解数据稀缺问题，Task-Lens方法通过评估数据集的多任务适用性，帮助研究人员充分利用现有资源并确定优先发展方向。

Abstract: The rising demand for inclusive speech technologies amplifies the need for multilingual datasets for Natural Language Processing (NLP) research. However, limited awareness of existing task-specific resources in low-resource languages hinders research. This challenge is especially acute in linguistically diverse countries, such as India. Cross-task profiling of existing Indian speech datasets can alleviate the data scarcity challenge. This involves investigating the utility of datasets across multiple downstream tasks rather than focusing on a single task. Prior surveys typically catalogue datasets for a single task, leaving comprehensive cross-task profiling as an open opportunity. Therefore, we propose Task-Lens, a cross-task survey that assesses the readiness of 50 Indian speech datasets spanning 26 languages for nine downstream speech tasks. First, we analyze which datasets contain metadata and properties suitable for specific tasks. Next, we propose task-aligned enhancements to unlock datasets to their full downstream potential. Finally, we identify tasks and Indian languages that are critically underserved by current resources. Our findings reveal that many Indian speech datasets contain untapped metadata that can support multiple downstream tasks. By uncovering cross-task linkages and gaps, Task-Lens enables researchers to explore the broader applicability of existing datasets and to prioritize dataset creation for underserved tasks and languages.

</details>


### [74] [Truncated Step-Level Sampling with Process Rewards for Retrieval-Augmented Reasoning](https://arxiv.org/abs/2602.23440)
*Chris Samarinas,Haw-Shiuan Chang,Hamed Zamani*

Main category: cs.CL

TL;DR: SLATE框架通过截断步级采样和密集LLM评判奖励，解决了语言模型搜索推理中的信用分配问题，相比传统稀疏奖励和过程奖励方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有方法在训练语言模型进行搜索推理时存在信用分配问题：稀疏奖励方法难以将成功或失败归因于单个推理和检索决策，而过程奖励方法虽然引入步级监督但依赖启发式奖励且梯度方差高。

Method: 提出SLATE框架，包含两个核心思想：(1) 截断步级采样：生成k条共享共同前缀、仅在下一步不同的轨迹；(2) 密集LLM评判奖励：用能力强的LLM评估器替代启发式评分，评估每个推理步骤、搜索查询和回答的质量。

Result: 理论证明在相同密集奖励结构下，截断采样可将优势估计方差降低最多T倍（T步轨迹），产生更低方差、更精准的策略梯度。在七个QA基准测试中，SLATE始终优于稀疏奖励和过程奖励基线，在更难的multi-hop任务和小模型上提升最大。

Conclusion: SLATE通过截断采样和密集LLM奖励的组合，有效解决了搜索推理中的信用分配问题，提供了更可靠、低方差的监督信号，显著提升了语言模型的搜索推理能力。

Abstract: Training large language models to reason with search engines via reinforcement learning is hindered by a fundamental credit assignment problem: existing methods such as Search-R1 provide only a sparse outcome reward after an entire multi-step trajectory, making it infeasible to attribute success or failure to individual reasoning and retrieval decisions. Process-reward methods like StepSearch alleviate this by introducing step-level supervision, but rely on heuristic rewards such as TF-IDF overlap with gold documents, and still sample k complete trajectories per example, retaining high gradient variance. We propose SLATE, a framework built on two complementary ideas: (1) truncated step-level sampling, which generates k trajectories that share a common prefix and differ only at the next step, and (2) dense LLM-as-judge rewards, which replace heuristic scoring with a capable LLM evaluator that assesses the quality of each reasoning step, search query, and answer, providing richer and more reliable supervision. We theoretically prove that under the same dense reward structure, truncated sampling reduces the variance of advantage estimates by up to a factor of T compared to full-trajectory sampling for T-step trajectories, yielding lower-variance, better-targeted policy gradients. Experiments on seven QA benchmarks confirm that SLATE consistently outperforms both sparse-reward and process-reward baselines, with the largest gains on harder multi-hop tasks and smaller models.

</details>


### [75] [CiteAudit: You Cited It, But Did You Read It? A Benchmark for Verifying Scientific References in the LLM Era](https://arxiv.org/abs/2602.23452)
*Zhengqing Yuan,Kaiwen Shi,Zheyuan Zhang,Lichao Sun,Nitesh V. Chawla,Yanfang Ye*

Main category: cs.CL

TL;DR: 该论文提出了首个针对科学写作中幻觉引用的综合基准和检测框架，通过多智能体验证管道分解引用检查过程，构建大规模人工验证数据集，显著提升了检测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在科学写作中会产生看似合理但实际不存在的幻觉引用，这种现象已在主要机器学习会议中被观察到，暴露了同行评审的脆弱性。同时，快速增长的参考文献列表使得手动验证变得不切实际，现有自动化工具对噪声和异构引用格式的鲁棒性不足，且缺乏标准化评估。

Method: 提出了一个多智能体验证管道，将引用检查分解为：1）主张提取，2）证据检索，3）段落匹配，4）推理，5）校准判断。构建了跨领域的大规模人工验证数据集，并定义了统一的引用忠实度和证据对齐度量标准。

Result: 实验表明，最先进的LLMs存在大量引用错误，而该框架在准确性和可解释性方面显著优于先前方法。这为LLM时代的引用审计提供了首个可扩展的基础设施。

Conclusion: 该工作提供了首个可扩展的基础设施来审计LLM时代的引用，并为提高科学参考文献的可信度提供了实用工具，有助于增强科学研究的完整性和可信度。

Abstract: Scientific research relies on accurate citation for attribution and integrity, yet large language models (LLMs) introduce a new risk: fabricated references that appear plausible but correspond to no real publications. Such hallucinated citations have already been observed in submissions and accepted papers at major machine learning venues, exposing vulnerabilities in peer review. Meanwhile, rapidly growing reference lists make manual verification impractical, and existing automated tools remain fragile to noisy and heterogeneous citation formats and lack standardized evaluation. We present the first comprehensive benchmark and detection framework for hallucinated citations in scientific writing. Our multi-agent verification pipeline decomposes citation checking into claim extraction, evidence retrieval, passage matching, reasoning, and calibrated judgment to assess whether a cited source truly supports its claim. We construct a large-scale human-validated dataset across domains and define unified metrics for citation faithfulness and evidence alignment. Experiments with state-of-the-art LLMs reveal substantial citation errors and show that our framework significantly outperforms prior methods in both accuracy and interpretability. This work provides the first scalable infrastructure for auditing citations in the LLM era and practical tools to improve the trustworthiness of scientific references.

</details>


### [76] [FHIRPath-QA: Executable Question Answering over FHIR Electronic Health Records](https://arxiv.org/abs/2602.23479)
*Michael Frew,Nishit Bheda,Bryan Tripp*

Main category: cs.CL

TL;DR: FHIRPath-QA是首个针对患者特定问题的开放数据集和基准，采用text-to-FHIRPath查询合成范式，将临床问答从自由文本生成转向结构化查询，显著减少LLM使用并提高安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 尽管患者越来越多地获得电子健康记录的数字访问权限，但现有界面可能无法提供精确、可信的患者特定问题答案。基于检索的大型语言模型方法存在计算效率低、易产生幻觉、难以在实际EHR上部署等问题。

Method: 提出text-to-FHIRPath问答范式，将推理从自由文本生成转向FHIRPath查询合成。基于MIMIC-IV on FHIR Demo构建数据集，包含超过14k个自然语言问题（患者和临床医生表述）与经过验证的FHIRPath查询和答案。

Result: 最先进的LLM在处理患者语言模糊性方面表现不佳，在FHIRPath查询合成中表现较差，但通过监督微调后性能显著提升。text-to-FHIRPath合成有潜力作为安全、高效、可互操作的消费者健康应用基础。

Conclusion: FHIRPath-QA数据集和基准为未来研究提供了起点，text-to-FHIRPath合成范式有望成为实用、安全、高效的临床问答解决方案，特别适合消费者健康应用场景。

Abstract: Though patients are increasingly granted digital access to their electronic health records (EHRs), existing interfaces may not support precise, trustworthy answers to patient-specific questions. Large language models (LLM) show promise in clinical question answering (QA), but retrieval-based approaches are computationally inefficient, prone to hallucination, and difficult to deploy over real-life EHRs. In this work, we introduce FHIRPath-QA, the first open dataset and benchmark for patient-specific QA that includes open-standard FHIRPath queries over real-world clinical data. We propose a text-to-FHIRPath QA paradigm that shifts reasoning from free-text generation to FHIRPath query synthesis, significantly reducing LLM usage. Built on MIMIC-IV on FHIR Demo, the dataset pairs over 14k natural language questions in patient and clinician phrasing with validated FHIRPath queries and answers. Further, we demonstrate that state-of-the-art LLMs struggle to deal with ambiguity in patient language and perform poorly in FHIRPath query synthesis. However, they benefit strongly from supervised fine-tuning. Our results highlight that text-to-FHIRPath synthesis has the potential to serve as a practical foundation for safe, efficient, and interoperable consumer health applications, and our dataset and benchmark serve as a starting point for future research on the topic. The full dataset and generation code is available at: https://github.com/mooshifrew/fhirpath-qa.

</details>


### [77] [Humans and LLMs Diverge on Probabilistic Inferences](https://arxiv.org/abs/2602.23546)
*Gaurav Kamath,Sreenath Madathil,Sebastian Schuster,Marie-Catherine de Marneffe,Siva Reddy*

Main category: cs.CL

TL;DR: 该研究创建了ProbCOPA数据集，包含210个人工标注的概率推理问题，比较了人类与8个先进推理LLM的表现，发现模型无法产生类似人类的概率分布。


<details>
  <summary>Details</summary>
Motivation: 人类推理经常基于有限信息得出概率性结论，而当前LLM在逻辑和数学任务上表现出色，但在这种开放式的、非确定性的概率推理任务上的行为尚未得到充分探索。

Method: 创建ProbCOPA数据集，包含210个手工制作的英语概率推理问题，每个问题由25-30名人类参与者标注推理可能性。比较人类判断与8个最先进的推理LLM的响应，并分析LLM的推理链。

Result: 人类响应呈现分级和多样化，揭示了数据集中的概率判断。模型无法产生类似人类的分布，分析LLM推理链发现它们使用共同的推理模式来评估此类推理。

Conclusion: 研究揭示了人类与LLM之间持续存在的差异，强调需要在非确定性环境中评估推理能力，超越传统的确定性评估框架。

Abstract: Human reasoning often involves working over limited information to arrive at probabilistic conclusions. In its simplest form, this involves making an inference that is not strictly entailed by a premise, but rather only likely given the premise. While reasoning LLMs have demonstrated strong performance on logical and mathematical tasks, their behavior on such open-ended, non-deterministic inferences remains largely unexplored. We introduce ProbCOPA, a dataset of 210 handcrafted probabilistic inferences in English, each annotated for inference likelihood by 25--30 human participants. We find that human responses are graded and varied, revealing probabilistic judgments of the inferences in our dataset. Comparing these judgments with responses from eight state-of-the-art reasoning LLMs, we show that models consistently fail to produce human-like distributions. Finally, analyzing LLM reasoning chains, we find evidence of a common reasoning pattern used to evaluate such inferences. Our findings reveal persistent differences between humans and LLMs, and underscore the need to evaluate reasoning beyond deterministic settings.

</details>


### [78] [France or Spain or Germany or France: A Neural Account of Non-Redundant Redundant Disjunctions](https://arxiv.org/abs/2602.23547)
*Sasha Boguraev,Qing Yao,Kyle Mahowald*

Main category: cs.CL

TL;DR: 论文研究句子中看似冗余的"或"连接词在特定语境下变得可接受的现象，通过人工和语言模型实验，揭示了Transformer模型通过绑定上下文信息和选择性注意力机制避免冗余的神经机制。


<details>
  <summary>Details</summary>
Motivation: 研究像"她将去法国或西班牙，或者可能去德国或法国"这样看似形式冗余的句子，在特定语境下变得可接受的现象。传统分析主要使用符号形式表示，本文旨在提供基于人工神经机制的补充解释。

Method: 首先收集人类和大型语言模型的行为证据，展示这种表面非冗余性在不同语境下的鲁棒性。然后分析语言模型中，冗余避免通过两种交互机制实现：模型学习将上下文相关信息绑定到重复的词汇项，Transformer的归纳头选择性关注这些语境许可的表示。

Result: 实验证明这种现象在人类和语言模型中都具有鲁棒性。在语言模型中，冗余避免源于上下文信息绑定和Transformer归纳头的选择性注意力机制。模型能够学习将不同上下文信息与重复词汇关联，从而避免感知冗余。

Conclusion: 这种神经机制解释为语境敏感语义解释提供了新的理解视角，补充了现有的符号分析。研究揭示了Transformer模型如何处理语境依赖的语义解释，为理解语言理解和生成中的冗余现象提供了神经基础。

Abstract: Sentences like "She will go to France or Spain, or perhaps to Germany or France." appear formally redundant, yet become acceptable in contexts such as "Mary will go to a philosophy program in France or Spain, or a mathematics program in Germany or France." While this phenomenon has typically been analyzed using symbolic formal representations, we aim to provide a complementary account grounded in artificial neural mechanisms. We first present new behavioral evidence from humans and large language models demonstrating the robustness of this apparent non-redundancy across contexts. We then show that, in language models, redundancy avoidance arises from two interacting mechanisms: models learn to bind contextually relevant information to repeated lexical items, and Transformer induction heads selectively attend to these context-licensed representations. We argue that this neural explanation sheds light on the mechanisms underlying context-sensitive semantic interpretation, and that it complements existing symbolic analyses.

</details>


### [79] [Multi-Agent Causal Reasoning for Suicide Ideation Detection Through Online Conversations](https://arxiv.org/abs/2602.23577)
*Jun Li,Xiangmeng Wang,Haoyang Li,Yifei Yan,Shijie Zhang,Hong Va Leong,Ling Feng,Nancy Xiaonan Yu,Qing Li*

Main category: cs.CL

TL;DR: 提出MACR多智能体因果推理框架，通过推理智能体扩展用户交互，偏置感知决策智能体缓解隐藏偏置，提升社交媒体自杀风险检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有社交媒体自杀风险检测方法存在两大局限：1) 依赖预定义规则（如引用或回复）记录对话，只能捕捉有限的用户交互；2) 忽视用户从众和自杀模仿行为等隐藏影响因素，这些因素显著影响在线社区中的自杀表达和传播。

Method: 提出多智能体因果推理（MACR）框架，包含两个协作智能体：推理智能体整合认知评价理论生成用户对帖子的反事实反应，从而扩展用户交互；偏置感知决策智能体通过前门调整策略缓解隐藏偏置，利用推理智能体产生的反事实用户反应。推理智能体通过认知、情感和行为三个维度分析用户反应，每个维度有专门的子智能体负责。

Result: 在真实世界对话数据集上的大量实验表明，MACR在识别自杀风险方面具有有效性和鲁棒性。

Conclusion: MACR框架通过推理和偏置感知决策的协作，不仅缓解了隐藏偏置，还通过反事实知识丰富了用户交互的上下文信息，提升了社交媒体自杀风险检测能力。

Abstract: Suicide remains a pressing global public health concern. While social media platforms offer opportunities for early risk detection through online conversation trees, existing approaches face two major limitations: (1) They rely on predefined rules (e.g., quotes or relies) to log conversations that capture only a narrow spectrum of user interactions, and (2) They overlook hidden influences such as user conformity and suicide copycat behavior, which can significantly affect suicidal expression and propagation in online communities. To address these limitations, we propose a Multi-Agent Causal Reasoning (MACR) framework that collaboratively employs a Reasoning Agent to scale user interactions and a Bias-aware Decision-Making Agent to mitigate harmful biases arising from hidden influences. The Reasoning Agent integrates cognitive appraisal theory to generate counterfactual user reactions to posts, thereby scaling user interactions. It analyses these reactions through structured dimensions, i.e., cognitive, emotional, and behavioral patterns, with a dedicated sub-agent responsible for each dimension. The Bias-aware Decision-Making Agent mitigates hidden biases through a front-door adjustment strategy, leveraging the counterfactual user reactions produced by the Reasoning Agent. Through the collaboration of reasoning and bias-aware decision making, the proposed MACR framework not only alleviates hidden biases, but also enriches contextual information of user interactions with counterfactual knowledge. Extensive experiments on real-world conversational datasets demonstrate the effectiveness and robustness of MACR in identifying suicide risk.

</details>


### [80] [BRIDGE the Gap: Mitigating Bias Amplification in Automated Scoring of English Language Learners via Inter-group Data Augmentation](https://arxiv.org/abs/2602.23580)
*Yun Wang,Xuansheng Wu,Jingyuan Huang,Lei Liu,Xiaoming Zhai,Ninghao Liu*

Main category: cs.CL

TL;DR: BRIDGE框架通过合成高质量英语学习者样本来减少自动评分系统中的偏见放大问题，在保持整体评分性能的同时显著提升对高分数英语学习者的预测公平性。


<details>
  <summary>Details</summary>
Motivation: 教育评估中基于深度学习和大语言模型的自动评分系统存在偏见放大风险，特别是对英语学习者等少数群体。由于少数群体（高分数英语学习者）样本稀缺，模型倾向于偏向多数群体（非英语学习者）的语言模式，导致对英语学习者评分偏低，即使他们展示了相当的学科知识。

Method: 提出BRIDGE框架：一种偏见减少的组间数据生成方法。该方法不依赖有限的少数群体样本，而是通过将丰富的高分数非英语学习者样本中的建构相关（即评分标准对齐的知识和证据）内容"粘贴"到真实的英语学习者语言模式中，合成高质量英语学习者样本。同时引入判别器模型确保合成样本质量。

Result: 在加州科学测试数据集上的实验表明，BRIDGE有效减少了高分数英语学习者的预测偏见，同时保持了整体评分性能。该方法实现的公平性提升与使用额外真实人类数据相当。

Conclusion: BRIDGE为大规模评估中的公平评分提供了一个经济有效的解决方案，通过合成数据生成方法缓解了自动评分系统中的偏见放大问题，特别是针对资源有限的评估环境。

Abstract: In the field of educational assessment, automated scoring systems increasingly rely on deep learning and large language models (LLMs). However, these systems face significant risks of bias amplification, where model prediction gaps between student groups become larger than those observed in training data. This issue is especially severe for underrepresented groups such as English Language Learners (ELLs), as models may inherit and further magnify existing disparities in the data. We identify that this issue is closely tied to representation bias: the scarcity of minority (high-scoring ELL) samples makes models trained with empirical risk minimization favor majority (non-ELL) linguistic patterns. Consequently, models tend to under-predict ELL students who even demonstrate comparable domain knowledge but use different linguistic patterns, thereby undermining the fairness of automated scoring outcomes. To mitigate this, we propose BRIDGE, a Bias-Reducing Inter-group Data GEneration framework designed for low-resource assessment settings. Instead of relying on the limited minority samples, BRIDGE synthesizes high-scoring ELL samples by "pasting" construct-relevant (i.e., rubric-aligned knowledge and evidence) content from abundant high-scoring non-ELL samples into authentic ELL linguistic patterns. We further introduce a discriminator model to ensure the quality of synthetic samples. Experiments on California Science Test (CAST) datasets demonstrate that BRIDGE effectively reduces prediction bias for high-scoring ELL students while maintaining overall scoring performance. Notably, our method achieves fairness gains comparable to using additional real human data, offering a cost-effective solution for ensuring equitable scoring in large-scale assessments.

</details>


### [81] [LFQA-HP-1M: A Large-Scale Human Preference Dataset for Long-Form Question Answering](https://arxiv.org/abs/2602.23603)
*Rafid Ishrak Jahan,Fahmid Shahriar Iqbal,Sagnik Ray Choudhury*

Main category: cs.CL

TL;DR: 本文提出了LFQA-HP-1M数据集，包含130万个人类成对偏好标注，用于长格式问答评估。作者设计了九个评估标准，并发现基于这些特征的简单线性模型与最先进的LLM评估器性能相当。研究还揭示了LLM评估器在传递一致性、位置偏见和冗长偏见方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 长格式问答需要评估多句子解释性回答，但现有评估指标往往无法准确反映人类判断。为了解决这一问题，作者旨在创建一个大规模的人类偏好数据集，并开发更透明可靠的评估框架。

Method: 1. 构建LFQA-HP-1M数据集，包含130万个人类成对偏好标注；2. 设计九个答案质量评估标准；3. 基于这些特征构建简单线性模型；4. 分析LLM评估器的传递一致性、位置偏见和冗长偏见；5. 测试LLM评估器对对抗性扰动的脆弱性。

Result: 1. 基于九个评估标准的简单线性模型与最先进的LLM评估器性能相当；2. 发现LLM评估器存在传递一致性不足、位置偏见和冗长偏见问题；3. 证明LLM评估器容易受到对抗性扰动的影响；4. 提供了目前最大的公开LFQA偏好数据集。

Conclusion: 本研究提供了一个大规模的长格式问答偏好数据集和基于评估标准的框架，能够实现更透明可靠的评估。研究揭示了当前LLM评估器的局限性，为未来评估方法的发展提供了重要基础。

Abstract: Long-form question answering (LFQA) demands nuanced evaluation of multi-sentence explanatory responses, yet existing metrics often fail to reflect human judgment. We present LFQA-HP-1M, a large-scale dataset comprising 1.3M human pairwise preference annotations for LFQA. We propose nine rubrics for answer quality evaluation, and show that simple linear models based on these features perform comparably to state-of-the-art LLM evaluators. We further examine transitivity consistency, positional bias, and verbosity biases in LLM evaluators and demonstrate their vulnerability to adversarial perturbations. Overall, this work provides one of the largest public LFQA preference datasets and a rubric-driven framework for transparent and reliable evaluation.

</details>


### [82] [LLM-Driven Multi-Turn Task-Oriented Dialogue Synthesis for Realistic Reasoning](https://arxiv.org/abs/2602.23610)
*Yu Zhu,Kai Yang*

Main category: cs.CL

TL;DR: 提出LLM驱动的多轮任务导向对话合成框架，通过三层优化生成基于真实推理场景的对话，构建高质量推理任务数据集，用于评估和提升LLM的现实逻辑推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有推理基准无法充分反映现实场景复杂性，数据集过于简化抽象，与真实任务流程脱节，且存在数据污染问题，传统众包方法成本高难扩展，需要更好的评估LLM现实推理能力的方法。

Method: 提出LLM驱动的框架，合成基于真实推理场景的多轮任务导向对话，采用三层优化提升对话质量，生成包含真实世界信息的连贯对话，并围绕对话设计迭代优化的推理任务。

Result: 实验结果表明，基于合成数据的推理任务引入了非平凡的推理挑战，为提升LLM的推理能力提供了有意义的支持，生成的对话数据集可作为评估LLM现实逻辑推理能力的有效基准。

Conclusion: 该框架成功解决了现有推理评估的局限性，通过合成真实场景的对话和任务，为评估和提升LLM的现实逻辑推理能力提供了有效工具，推动了LLM在复杂实际应用中的发展。

Abstract: The reasoning capability of large language models (LLMs), defined as their ability to analyze, infer, and make decisions based on input information, is essential for building intelligent task-oriented dialogue systems. However, existing benchmarks do not sufficiently reflect the complexity of real-world scenarios, which limits their effectiveness in evaluating and enhancing LLM reasoning in practical contexts. Many current reasoning datasets are overly simplistic and abstract, often disconnected from realistic task flows, domain constraints, and operational rules, making it difficult to effectively evaluate LLMs' logical reasoning ability. In addition, data contamination from pretraining corpora undermines the reliability of evaluation results, and traditional crowdsourcing methods for dataset construction are labor-intensive and difficult to scale. To address these challenges, we propose a LLM-driven framework for synthesizing multi-turn, task-oriented dialogues grounded in realistic reasoning scenarios, leveraging trilevel optimization to enhance dialogue quality. Our method generates dialogues grounded in authentic task scenarios, enriched with real-world information, and exhibiting strong contextual coherence. Corresponding reasoning tasks are carefully designed around these dialogues and iteratively refined to continuously improve the tasks' quality and challenge. The resulting dataset serves as a valuable benchmark for assessing and advancing the realistic logical reasoning capabilities of LLMs. Experimental results show that our synthetic data-based reasoning tasks introduce non-trivial reasoning challenges and provide meaningful support for improving the reasoning capabilities of LLMs.

</details>


### [83] [TRIZ-RAGNER: A Retrieval-Augmented Large Language Model for TRIZ-Aware Named Entity Recognition in Patent-Based Contradiction Mining](https://arxiv.org/abs/2602.23656)
*Zitong Xu,Yuqing Wu,Yue Zhao*

Main category: cs.CL

TL;DR: 本文提出TRIZ-RAGNER框架，通过检索增强的LLM方法改进专利中的TRIZ矛盾挖掘，相比传统方法显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有基于规则或传统机器学习的方法在处理复杂专利语言时存在语义模糊、领域依赖和泛化能力有限的问题，而直接应用大语言模型又面临幻觉和缺乏结构化TRIZ知识基础的限制

Method: 提出TRIZ-RAGNER框架，将矛盾挖掘重新定义为语义级命名实体识别任务，集成密集检索TRIZ知识库、交叉编码器重排序和结构化LLM提示，从专利句子中提取改善和恶化参数

Result: 在PaTRIZ数据集上，TRIZ-RAGNER在TRIZ矛盾对识别中达到85.6%精确率、82.9%召回率和84.2% F1分数，相比基于提示增强GPT的最强基线绝对提升7.3个百分点

Conclusion: 检索增强的TRIZ知识基础能有效减少语义噪声并提高提取一致性，为稳健准确的专利矛盾挖掘提供了有效解决方案

Abstract: TRIZ-based contradiction mining is a fundamental task in patent analysis and systematic innovation, as it enables the identification of improving and worsening technical parameters that drive inventive problem solving. However, existing approaches largely rely on rule-based systems or traditional machine learning models, which struggle with semantic ambiguity, domain dependency, and limited generalization when processing complex patent language. Recently, large language models (LLMs) have shown strong semantic understanding capabilities, yet their direct application to TRIZ parameter extraction remains challenging due to hallucination and insufficient grounding in structured TRIZ knowledge. To address these limitations, this paper proposes TRIZ-RAGNER, a retrieval-augmented large language model framework for TRIZ-aware named entity recognition in patent-based contradiction mining. TRIZ-RAGNER reformulates contradiction mining as a semantic-level NER task and integrates dense retrieval over a TRIZ knowledge base, cross-encoder reranking for context refinement, and structured LLM prompting to extract improving and worsening parameters from patent sentences. By injecting domain-specific TRIZ knowledge into the LLM reasoning process, the proposed framework effectively reduces semantic noise and improves extraction consistency. Experiments on the PaTRIZ dataset demonstrate that TRIZ-RAGNER consistently outperforms traditional sequence labeling models and LLM-based baselines. The proposed framework achieves a precision of 85.6%, a recall of 82.9%, and an F1-score of 84.2% in TRIZ contradiction pair identification. Compared with the strongest baseline using prompt-enhanced GPT, TRIZ-RAGNER yields an absolute F1-score improvement of 7.3 percentage points, confirming the effectiveness of retrieval-augmented TRIZ knowledge grounding for robust and accurate patent-based contradiction mining.

</details>


### [84] [From Static Benchmarks to Dynamic Protocol: Agent-Centric Text Anomaly Detection for Evaluating LLM Reasoning](https://arxiv.org/abs/2602.23729)
*Seungdong Yoa,Sanghyu Yoon,Suhee Yoon,Dongmin Kim,Ye Seul Sim,Junhyun Lee,Woohyung Lim*

Main category: cs.CL

TL;DR: 提出基于智能体的动态基准测试范式，替代传统静态数据集评估方法，通过教师、协调者和学生智能体的协作自动生成、验证和解决问题，实现难度自适应扩展。


<details>
  <summary>Details</summary>
Motivation: 传统基于静态数据集的LLM评估方法存在可扩展性有限、无法捕捉模型演进推理能力的问题，需要更动态、可持续的评估框架。

Method: 采用智能体中心范式：教师智能体生成候选问题，协调者智能体验证问题有效性并防御对抗攻击，学生智能体尝试解决问题。无效问题由教师修订，正确解答后生成更具挑战的变体。

Result: 该协议能系统性地暴露传统基准测试无法揭示的边界情况推理错误，在文本异常检测任务中展示出优越性，支持跨模型成对性能和问题演进的多维度评估。

Conclusion: 从固定数据集转向动态协议为评估不断演进的语言模型提供了可持续方向，并引入了以智能体基准测试共同进化为中心的研究议程。

Abstract: The evaluation of large language models (LLMs) has predominantly relied on static datasets, which offer limited scalability and fail to capture the evolving reasoning capabilities of recent models. To overcome these limitations, we propose an agent-centric benchmarking paradigm that moves beyond static datasets by introducing a dynamic protocol in which autonomous agents iteratively generate, validate, and solve problems. Within this protocol, a teacher agent generates candidate problems, an orchestrator agent rigorously verifies their validity and guards against adversarial attacks, and a student agent attempts to solve the validated problems. An invalid problem is revised by the teacher agent until it passes validation. If the student correctly solves the problem, the orchestrator prompts the teacher to generate more challenging variants. Consequently, the benchmark scales in difficulty automatically as more capable agents are substituted into any role, enabling progressive evaluation of large language models without manually curated datasets. Adopting text anomaly detection as our primary evaluation format, which demands cross-sentence logical inference and resists pattern-matching shortcuts, we demonstrate that this protocol systematically exposes corner-case reasoning errors that conventional benchmarks fail to reveal. We further advocate evaluating systems along several complementary axes including cross-model pairwise performance and progress between the initial and orchestrator-finalized problems. By shifting the focus from fixed datasets to dynamic protocols, our approach offers a sustainable direction for evaluating ever-evolving language models and introduces a research agenda centered on the co-evolution of agent-centric benchmarks.

</details>


### [85] [Structured Prompt Optimization for Few-Shot Text Classification via Semantic Alignment in Latent Space](https://arxiv.org/abs/2602.23753)
*Jiasen Zheng,Zijun Zhou,Huajun Zhang,Junjiang Lin,Jingyun Jia,Qi Wang*

Main category: cs.CL

TL;DR: 提出基于结构化提示的优化框架，解决少样本文本分类中的语义纠缠、标签结构不清晰和特征表示不足问题，通过多维度语义因素和跨空间对齐机制提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 针对少样本文本分类中存在的语义纠缠、标签结构不清晰和特征表示不足等问题，需要在低资源条件下提升语义理解和任务适应能力。

Method: 使用预训练语言模型编码文本，引入由多维度语义因素组成的结构化提示，通过可学习组合机制与文本特征融合，构建结构化标签嵌入矩阵和跨空间对齐机制，应用提示正交性约束和联合优化目标。

Result: 实验结果表明，该框架有效缓解了少样本文本分类中的语义冲突和标签模糊问题，在准确率、精确率、召回率和AUC等指标上显著提升，并展现出强大的跨任务适用性。

Conclusion: 提出的结构化提示优化框架能够有效解决少样本文本分类的关键挑战，通过增强语义理解和任务适应能力，为低资源条件下的文本分类提供了透明可控的指导方案。

Abstract: This study addresses the issues of semantic entanglement, unclear label structure, and insufficient feature representation in few-shot text classification, and proposes an optimization framework based on structured prompts to enhance semantic understanding and task adaptation under low-resource conditions. The framework first uses a pretrained language model to encode the input text and obtain basic semantic representations. It then introduces structured prompts composed of multi-dimensional semantic factors and integrates them with text features through a learnable combination mechanism, which forms task-related representations with clear boundaries in the latent space. To further strengthen the consistency between text representations and label semantics, the method constructs a structured label embedding matrix and employs a cross-space alignment mechanism to ensure stable matching between textual features and label attributes. In addition, the model applies prompt orthogonality constraints and a joint optimization objective to maintain independence across different semantic factors in the prompts, allowing the structured prompts to provide transparent and controllable guidance for classification decisions. Three types of sensitivity experiments, including learning rate sensitivity, prompt length sensitivity, and data scale sensitivity, are designed to evaluate the stability and robustness of the framework under different conditions. Experimental results show that the proposed structured prompt optimization framework effectively alleviates semantic conflicts and label ambiguity in few-shot text classification. It significantly improves performance on accuracy, precision, recall, and AUC, and demonstrates strong cross-task applicability.

</details>


### [86] [Divide and Conquer: Accelerating Diffusion-Based Large Language Models via Adaptive Parallel Decoding](https://arxiv.org/abs/2602.23792)
*Xiangzhong Luo,Yilin An,Zhicheng Yu,Weichen Liu,Xu Yang*

Main category: cs.CL

TL;DR: DiCo是一种用于扩散大语言模型的自适应并行解码方法，通过分治范式实现并行生成，在保持生成质量的同时显著提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型理论上支持并行生成多个token，但实际应用中仍倾向于单token生成，因为直接解码多个掩码token会导致生成质量和稳定性下降，存在理论与实际性能的差距。

Method: 提出DiCo自适应并行解码方法，采用三阶段分治范式：1) Divide阶段：探索输入掩码序列，识别种子token并扩展构建局部簇；2) Conquer阶段：在不同局部簇间并行解码；3) Finalize阶段：使用细粒度复合解码方案解码剩余少量掩码token完成生成。

Result: 大量实验表明，DiCo能够实现显著的推理加速，同时保持有竞争力的生成质量。

Conclusion: DiCo通过自适应并行解码方法成功弥合了扩散大语言模型理论并行性与实际性能之间的差距，为高效推理提供了有效解决方案。

Abstract: Diffusion-based large language models (dLLMs) have shown promising performance across various reasoning tasks, establishing themselves as an alternative to autoregressive large language models (LLMs). Unlike autoregressive LLMs that generate one token per step based on all previous tokens, dLLMs theoretically enable parallel generation of multiple tokens at each decoding step. However, recent dLLMs still favor one-token-per-step generation in practice, as directly decoding multiple masked tokens often leads to degraded generation quality and stability. This reveals a substantial gap between the theoretical parallelism and practical performance of dLLMs. To bridge this gap, we introduce an adaptive parallel decoding approach, namely DiCo, which features a three-phase divide-and-conquer paradigm to unleash the inherent parallelism of dLLMs. During the Divide phase, DiCo first explores the input masked sequence and identifies masked tokens as seed tokens, which are then expanded to construct a set of local clusters. During the Conquer phase, DiCo performs parallel decoding across different local clusters constructed in the Divide phase. The divide-and-conquer process repeatedly alternates between the Divide and Conquer phases until convergence. During the Finalize phase, DiCo decodes the remaining few masked tokens using an effective fine-grained compound decoding scheme to finalize the generation. Extensive experiments demonstrate that DiCo can achieve significant inference speedups while maintaining competitive generation quality.

</details>


### [87] [GLUScope: A Tool for Analyzing GLU Neurons in Transformer Language Models](https://arxiv.org/abs/2602.23826)
*Sebastian Gerstner,Hinrich Schütze*

Main category: cs.CL

TL;DR: GLUScope是一个开源工具，用于分析基于Transformer的语言模型中的神经元，特别针对使用SwiGLU等门控激活函数的较新模型，通过展示四种不同符号组合的文本示例来帮助理解神经元功能。


<details>
  <summary>Details</summary>
Motivation: 现有工具主要针对早期Transformer模型，而较新模型使用门控激活函数（如SwiGLU）带来了新的分析挑战：仅理解正激活不够，需要同时考虑门激活和输入激活的正负符号组合。

Method: 开发GLUScope工具，针对每个神经元展示四种符号组合（门正/负 × 输入正/负）的文本示例，并统计每种组合的出现频率，帮助研究人员理解神经元的不同功能模式。

Result: GLUScope能够有效分析使用门控激活函数的Transformer模型神经元，通过展示四种符号组合的示例，揭示了在某些情况下这些组合具有相当不同的功能特性。

Conclusion: GLUScope为可解释性研究人员提供了分析现代Transformer模型神经元的新工具，特别适用于理解门控激活函数带来的复杂行为，能够产生新的研究见解。

Abstract: We present GLUScope, an open-source tool for analyzing neurons in Transformer-based language models, intended for interpretability researchers. We focus on more recent models than previous tools do; specifically we consider gated activation functions such as SwiGLU. This introduces a new challenge: understanding positive activations is not enough. Instead, both the gate and the in activation of a neuron can be positive or negative, leading to four different possible sign combinations that in some cases have quite different functionalities. Accordingly, for any neuron, our tool shows text examples for each of the four sign combinations, and indicates how often each combination occurs. We describe examples of how our tool can lead to novel insights. A demo is available at https: //sjgerstner.github.io/gluscope.

</details>


### [88] [CLFEC: A New Task for Unified Linguistic and Factual Error Correction in paragraph-level Chinese Professional Writing](https://arxiv.org/abs/2602.23845)
*Jian Kai,Zidong Zhang,Jiwen Chen,Zhengxiang Wu,Songtao Sun,Fuyang Li,Yang Cao,Qiang Liu*

Main category: cs.CL

TL;DR: 本文提出CLFEC任务，旨在联合纠正中文专业写作中的语言错误和事实错误，构建了多领域数据集并系统研究了基于LLM的纠正方法。


<details>
  <summary>Details</summary>
Motivation: 传统中文纠错主要关注拼写和语法，而事实错误纠正通常单独处理。但在段落级中文专业写作中，语言错误（词汇/语法/标点）和事实错误经常同时出现且相互影响，使得统一纠正既必要又具有挑战性。

Method: 构建了涵盖时事、金融、法律和医学的多领域中文专业写作数据集；系统研究了基于大语言模型的纠正范式，包括提示工程、检索增强生成（RAG）和智能体工作流。

Result: 研究发现：专业纠正模型的泛化能力有限；事实修复需要证据支持；混合错误段落处理困难；在干净输入上存在过度纠正问题。在同一上下文中处理语言和事实错误优于解耦处理，智能体工作流在合适的骨干模型下表现有效。

Conclusion: 本文的数据集和实证结果为在工业环境中构建可靠、全自动的校对系统提供了指导。联合处理语言和事实错误是可行的，智能体工作流在适当模型支持下具有应用潜力。

Abstract: Chinese text correction has traditionally focused on spelling and grammar, while factual error correction is usually treated separately. However, in paragraph-level Chinese professional writing, linguistic (word/grammar/punctuation) and factual errors frequently co-occur and interact, making unified correction both necessary and challenging. This paper introduces CLFEC (Chinese Linguistic & Factual Error Correction), a new task for joint linguistic and factual correction. We construct a mixed, multi-domain Chinese professional writing dataset spanning current affairs, finance, law, and medicine. We then conduct a systematic study of LLM-based correction paradigms, from prompting to retrieval-augmented generation (RAG) and agentic workflows. The analysis reveals practical challenges, including limited generalization of specialized correction models, the need for evidence grounding for factual repair, the difficulty of mixed-error paragraphs, and over-correction on clean inputs. Results further show that handling linguistic and factual Error within the same context outperform decoupled processes, and that agentic workflows can be effective with suitable backbone models. Overall, our dataset and empirical findings provide guidance for building reliable, fully automatic proofreading systems in industrial settings.

</details>


### [89] [The Astonishing Ability of Large Language Models to Parse Jabberwockified Language](https://arxiv.org/abs/2602.23928)
*Gary Lupyan,Senyi Yang*

Main category: cs.CL

TL;DR: 大语言模型能从严重退化的英语文本中恢复语义，即使内容词被随机替换为无意义字符串，模型仍能将其翻译回接近原文的常规英语。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在理解语言结构方面的能力，特别是它们如何仅凭结构线索（如形态句法、封闭类词汇）来恢复被破坏文本的语义。

Method: 通过创建"Jabberwockified"英语文本（将内容词随机替换为无意义字符串），测试大语言模型将这些退化文本翻译回常规英语的能力。

Result: 大语言模型展现出惊人的能力，能够从严重退化的文本中恢复语义，在许多情况下能生成接近原文的翻译，表明结构线索对词汇意义的约束程度远超想象。

Conclusion: 大语言模型理解"Jabberwockified"英语的能力远超人类，这对理解语言结构有重要意义，表明高效的语言处理（无论是生物还是人工系统）都需要语法、词汇语义和世界知识的紧密整合。

Abstract: We show that large language models (LLMs) have an astonishing ability to recover meaning from severely degraded English texts. Texts in which content words have been randomly substituted by nonsense strings, e.g., "At the ghybe of the swuint, we are haiveed to Wourge Phrear-gwurr, who sproles into an ghitch flount with his crurp", can be translated to conventional English that is, in many cases, close to the original text, e.g., "At the start of the story, we meet a man, Chow, who moves into an apartment building with his wife." These results show that structural cues (e.g., morphosyntax, closed-class words) constrain lexical meaning to a much larger degree than imagined. Although the abilities of LLMs to make sense of "Jabberwockified" English are clearly superhuman, they are highly relevant to understanding linguistic structure and suggest that efficient language processing either in biological or artificial systems likely benefits from very tight integration between syntax, lexical semantics, and general world knowledge.

</details>


### [90] [Benchmarking BERT-based Models for Sentence-level Topic Classification in Nepali Language](https://arxiv.org/abs/2602.23940)
*Nischal Karki,Bipesh Subedi,Prakash Poudyal,Rupak Raj Ghimire,Bal Krishna Bal*

Main category: cs.CL

TL;DR: 本研究对多种BERT变体在尼泊尔语主题分类任务上的性能进行了基准测试，发现印度语系模型（特别是MuRIL-large）表现最佳，F1分数达90.60%，为尼泊尔语NLP应用建立了可靠基线。


<details>
  <summary>Details</summary>
Motivation: 尽管基于Transformer的模型如BERT显著推动了多语言自然语言处理的发展，但使用天城体文字书写的低资源语言尼泊尔语仍相对缺乏研究。本研究旨在评估不同BERT变体在尼泊尔语主题分类任务上的有效性。

Method: 研究对10个预训练模型（包括mBERT、XLM-R、MuRIL、DevBERT、HindiBERT、IndicBERT和NepBERTa）在平衡的尼泊尔语数据集上进行微调和测试。该数据集包含25,006个句子，涵盖五个概念领域。使用准确率、加权精确率、召回率、F1分数和AUROC等指标评估性能。

Result: 结果显示，印度语系模型表现最佳，特别是MuRIL-large模型取得了最高的F1分数90.60%，优于多语言和单语言模型。NepBERTa也表现出竞争力，F1分数为88.26%。

Conclusion: 这些发现为未来文档级分类和更广泛的尼泊尔语自然语言处理应用建立了稳健的基准，表明针对特定语言家族优化的模型在低资源语言任务上具有优势。

Abstract: Transformer-based models such as BERT have significantly advanced Natural Language Processing (NLP) across many languages. However, Nepali, a low-resource language written in Devanagari script, remains relatively underexplored. This study benchmarks multilingual, Indic, Hindi, and Nepali BERT variants to evaluate their effectiveness in Nepali topic classification. Ten pre-trained models, including mBERT, XLM-R, MuRIL, DevBERT, HindiBERT, IndicBERT, and NepBERTa, were fine-tuned and tested on the balanced Nepali dataset containing 25,006 sentences across five conceptual domains and the performance was evaluated using accuracy, weighted precision, recall, F1-score, and AUROC metrics. The results reveal that Indic models, particularly MuRIL-large, achieved the highest F1-score of 90.60%, outperforming multilingual and monolingual models. NepBERTa also performed competitively with an F1-score of 88.26%. Overall, these findings establish a robust baseline for future document-level classification and broader Nepali NLP applications.

</details>


### [91] [EDDA-Coordinata: An Annotated Dataset of Historical Geographic Coordinates](https://arxiv.org/abs/2602.23941)
*Ludovic Moncla,Pierre Nugues,Thierry Joliveau,Katherine McDonough*

Main category: cs.CL

TL;DR: 从18世纪《百科全书》中构建地理坐标数据集，训练模型自动提取和标准化历史文本中的坐标信息


<details>
  <summary>Details</summary>
Motivation: 历史文本中的地理坐标表达方式多样且精度不一，自动提取困难，需要构建高质量数据集来改进从早期现代数字化文本中提取坐标的能力

Method: 从《百科全书》74,000篇文章中筛选15,278个地理条目，人工标注4,798个含坐标条目；训练基于transformer的模型，采用两步流程：分类器识别含坐标条目，第二个模型进行坐标提取和标准化

Result: 交叉验证获得86%的精确匹配分数；在跨域测试中，对18世纪法语Trevoux词典达到61% EM，对19世纪英文《大英百科全书》第七版达到77% EM

Conclusion: 构建的数据集作为训练数据具有实用价值，两步方法在跨语言、跨领域场景中展现出良好的泛化能力

Abstract: This paper introduces a dataset of enriched geographic coordinates retrieved from Diderot and d'Alembert's eighteenth-century Encyclopedie. Automatically recovering geographic coordinates from historical texts is a complex task, as they are expressed in a variety of ways and with varying levels of precision. To improve retrieval of coordinates from similar digitized early modern texts, we have created a gold standard dataset, trained models, published the resulting inferred and normalized coordinate data, and experimented applying these models to new texts. From 74,000 total articles in each of the digitized versions of the Encyclopedie from ARTFL and ENCCRE, we examined 15,278 geographical entries, manually identifying 4,798 containing coordinates, and 10,480 with descriptive but non-numerical references. Leveraging our gold standard annotations, we trained transformer-based models to retrieve and normalize coordinates. The pipeline presented here combines a classifier to identify coordinate-bearing entries and a second model for retrieval, tested across encoder-decoder and decoder architectures. Cross-validation yielded an 86% EM score. On an out-of-domain eighteenth-century Trevoux dictionary (also in French), our fine-tuned model had a 61% EM score, while for the nineteenth-century, 7th edition of the Encyclopaedia Britannica in English, the EM was 77%. These findings highlight the gold standard dataset's usefulness as training data, and our two-step method's cross-lingual, cross-domain generalizability.

</details>


### [92] [MemEmo: Evaluating Emotion in Memory Systems of Agents](https://arxiv.org/abs/2602.23944)
*Peng Liu,Zhen Tao,Jihao Zhao,Ding Chen,Yansong Zhang,Cuiping Li,Zhiyu Li,Hong Chen*

Main category: cs.CL

TL;DR: 提出情感增强记忆评估基准HLME，评估主流记忆系统处理情感信息的能力，发现现有系统在情感信息提取、更新和问答方面均不完善。


<details>
  <summary>Details</summary>
Motivation: 当前LLM记忆系统在长时间交互中存在上下文丢失问题，但与人类认知相比，这些系统处理情感相关信息的有效性尚不明确，需要专门评估基准来填补这一研究空白。

Method: 提出情感增强记忆评估基准，开发HLME数据集，从三个维度评估记忆系统：情感信息提取、情感记忆更新、情感记忆问答。

Result: 实验结果表明，所有评估的记忆系统在三个任务中均未达到稳健性能，揭示了当前记忆系统在处理情感记忆方面的不足。

Conclusion: 研究为记忆系统处理情感记忆的当前缺陷提供了客观视角，并为未来研究和系统优化指出了新的方向。

Abstract: Memory systems address the challenge of context loss in Large Language Model during prolonged interactions. However, compared to human cognition, the efficacy of these systems in processing emotion-related information remains inconclusive. To address this gap, we propose an emotion-enhanced memory evaluation benchmark to assess the performance of mainstream and state-of-the-art memory systems in handling affective information. We developed the \textbf{H}uman-\textbf{L}ike \textbf{M}emory \textbf{E}motion (\textbf{HLME}) dataset, which evaluates memory systems across three dimensions: emotional information extraction, emotional memory updating, and emotional memory question answering. Experimental results indicate that none of the evaluated systems achieve robust performance across all three tasks. Our findings provide an objective perspective on the current deficiencies of memory systems in processing emotional memories and suggest a new trajectory for future research and system optimization.

</details>


### [93] [The GRADIEND Python Package: An End-to-End System for Gradient-Based Feature Learning](https://arxiv.org/abs/2602.23993)
*Jonathan Drechsel,Steffen Herbold*

Main category: cs.CL

TL;DR: gradiend是一个开源Python包，实现了GRADIEND方法，用于从语言模型的事实-反事实MLM和CLM梯度中学习特征方向，提供从数据创建到模型重写的完整工作流。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一的工作流程来操作化GRADIEND方法，使研究人员能够系统地学习语言模型中的特征方向，并进行模型重写和特征比较。

Method: 基于事实-反事实的MLM（掩码语言建模）和CLM（因果语言建模）梯度，学习语言模型中的特征方向，通过受控的权重更新实现持久性模型重写。

Result: 成功开发了gradiend开源包，并在英语代词范例和大规模特征比较中展示了GRADIEND方法的有效性，复现了先前的研究用例。

Conclusion: gradiend包为语言模型特征方向学习提供了一个实用的工具，支持从数据创建到模型重写的完整工作流程，有助于系统性地研究和修改语言模型中的特征表示。

Abstract: We present gradiend, an open-source Python package that operationalizes the GRADIEND method for learning feature directions from factual-counterfactual MLM and CLM gradients in language models. The package provides a unified workflow for feature-related data creation, training, evaluation, visualization, persistent model rewriting via controlled weight updates, and multi-feature comparison. We demonstrate GRADIEND on an English pronoun paradigm and on a large-scale feature comparison that reproduces prior use cases.

</details>


### [94] [Dialect and Gender Bias in YouTube's Spanish Captioning System](https://arxiv.org/abs/2602.24002)
*Iris Dania Jimenez,Christoph Kern*

Main category: cs.CL

TL;DR: 研究YouTube西班牙语自动字幕系统对不同西班牙语方言的偏见问题，发现系统在不同方言间存在系统性差异


<details>
  <summary>Details</summary>
Motivation: 西班牙语是21个国家的官方语言，有超过4.41亿使用者，但YouTube只提供一种西班牙语自动字幕选项，这引发了对该系统是否对不同西班牙语方言存在偏见的疑问

Method: 通过分析YouTube自动字幕系统在不同西班牙语方言上的表现，比较来自不同地区的男女说话者的字幕质量

Result: 研究发现YouTube自动字幕系统在不同西班牙语方言间存在系统性差异，这些差异可归因于特定方言

Conclusion: 数字平台上部署的算法技术需要根据用户群体的多样化需求和经验进行校准，以确保公平性和包容性

Abstract: Spanish is the official language of twenty-one countries and is spoken by over 441 million people. Naturally, there are many variations in how Spanish is spoken across these countries. Media platforms such as YouTube rely on automatic speech recognition systems to make their content accessible to different groups of users. However, YouTube offers only one option for automatically generating captions in Spanish. This raises the question: could this captioning system be biased against certain Spanish dialects? This study examines the potential biases in YouTube's automatic captioning system by analyzing its performance across various Spanish dialects. By comparing the quality of captions for female and male speakers from different regions, we identify systematic disparities which can be attributed to specific dialects. Our study provides further evidence that algorithmic technologies deployed on digital platforms need to be calibrated to the diverse needs and experiences of their user populations.

</details>


### [95] [Task Complexity Matters: An Empirical Study of Reasoning in LLMs for Sentiment Analysis](https://arxiv.org/abs/2602.24060)
*Donghao Huang,Zhaoxia Wang*

Main category: cs.CL

TL;DR: 该研究通过504种配置的全面评估发现，大语言模型的推理能力并非普遍提升所有语言任务性能，而是强烈依赖于任务复杂性。推理对简单任务（如二分类）可能造成性能下降，但对复杂任务（如27类情感识别）有显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前普遍认为大语言模型的推理能力能够普遍提升各种语言任务的性能，但这一假设缺乏系统性验证。研究者旨在通过全面评估来检验推理能力是否真的对所有任务都有帮助，以及这种帮助是否依赖于任务特性。

Method: 研究采用7个模型家族的504种配置，包括自适应、条件式和基于强化学习的推理架构。在情感分析数据集上进行评估，涵盖不同粒度的任务：二分类、五分类和27类情感识别。使用零样本和少样本提示策略，并进行帕累托前沿分析来评估效率-性能权衡。

Result: 1. 推理效果强烈依赖于任务复杂性：二分类任务性能下降高达19.9个F1百分点，而27类情感识别任务提升高达16.0个百分点；2. 蒸馏推理变体在简单任务上比基础模型差3-18个百分点；3. 少样本学习在大多数情况下优于零样本；4. 基础模型在效率-性能权衡中占主导地位，推理仅在复杂情感识别任务中合理，尽管带来2.1-54倍的计算开销。

Conclusion: 推理能力并非普遍提升大语言模型性能，而是强烈依赖于任务复杂性。对于简单任务，推理可能导致"过度思考"而降低性能；对于复杂任务，推理能显著提升性能。研究挑战了当前关于推理普遍有益的假设，为模型选择和部署提供了实用指导。

Abstract: Large language models (LLMs) with reasoning capabilities have fueled a compelling narrative that reasoning universally improves performance across language tasks. We test this claim through a comprehensive evaluation of 504 configurations across seven model families--including adaptive, conditional, and reinforcement learning-based reasoning architectures--on sentiment analysis datasets of varying granularity (binary, five-class, and 27-class emotion). Our findings reveal that reasoning effectiveness is strongly task-dependent, challenging prevailing assumptions: (1) Reasoning shows task-complexity dependence--binary classification degrades up to -19.9 F1 percentage points (pp), while 27-class emotion recognition gains up to +16.0pp; (2) Distilled reasoning variants underperform base models by 3-18 pp on simpler tasks, though few-shot prompting enables partial recovery; (3) Few-shot learning improves over zero-shot in most cases regardless of model type, with gains varying by architecture and task complexity; (4) Pareto frontier analysis shows base models dominate efficiency-performance trade-offs, with reasoning justified only for complex emotion recognition despite 2.1x-54x computational overhead. We complement these quantitative findings with qualitative error analysis revealing that reasoning degrades simpler tasks through systematic over-deliberation, offering mechanistic insight beyond the high-level overthinking hypothesis.

</details>


### [96] [Preference Packing: Efficient Preference Optimization for Large Language Models](https://arxiv.org/abs/2602.24082)
*Jaekyung Cho*

Main category: cs.CL

TL;DR: 提出preference packing方法，通过减少重复输入提示的注意力操作和降低KV缓存内存使用，提升奖励模型和DPO等训练的资源效率，实验显示训练时间减少至少37%，结合现有优化技术可实现3.22倍加速。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模持续增长，资源高效的训练优化技术变得越来越重要。特别是在使用相同输入提示对应不同响应的数据训练时（如奖励模型或DPO），现有方法存在资源效率不足的问题。

Method: 提出preference packing方法，通过打包处理相同输入提示对应的不同响应数据，减少重复输入提示的注意力计算操作，降低KV缓存内存使用，从而提升训练资源效率。

Result: 在纯文本数据集和包含图像的数据集上进行实验，实现了至少37%的训练时间减少。该方法可与现有优化技术（如批次排序）结合使用，获得3.22倍的加速效果。

Conclusion: preference packing是一种有效的资源效率优化方法，特别适用于使用相同输入提示对应不同响应数据的训练场景，能够显著减少训练时间和资源消耗。

Abstract: Resource-efficient training optimization techniques are becoming increasingly important as the size of large language models (LLMs) continues to grow. In particular, batch packing is commonly used in pre-training and supervised fine-tuning to achieve resource-efficient training. We propose preference packing, a method to enhance resource efficiency in training techniques that use data with different responses for the same input prompt, such as reward models or Direct Preference Optimization (DPO). Preference packing improves resource efficiency by reducing the attention operations for duplicate input prompts and decreasing KV cache memory usage. We conducted experiments on text-only datasets and image-included datasets and achieved at least 37% reduction in training time. Notably, this method can be applied alongside existing optimization techniques such as batch sorting, resulting in a 3.22x speedup.

</details>


### [97] [ARGUS: Seeing the Influence of Narrative Features on Persuasion in Argumentative Texts](https://arxiv.org/abs/2602.24109)
*Sara Nabhani,Federico Pianzola,Khalid Al-Khatib,Malvina Nissim*

Main category: cs.CL

TL;DR: ARGUS框架研究叙事在在线论证中的说服力影响，通过标注故事存在和六个关键叙事特征，结合理论框架和LLM技术分析不同叙事维度如何影响说服成功


<details>
  <summary>Details</summary>
Motivation: 虽然故事常被视为强大的说服工具，但其在在线非结构化论证中的具体作用尚未充分探索。本研究旨在填补这一空白，研究叙事如何影响在线论证中的说服力

Method: 提出ARGUS框架，创建新的ChangeMyView语料库，标注故事存在和六个关键叙事特征。结合两个成熟的理论框架，使用编码器分类器和零样本大型语言模型识别故事和叙事特征，大规模分析叙事维度对说服成功的影响

Result: ARGUS框架能够识别故事和叙事特征，并应用于大规模分析，揭示了不同叙事维度如何影响在线论证中的说服成功

Conclusion: 叙事确实能增强论证的说服力，ARGUS框架为研究叙事在在线论证中的作用提供了系统方法，揭示了关键叙事特征对说服效果的影响

Abstract: Can narratives make arguments more persuasive? And to this end, which narrative features matter most? Although stories are often seen as powerful tools for persuasion, their specific role in online, unstructured argumentation remains underexplored. To address this gap, we present ARGUS, a framework for studying the impact of narration on persuasion in argumentative discourse. ARGUS introduces a new ChangeMyView corpus annotated for story presence and six key narrative features, integrating insights from two established theoretical frameworks that capture both textual narrative features and their effects on recipients. Leveraging both encoder-based classifiers and zero-shot large language models (LLMs), ARGUS identifies stories and narrative features and applies them at scale to examine how different narrative dimensions influence persuasion success in online argumentation.

</details>


### [98] [Terminology Rarity Predicts Catastrophic Failure in LLM Translation of Low-Resource Ancient Languages: Evidence from Ancient Greek](https://arxiv.org/abs/2602.24119)
*James L. Zainaldin,Cameron Pattison,Manuela Marai,Jacob Wu,Mark J. Schiefsky*

Main category: cs.CL

TL;DR: 本研究首次对大型语言模型在古希腊技术散文翻译方面进行了系统性、无参考的人类评估，评估了三种商业LLM对盖伦医学著作的翻译质量，发现翻译质量与术语稀有度高度相关。


<details>
  <summary>Details</summary>
Motivation: 研究动机是填补对大型语言模型在低资源古代语言翻译方面评估的空白，特别是针对古希腊技术散文这种专业领域，为古典学术研究和自动化评估流程设计提供依据。

Method: 使用三种商业LLM（Claude、Gemini、ChatGPT）翻译盖伦的两部医学著作段落，其中一部已有英文译本，另一部从未完全翻译。采用标准自动化评估指标（BLEU、chrF++等）和专家人类评估（修改版MQM框架）相结合的方法。

Result: 在已有翻译的说明性文本上，LLM达到高质量翻译（平均MQM得分95.2/100），接近专家水平。在未翻译的药理学文本上，总体质量较低（79.9/100），但排除两个术语密度极高的段落后，得分接近已有翻译文本。术语稀有度（通过语料库频率衡量）是翻译失败的重要预测因子（r=-0.97）。自动化指标在质量差异大的文本上与人类判断有中等相关性，但无法区分高质量翻译。

Conclusion: LLM在古希腊技术散文翻译方面表现良好，特别是在已有参考翻译的文本上接近专家水平。术语稀有度是翻译质量的关键影响因素。自动化评估指标在低资源古代语言翻译评估中存在局限性，需要结合人类专家评估。研究为古典学术中LLM的应用和古代语言自动化评估流程设计提供了重要见解。

Abstract: This study presents the first systematic, reference-free human evaluation of large language model (LLM) machine translation (MT) for Ancient Greek (AG) technical prose. We evaluate translations by three commercial LLMs (Claude, Gemini, ChatGPT) of twenty paragraph-length passages from two works by the Greek physician Galen of Pergamum (ca. 129-216 CE): On Mixtures, which has two published English translations, and On the Composition of Drugs according to Kinds, which has never been fully translated into English. We assess translation quality using both standard automated evaluation metrics (BLEU, chrF++, METEOR, ROUGE-L, BERTScore, COMET, BLEURT) and expert human evaluation via a modified Multidimensional Quality Metrics (MQM) framework applied to all 60 translations by a team of domain specialists. On the previously translated expository text, LLMs achieved high translation quality (mean MQM score 95.2/100), with performance approaching expert level. On the untranslated pharmacological text, aggregate quality was lower (79.9/100) but with high variance driven by two passages presenting extreme terminological density; excluding these, scores converged to within 4 points of the translated text. Terminology rarity, operationalized via corpus frequency in the literary Diorisis Ancient Greek Corpus, emerged as a strong predictor of translation failure (r = -.97 for passage-level quality on the untranslated text). Automated metrics showed moderate correlation with human judgment overall on the text with a wide quality spread (Composition), but no metric discriminated among high-quality translations. We discuss implications for the use of LLMs in Classical scholarship and for the design of automated evaluation pipelines for low-resource ancient languages.

</details>


### [99] [Task-Centric Acceleration of Small-Language Models](https://arxiv.org/abs/2602.24174)
*Dor Tsur,Sharon Adar,Ran Levy*

Main category: cs.CL

TL;DR: TASC框架包含TASC-ft和TASC-spec两种方法，用于加速小型语言模型在特定任务上的性能，通过词汇扩展和推测解码提升效率。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型在需要高吞吐量和低延迟的应用场景中效率至关重要，但现有方法在任务特定优化方面存在不足，需要更高效的加速方案。

Method: 提出TASC框架：1) TASC-ft在微调时向分词器词汇表中添加高频输出n-gram，然后微调模型使用扩展词汇；2) TASC-spec在推理时构建n-gram草稿模型，混合任务和上下文信息，无需额外训练。

Result: 在多个低输出变异性生成任务中，两种方法都显示出推理效率的持续提升，同时保持了任务性能。

Conclusion: TASC框架为小型语言模型提供了有效的任务自适应加速方案，通过词汇扩展和训练自由的推测解码，在保持性能的同时显著提升推理效率。

Abstract: Small language models (SLMs) have emerged as efficient alternatives to large language models for task-specific applications. However, they are often employed in high-volume, low-latency settings, where efficiency is crucial. We propose TASC, Task-Adaptive Sequence Compression, a framework for SLM acceleration comprising two use-cases: When performing SLM fine-tuning, we propose TASC-ft, which iteratively enriches the tokenizer vocabulary with high-frequency output n-grams and then fine-tunes the model to utilize the expanded vocabulary. Next, we propose an inference-time method, termed TASC-spec. TASC-spec is a lightweight, training-free speculative decoding method that constructs an n-gram draft model from the task's output corpus, mixing task and context n-gram information.TASC-spec avoids any additional training, while bypassing draft-target vocabulary alignment constraints. We demonstrate the effectiveness of both methods across multiple low output-variability generation tasks. Our methods show consistent improvements in inference efficiency while maintaining task performance.

</details>


### [100] [MT-PingEval: Evaluating Multi-Turn Collaboration with Private Information Games](https://arxiv.org/abs/2602.24188)
*Jacob Eisenstein,Fantine Huot,Adam Fisch,Jonathan Berant,Mirella Lapata*

Main category: cs.CL

TL;DR: 提出MT-PingEval评估框架，通过多轮协作游戏测试语言模型在私密信息交流中的表现，发现现有模型在多轮协作中表现不佳，无法有效利用交互提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型在真实世界通信中需要处理私密信息，但缺乏系统评估其在多轮交互协作中能力的框架。私密信息管理是现实通信的关键特征，需要专门评估方法。

Method: 开发MT-PingEval评估框架，使用需要私密信息交流的协作游戏套件。采用交互式缩放分析，将固定token预算分配到可变轮次中，比较模型在多轮交互与单轮总结场景下的表现。

Result: 在许多情况下，语言模型无法通过多轮交互协作超越非交互基线（单智能体总结信息后立即行动），尽管存在显著提升空间。人类在相同任务中能以更高token效率实现可比成功率，且对话更连贯。

Conclusion: 最先进的语言模型在多轮协作对话的规划和执行方面仍存在显著弱点。虽然无法用单一语言特征解释这些协作弱点，但人类对话的连贯性优势表明改进方向。MT-PingEval框架有望推动提升语言模型的私密信息管理能力。

Abstract: We present a scalable methodology for evaluating language models in multi-turn interactions, using a suite of collaborative games that require effective communication about private information. This enables an interactive scaling analysis, in which a fixed token budget is divided over a variable number of turns. We find that in many cases, language models are unable to use interactive collaboration to improve over the non-interactive baseline scenario in which one agent attempts to summarize its information and the other agent immediately acts -- despite substantial headroom. This suggests that state-of-the-art models still suffer from significant weaknesses in planning and executing multi-turn collaborative conversations. We analyze the linguistic features of these dialogues, assessing the roles of sycophancy, information density, and discourse coherence. While there is no single linguistic explanation for the collaborative weaknesses of contemporary language models, we note that humans achieve comparable task success at superior token efficiency by producing dialogues that are more coherent than those produced by most language models. The proactive management of private information is a defining feature of real-world communication, and we hope that MT-PingEval will drive further work towards improving this capability.

</details>


### [101] [Controllable Reasoning Models Are Private Thinkers](https://arxiv.org/abs/2602.24210)
*Haritz Puerto,Haonan Li,Xudong Han,Timothy Baldwin,Iryna Gurevych*

Main category: cs.CL

TL;DR: 训练推理模型在推理轨迹中遵循指令以保护隐私，通过分离推理和答案生成的LoRA适配器方法，在隐私基准上提升51.9个百分点，但可能牺牲任务效用。


<details>
  <summary>Details</summary>
Motivation: AI推理模型需要访问敏感用户数据，但其推理轨迹难以控制，可能导致隐私信息意外泄露给外部方。现有模型只在最终答案中遵循指令，而推理轨迹缺乏控制。

Method: 1) 在新指令遵循数据集上微调模型，对推理轨迹施加明确限制；2) 引入分离推理和答案生成的生成策略，使用独立的LoRA适配器；3) 在6个模型（1.7B-14B参数）上评估，涵盖两个指令遵循基准和两个隐私基准。

Result: 方法显著提升性能：指令遵循性能提升达20.9分，隐私基准提升达51.9个百分点。但改进可能以任务效用为代价，体现了推理性能与指令遵循能力之间的权衡。

Conclusion: 提升推理模型的指令遵循能力可显著增强隐私保护，为未来隐私感知智能体的开发提供了有前景的方向。需要在隐私保护和任务效用之间找到平衡。

Abstract: AI agents powered by reasoning models require access to sensitive user data. However, their reasoning traces are difficult to control, which can result in the unintended leakage of private information to external parties. We propose training models to follow instructions not only in the final answer, but also in reasoning traces, potentially under different constraints. We hypothesize that improving their instruction following abilities in the reasoning traces can improve their privacy-preservation skills. To demonstrate this, we fine-tune models on a new instruction-following dataset with explicit restrictions on reasoning traces. We further introduce a generation strategy that decouples reasoning and answer generation using separate LoRA adapters. We evaluate our approach on six models from two model families, ranging from 1.7B to 14B parameters, across two instruction-following benchmarks and two privacy benchmarks. Our method yields substantial improvements, achieving gains of up to 20.9 points in instruction-following performance and up to 51.9 percentage points on privacy benchmarks. These improvements, however, can come at the cost of task utility, due to the trade-off between reasoning performance and instruction-following abilities. Overall, our results show that improving instruction-following behavior in reasoning models can significantly enhance privacy, suggesting a promising direction for the development of future privacy-aware agents. Our code and data are available at https://github.com/UKPLab/arxiv2026-controllable-reasoning-models

</details>


### [102] [Do LLMs Benefit From Their Own Words?](https://arxiv.org/abs/2602.24287)
*Jenny Y. Huang,Leshem Choshen,Ramon Astudillo,Tamara Broderick,Jacob Andreas*

Main category: cs.CL

TL;DR: 研究发现，在多轮对话中省略语言模型自己之前的回复，不仅不会降低回答质量，反而能减少上下文长度并避免上下文污染问题。


<details>
  <summary>Details</summary>
Motivation: 传统多轮对话系统通常保留助手的所有历史回复，但作者质疑这种设计是否真正有益，想探究语言模型是否真的需要依赖自己之前的回答来生成更好的回复。

Method: 使用真实多轮对话数据，比较标准全上下文提示与仅用户轮次提示（省略所有助手历史回复）的效果，测试了三个开放推理模型和一个最先进模型。设计了上下文过滤方法，选择性省略助手侧上下文。

Result: 1. 移除助手历史回复对大部分轮次回答质量无影响；2. 省略助手侧历史可将累计上下文长度减少高达10倍；3. 36.4%的提示是自包含的；4. 发现上下文污染现象，模型过度依赖自己之前的回复导致错误传播；5. 选择性省略助手历史可同时提升回答质量和减少内存消耗。

Conclusion: 在多轮对话中，选择性省略语言模型自己的历史回复是更优的设计选择，既能提高回答质量，又能显著减少计算资源消耗。

Abstract: Multi-turn interactions with large language models typically retain the assistant's own past responses in the conversation history. In this work, we revisit this design choice by asking whether large language models benefit from conditioning on their own prior responses. Using in-the-wild, multi-turn conversations, we compare standard (full-context) prompting with a user-turn-only prompting approach that omits all previous assistant responses, across three open reasoning models and one state-of-the-art model. To our surprise, we find that removing prior assistant responses does not affect response quality on a large fraction of turns. Omitting assistant-side history can reduce cumulative context lengths by up to 10x. To explain this result, we find that multi-turn conversations consist of a substantial proportion (36.4%) of self-contained prompts, and that many follow-up prompts provide sufficient instruction to be answered using only the current user turn and prior user turns. When analyzing cases where user-turn-only prompting substantially outperforms full context, we identify instances of context pollution, in which models over-condition on their previous responses, introducing errors, hallucinations, or stylistic artifacts that propagate across turns. Motivated by these findings, we design a context-filtering approach that selectively omits assistant-side context. Our findings suggest that selectively omitting assistant history can improve response quality while reducing memory consumption.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [103] [Demystifying Action Space Design for Robotic Manipulation Policies](https://arxiv.org/abs/2602.23408)
*Yuchun Feng,Jinliang Zheng,Zhihao Wang,Dongxiu Liu,Jianxiong Li,Jiangmiao Pang,Tai Wang,Xianyuan Zhan*

Main category: cs.RO

TL;DR: 动作空间设计对基于模仿学习的机器人操作策略学习有重要影响，本文通过大规模实证研究分析了动作空间在时间和空间维度上的设计选择对策略学习的影响。


<details>
  <summary>Details</summary>
Motivation: 当前机器人策略学习中，动作空间的选择主要基于经验法则或传统设计，缺乏系统性的理解。虽然近期研究集中在扩展训练数据和模型容量上，但动作空间设计对优化景观的影响仍不明确。

Method: 进行了大规模系统性实证研究，将动作设计空间沿时间和空间维度分解，分析了绝对vs.增量表示、关节空间vs.任务空间参数化的权衡。基于双臂机器人的13,000+次真实世界测试和500+个训练模型在四个场景中的评估。

Result: 动作空间确实对机器人策略学习有显著且复杂的影响。设计策略预测增量动作能持续提升性能，而关节空间和任务空间表示各有优势：关节空间有利于控制稳定性，任务空间有利于泛化能力。

Conclusion: 动作空间设计在机器人策略学习中至关重要，需要系统性地考虑时间和空间维度的设计选择。增量动作表示通常更优，而关节空间和任务空间参数化各有适用场景，应根据具体需求平衡控制稳定性和泛化能力。

Abstract: The specification of the action space plays a pivotal role in imitation-based robotic manipulation policy learning, fundamentally shaping the optimization landscape of policy learning. While recent advances have focused heavily on scaling training data and model capacity, the choice of action space remains guided by ad-hoc heuristics or legacy designs, leading to an ambiguous understanding of robotic policy design philosophies. To address this ambiguity, we conducted a large-scale and systematic empirical study, confirming that the action space does have significant and complex impacts on robotic policy learning. We dissect the action design space along temporal and spatial axes, facilitating a structured analysis of how these choices govern both policy learnability and control stability. Based on 13,000+ real-world rollouts on a bimanual robot and evaluation on 500+ trained models over four scenarios, we examine the trade-offs between absolute vs. delta representations, and joint-space vs. task-space parameterizations. Our large-scale results suggest that properly designing the policy to predict delta actions consistently improves performance, while joint-space and task-space representations offer complementary strengths, favoring control stability and generalization, respectively.

</details>


### [104] [Printed helicoids with embedded air channels make sensorized segments for soft continuum robots](https://arxiv.org/abs/2602.23457)
*Annan Zhang,Hanna Matusik,Miguel Flores-Acton,Emily R. Sologuren,Joshua Jacob,Daniela Rus*

Main category: cs.RO

TL;DR: 提出了一种在螺旋晶格软体机器人中嵌入空气通道的制造方法，实现分布式变形感知，并构建了米级14自由度软体臂进行验证


<details>
  <summary>Details</summary>
Motivation: 软体机器人虽然能与复杂环境安全交互，但由于高度可变形的结构，传感和控制仍然困难。螺旋晶格等结构化软材料具有可调刚度和强度，但因其稀疏几何结构而难以集成传感器

Method: 采用视觉控制喷射的多材料3D打印技术，在螺旋晶格软体机器人中嵌入空气通道，并与PCB板集成，PCB板上装有微型压力传感器和IMU，实现分布式变形感知

Result: 表征了四种螺旋晶格设计的机械性能，验证了传感器对基本变形模式的响应。构建了米级14自由度电缆驱动软体臂，能够进行开环轨迹跟踪和物体抓取，并利用夹持器传感器实现了基于触觉的刚度检测

Conclusion: 该方法为大规模软体机器人系统中的传感器化结构化材料建立了可扩展的制造策略

Abstract: Soft robots enable safe, adaptive interaction with complex environments but remain difficult to sense and control due to their highly deformable structures. Architected soft materials such as helicoid lattices offer tunable stiffness and strength but are challenging to instrument because of their sparse geometry. We introduce a fabrication method for embedding air channels into helicoid-based soft continuum robots. Multi-material segments fabricated via vision-controlled jetting in a single print interface with PCBs housing miniature pressure sensors and IMUs for distributed deformation sensing. We characterize the mechanical properties of four helicoid designs and validate the sensor response to fundamental deformation modes. To demonstrate the platform's scalability, we construct and mechanically evaluate a meter-scale, 14-DoF cable-driven soft arm capable of open-loop trajectory tracking and object grasping, with tactile-based stiffness detection demonstrated using the gripper sensors. This approach establishes a scalable fabrication strategy for sensorized architected materials in large-scale soft robotic systems.

</details>


### [105] [Refining Almost-Safe Value Functions on the Fly](https://arxiv.org/abs/2602.23478)
*Sander Tonkens,Sosuke Kojima,Chenhao Liu,Judy Masri,Sylvia Herbert*

Main category: cs.RO

TL;DR: 该论文提出refineCBF和HJ-Patch两种方法，通过热启动的Hamilton-Jacobi可达性分析在线精化近似控制屏障函数，实现实时安全适应，应用于地面车辆和四旋翼无人机应对环境变化。


<details>
  <summary>Details</summary>
Motivation: 控制屏障函数是确保机器人安全的有力工具，但为复杂系统设计或学习有效的CBF具有挑战性。Hamilton-Jacobi可达性分析虽然能形式化合成安全值函数，但扩展性差且通常离线执行，限制了在动态环境中的应用。需要弥合离线合成与在线适应之间的差距。

Method: 1. 提出refineCBF方法：通过热启动的HJ可达性分析精化近似CBF（无论是解析推导、学习得到还是甚至不安全的CBF）；2. 提出HJ-Patch方法：通过局部化更新加速这一过程；3. 两种方法都能保证恢复安全值函数，并确保适应过程中的单调安全改进。

Result: 实验验证了框架的主要贡献：在回路中的实时适应能力，包括仿真（详细值函数分析）和物理硬件测试。地面车辆和四旋翼无人机的实验表明，该框架能成功适应突然的环境变化，如新障碍物和未建模的风扰动。

Conclusion: 该研究为在实际部署中实现形式化保证的安全提供了一条实用路径，通过在线精化CBF的方法，使机器人系统能够在动态环境中实时适应并保持安全。

Abstract: Control Barrier Functions (CBFs) are a powerful tool for ensuring robotic safety, but designing or learning valid CBFs for complex systems is a significant challenge. While Hamilton-Jacobi Reachability provides a formal method for synthesizing safe value functions, it scales poorly and is typically performed offline, limiting its applicability in dynamic environments. This paper bridges the gap between offline synthesis and online adaptation. We introduce refineCBF for refining an approximate CBF - whether analytically derived, learned, or even unsafe - via warm-started HJ reachability. We then present its computationally efficient successor, HJ-Patch, which accelerates this process through localized updates. Both methods guarantee the recovery of a safe value function and can ensure monotonic safety improvements during adaptation. Our experiments validate our framework's primary contribution: in-the-loop, real-time adaptation, in simulation (with detailed value function analysis) and on physical hardware. Our experiments on ground vehicles and quadcopters show that our framework can successfully adapt to sudden environmental changes, such as new obstacles and unmodeled wind disturbances, providing a practical path toward deploying formally guaranteed safety in real-world settings.

</details>


### [106] [TaCarla: A comprehensive benchmarking dataset for end-to-end autonomous driving](https://arxiv.org/abs/2602.23499)
*Tugrul Gorgulu,Atakan Dag,M. Esat Kalfaoglu,Halil Ibrahim Kuru,Baris Can Cam,Ozsel Kilinc*

Main category: cs.RO

TL;DR: 该论文提出了一个新的CARLA仿真数据集，包含285万帧数据，专门为自动驾驶研究设计，支持感知、规划、预测等多种任务，并提供了场景稀有度评分。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶数据集存在局限性：感知数据集缺乏规划数据，规划数据集行为多样性有限，且缺乏闭环评估设置。CARLA Leaderboard 2.0虽然提供了多样化场景，但现有数据集传感器配置有限，无法满足端到端自动驾驶研究需求。

Method: 使用CARLA仿真环境收集新数据集，覆盖Leaderboard 2.0挑战的多样化场景，包含超过285万帧数据。数据集不仅支持规划任务，还支持动态物体检测、车道线检测、中心线检测、交通灯识别、预测任务和视觉语言动作模型。同时提供数值稀有度评分来衡量当前状态在数据集中的罕见程度。

Result: 创建了一个包含285万帧的综合性自动驾驶数据集，覆盖多种传感器配置和任务需求。通过在该数据集上训练多种模型，证明了其多功能性和实用性。稀有度评分机制有助于理解数据分布特性。

Conclusion: 该数据集填补了现有自动驾驶数据集的空白，为端到端自动驾驶研究提供了全面的数据支持，特别是在感知-规划一体化、闭环评估和长尾问题处理方面具有重要价值。

Abstract: Collecting a high-quality dataset is a critical task that demands meticulous attention to detail, as overlooking certain aspects can render the entire dataset unusable. Autonomous driving challenges remain a prominent area of research, requiring further exploration to enhance the perception and planning performance of vehicles. However, existing datasets are often incomplete. For instance, datasets that include perception information generally lack planning data, while planning datasets typically consist of extensive driving sequences where the ego vehicle predominantly drives forward, offering limited behavioral diversity. In addition, many real datasets struggle to evaluate their models, especially for planning tasks, since they lack a proper closed-loop evaluation setup. The CARLA Leaderboard 2.0 challenge, which provides a diverse set of scenarios to address the long-tail problem in autonomous driving, has emerged as a valuable alternative platform for developing perception and planning models in both open-loop and closed-loop evaluation setups. Nevertheless, existing datasets collected on this platform present certain limitations. Some datasets appear to be tailored primarily for limited sensor configuration, with particular sensor configurations. To support end-to-end autonomous driving research, we have collected a new dataset comprising over 2.85 million frames using the CARLA simulation environment for the diverse Leaderboard 2.0 challenge scenarios. Our dataset is designed not only for planning tasks but also supports dynamic object detection, lane divider detection, centerline detection, traffic light recognition, prediction tasks and visual language action models . Furthermore, we demonstrate its versatility by training various models using our dataset. Moreover, we also provide numerical rarity scores to understand how rarely the current state occurs in the dataset.

</details>


### [107] [V-MORALS: Visual Morse Graph-Aided Estimation of Regions of Attraction in a Learned Latent Space](https://arxiv.org/abs/2602.23524)
*Faiz Aladin,Ashwin Balasubramanian,Lars Lindemann,Daniel Seita*

Main category: cs.RO

TL;DR: V-MORALS提出了一种基于视觉的吸引域估计方法，通过图像轨迹数据在潜在空间中学习可达性分析，无需系统动力学模型或完整状态信息。


<details>
  <summary>Details</summary>
Motivation: 现有可达性和安全性分析方法存在三个主要问题：1）需要已知系统动力学或大量数据来估计准确模型；2）计算成本高；3）假设完整状态信息。MORALS方法虽然使用拓扑工具在低维潜在空间中估计吸引域，但仍依赖完整状态知识，且未研究仅使用传感器测量的情况。

Method: V-MORALS接收给定控制器下系统的图像轨迹数据集，学习用于可达性分析的潜在空间。利用这个学习到的潜在空间，该方法能够生成定义良好的莫尔斯图，从中可以计算各种系统和控制器的吸引域。

Result: V-MORALS提供了与原始MORALS架构类似的能力，但无需依赖状态知识，仅使用高级传感器数据（图像）。

Conclusion: 该方法解决了现有可达性分析方法的局限性，特别是在仅使用传感器测量（如图像）的情况下，为机器人安全分析提供了更实用的解决方案。

Abstract: Reachability analysis has become increasingly important in robotics to distinguish safe from unsafe states. Unfortunately, existing reachability and safety analysis methods often fall short, as they typically require known system dynamics or large datasets to estimate accurate system models, are computationally expensive, and assume full state information. A recent method, called MORALS, aims to address these shortcomings by using topological tools to estimate3DR-eEgnciodnesr of Attraction (ROA) in a low-dimensional latent space. However, MORALS still relies on full state knowledge and has not been studied when only sensor measurements are available. This paper presents Visual Morse Graph-Aided Estimation of Regions of Attraction in a Learned Latent Space (V- MORALS). V-MORALS takes in a dataset of image-based trajectories of a system under a given controller, and learns a latent space for reachability analysis. Using this learned latent space, our method is able to generate well-defined Morse Graphs, from which we can compute ROAs for various systems and controllers. V-MORALS provides capabilities similar to the original MORALS architecture without relying on state knowledge, and using only high-level sensor data. Our project website is at: https://v-morals.onrender.com.

</details>


### [108] [Tilt-X: Enabling Compliant Aerial Manipulation through a Tiltable-Extensible Continuum Manipulator](https://arxiv.org/abs/2602.23576)
*Anuraj Uthayasooriyan,Krishna Manaswi Digumarti,Jack Breward,Fernando Vanegas,Julian Galvez-Serna,Felipe Gonzalez*

Main category: cs.RO

TL;DR: Tilt-X是一种新型连续臂空中机械手，通过倾斜机构、伸缩平台和缆绳驱动连续臂设计，解决了传统空中机械手只能向下操作、易受螺旋桨下洗流影响的限制，实现了多方向操作能力。


<details>
  <summary>Details</summary>
Motivation: 现有连续臂空中机械手系统存在两个主要限制：1）只能在无人机下方进行操作，限制了多方向部署和通过复杂环境的能力；2）对螺旋桨下洗流敏感，影响操作精度和稳定性。

Method: 提出Tilt-X系统，整合了三个关键组件：1）倾斜机构实现平面方向调整（0°-90°）；2）伸缩平台提供75mm的延伸距离；3）缆绳驱动连续臂实现轻量化和柔顺操作。建立了系统的运动学模型并通过飞行演示进行验证。

Result: Tilt-X实现了体积工作空间，具有75mm延伸能力和0°-90°平面方向调整范围。实验比较了有/无下洗流情况下的末端执行器位姿精度，结果显示当机械臂延伸出螺旋桨影响区域时，末端执行器位姿得到稳定。

Conclusion: Tilt-X系统通过创新的倾斜和伸缩设计，显著提升了空中机械手的操作灵活性和抗干扰能力，为可靠空中机械手的设计和控制提供了重要指导依据。

Abstract: Aerial manipulators extend the reach and manipulation capabilities of uncrewed multirotor aerial vehicles for inspection, agriculture, sampling, and delivery. Continuum arm aerial manipulation systems offer lightweight, dexterous, and compliant interaction opportunities. Existing designs allow manipulation only below the UAV which restricts their deployability in multiple directions and through clutter. They are also sensitive to propeller downwash. Addressing these limitations, we present Tilt-X, a continuum arm aerial manipulator that integrates a tilting mechanism, a telescopic stage, and a cable-driven continuum section. We present its design and kinematic model and validate it through flight demonstrations. Tilt-X enables a volumetric workspace with up to 75 mm extension and planar orientations between 0$^\circ$ to 90$^\circ$. Experiments comparing end effector pose with and without downwash quantitatively measure its accuracy, providing critical evidence to guide the design and control of reliable aerial manipulators. Results show stabilisation of end effector pose as the manipulator extends out of the propeller influence zone.

</details>


### [109] [VCA: Vision-Click-Action Framework for Precise Manipulation of Segmented Objects in Target Ambiguous Environments](https://arxiv.org/abs/2602.23583)
*Donggeon Kim,Seungwon Jan,Hyeonjun Park,Daegyu Lim*

Main category: cs.RO

TL;DR: VCA框架用点击式视觉交互替代语言指令，解决VLA模型中语言带来的模糊性、认知负担和精确物体识别问题，实现更有效的机器人操作


<details>
  <summary>Details</summary>
Motivation: VLA模型依赖语言指令会引入模糊性、增加认知负担，在存在多个视觉相似物体的环境中难以精确识别对象和执行顺序任务

Method: 提出Vision-Click-Action框架，使用预训练分割模型，通过点击机器人2D相机视图中的目标物体来替代冗长的文本命令，实现直接的视觉交互

Result: 实验验证VCA框架能够有效实现指定目标物体的实例级操作，减少解释错误，降低认知负荷

Conclusion: VCA为现实世界机器人操作提供了一个实用且可扩展的替代语言驱动界面的方案

Abstract: The reliance on language in Vision-Language-Action (VLA) models introduces ambiguity, cognitive overhead, and difficulties in precise object identification and sequential task execution, particularly in environments with multiple visually similar objects. To address these limitations, we propose Vision-Click-Action (VCA), a framework that replaces verbose textual commands with direct, click-based visual interaction using pretrained segmentation models. By allowing operators to specify target objects clearly through visual selection in the robot's 2D camera view, VCA reduces interpretation errors, lowers cognitive load, and provides a practical and scalable alternative to language-driven interfaces for real-world robotic manipulation. Experimental results validate that the proposed VCA framework achieves effective instance-level manipulation of specified target objects. Experiment videos are available at https://robrosinc.github.io/vca/.

</details>


### [110] [KEEP: A KV-Cache-Centric Memory Management System for Efficient Embodied Planning](https://arxiv.org/abs/2602.23592)
*Zebin Yang,Tong Xie,Baotong Lu,Shaoshan Liu,Bo Yu,Meng Li*

Main category: cs.RO

TL;DR: KEEP是一个基于KV缓存的记忆管理系统，用于高效的大语言模型具身规划，通过创新的内存管理技术实现了2.68倍加速和可忽略的精度损失。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的记忆方法会导致过长的提示和高昂的预填充延迟，而基于KV缓存的方法由于频繁的缓存更新而效率受限，需要更高效的记忆管理系统。

Method: 提出KEEP系统，包含三个关键技术：1）静态-动态内存构建算法，通过混合粒度内存组减少KV缓存重计算；2）多跳内存重计算算法，动态识别不同内存组间的重要交叉注意力并迭代重建内存交互；3）层平衡内存加载，消除不同层间不平衡的KV缓存加载和交叉注意力计算。

Result: 在ALFRED数据集上，KEEP相比基于文本的记忆方法实现了2.68倍加速且精度损失可忽略；相比KV重计算方法CacheBlend，提升了4.13%的成功率并减少了1.90倍的首次令牌时间。

Conclusion: KEEP通过创新的KV缓存中心化内存管理系统，有效解决了具身规划中记忆管理的效率问题，在保持高准确性的同时显著提升了推理速度。

Abstract: Memory-augmented Large Language Models (LLMs) have demonstrated remarkable capability for complex and long-horizon embodied planning. By keeping track of past experiences and environmental states, memory enables LLMs to maintain a global view, thereby avoiding repetitive exploration. However, existing approaches often store the memory as raw text, leading to excessively long prompts and high prefill latency. While it is possible to store and reuse the KV caches, the efficiency benefits are greatly undermined due to frequent KV cache updates. In this paper, we propose KEEP, a KV-cache-centric memory management system for efficient embodied planning. KEEP features 3 key innovations: (1) a Static-Dynamic Memory Construction algorithm that reduces KV cache recomputation by mixed-granularity memory group; (2) a Multi-hop Memory Re-computation algorithm that dynamically identifies important cross-attention among different memory groups and reconstructs memory interactions iteratively; (3) a Layer-balanced Memory Loading that eliminates unbalanced KV cache loading and cross-attention computation across different layers. Extensive experimental results have demonstrated that KEEP achieves 2.68x speedup with negligible accuracy loss compared with text-based memory methods on ALFRED dataset. Compared with the KV re-computation method CacheBlend (EuroSys'25), KEEP shows 4.13% success rate improvement and 1.90x time-to-first-token (TTFT) reduction. Our code is available on https://github.com/PKU-SEC-Lab/KEEP_Embodied_Memory.

</details>


### [111] [MicroPush: A Simulator and Benchmark for Contact-Rich Cell Pushing and Assembly with a Magnetic Rolling Microrobot](https://arxiv.org/abs/2602.23607)
*Yanda Yang,Sambeeta Das*

Main category: cs.RO

TL;DR: MicroPush是一个用于磁性滚动微机器人在杂乱2D场景中的开源模拟器和基准测试套件，专注于接触丰富的微操作任务。


<details>
  <summary>Details</summary>
Motivation: 磁性滚动微机器人在受限微流体环境中能够实现温和操作，但接触丰富行为（如细胞推动和多目标组装）的自主性难以开发和可重复评估。

Method: 结合过阻尼相互作用模型与接触感知的粘滑效应、轻量级近场阻尼、可选泊肃叶背景流，以及从驱动频率到自由空间滚动速度的校准映射。提供模块化规划-控制堆栈，采用两阶段策略进行接触建立和目标导向推动。

Result: 结果显示控制器稳定性在流动扰动下主导性能，而规划器选择可以通过路径点进展影响长时域序列的命令平滑度。报告了成功率、时间、跟踪指标和驱动变化度量E_Δω。

Conclusion: MicroPush能够实现微尺度接触丰富微操作的规划、控制和学习方法的可重复比较和消融研究。

Abstract: Magnetic rolling microrobots enable gentle manipulation in confined microfluidic environments, yet autonomy for contact-rich behaviors such as cell pushing and multi-target assembly remains difficult to develop and evaluate reproducibly. We present MicroPush, an open-source simulator and benchmark suite for magnetic rolling microrobots in cluttered 2D scenes. MicroPush combines an overdamped interaction model with contact-aware stick--slip effects, lightweight near-field damping, optional Poiseuille background flow, and a calibrated mapping from actuation frequency to free-space rolling speed. On top of the simulator core, we provide a modular planning--control stack with a two-phase strategy for contact establishment and goal-directed pushing, together with a deterministic benchmark protocol with fixed tasks, staged execution, and unified CSV logging for single-object transport and hexagonal assembly. We report success, time, and tracking metrics, and an actuation-variation measure $E_{Δω}$. Results show that controller stability dominates performance under flow disturbances, while planner choice can influence command smoothness over long-horizon sequences via waypoint progression. MicroPush enables reproducible comparison and ablation of planning, control, and learning methods for microscale contact-rich micromanipulation.

</details>


### [112] [FAVLA: A Force-Adaptive Fast-Slow VLA model for Contact-Rich Robotic Manipulation](https://arxiv.org/abs/2602.23648)
*Yao Li,Peiyuan Tang,Wuyang Zhang,Chengyang Zhu,Yifan Duan,Weikai Shi,Xiaodong Zhang,Zijiang Yang,Jianmin Ji,Yanyong Zhang*

Main category: cs.RO

TL;DR: FAVLA提出了一种力自适应快慢VLA模型，通过解耦慢速感知规划和快速接触感知控制，解决了传统统一频率融合方法在接触丰富操作中的延迟响应问题。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型通常将所有模态以单一频率融合，忽略了机器人传感器的不同采样率，导致高频率接触信号被降采样。结合常见的VLM-动作专家流水线在昂贵的VLM更新之间基本开环执行动作块，统一频率融合往往对冲击、粘滑和力峰值产生延迟响应。

Method: FAVLA采用力自适应快慢架构：1) 慢速VLM以固定低频运行，编码多模态产生潜在表示并预测近未来力变化；2) 快速AE以可变高频执行，基于最新力序列数据生成反应性动作；3) 引入力适配器将高频力特征注入多个AE层；4) 基于VLM预测的力变化自适应调度AE执行频率。

Result: 在接触丰富的任务上进行大量实验表明，FAVLA显著优于基线方法，实现了更好的反应性和成功率，特别是在操作过程中使用更小的接触力时表现更优。

Conclusion: 通过解耦慢速感知规划和快速接触感知控制，FAVLA能够有效处理机器人传感器频率不匹配问题，在接触丰富的操作任务中实现更及时的反应和更高的成功率。

Abstract: Force/torque feedback can substantially improve Vision-Language-Action (VLA) models on contact-rich manipulation, but most existing approaches fuse all modalities at a single operating frequency. This design ignores the mismatched sampling rates of real robot sensors, forcing downsampling of the high-frequency contact cues needed for reactive correction. Combined with common VLM-action-expert (AE) pipelines that execute action chunks largely open loop between expensive VLM updates, unified-frequency fusion often yields delayed responses to impacts, stick-slip, and force spikes. We propose FAVLA, a force-adaptive fast-slow VLA that decouples slow perception planning from fast contact-aware control. FAVLA runs a slow VLM at a fixed low frequency to encode modalities to produce latent representations and to predict near-future force variation. A fast AE then executes at a variable high frequency, conditioning on the latest force sequence data to generate reactive actions. We further introduce a force adapter that injects high-frequency force features into multiple AE layers, and adaptively schedules the AE's execution frequency based on the VLM's predicted force variation. Extensive experiments on contact-rich tasks demonstrate that FAVLA significantly outperforms baselines, achieving superior reactivity and success rates, especially with a smaller contact force during manipulation.

</details>


### [113] [Interpretable Multimodal Gesture Recognition for Drone and Mobile Robot Teleoperation via Log-Likelihood Ratio Fusion](https://arxiv.org/abs/2602.23694)
*Seungyeol Baek,Jaspreet Singh,Lala Shakti Swarup Ray,Hymalai Bello,Paul Lukowicz,Sungho Suh*

Main category: cs.RO

TL;DR: 提出基于Apple Watch惯性数据和定制手套电容传感的多模态手势识别框架，用于无人机和移动机器人的免手持遥操作，性能媲美视觉基线但计算成本更低。


<details>
  <summary>Details</summary>
Motivation: 操作人员在危险环境中需要免手持遥操作移动机器人和无人机，现有视觉手势识别在遮挡、光照变化和杂乱背景中性能下降，限制了实际应用。

Method: 提出多模态手势识别框架，集成双腕Apple Watch的惯性数据（加速度计、陀螺仪、方向）和定制手套的电容传感信号，采用基于对数似然比（LLR）的后期融合策略。

Result: 框架性能与最先进的视觉基线相当，同时显著降低计算成本、模型大小和训练时间，适合实时机器人控制。

Conclusion: 传感器多模态融合为手势驱动的移动机器人和无人机遥操作提供了鲁棒且可解释的解决方案。

Abstract: Human operators are still frequently exposed to hazardous environments such as disaster zones and industrial facilities, where intuitive and reliable teleoperation of mobile robots and Unmanned Aerial Vehicles (UAVs) is essential. In this context, hands-free teleoperation enhances operator mobility and situational awareness, thereby improving safety in hazardous environments. While vision-based gesture recognition has been explored as one method for hands-free teleoperation, its performance often deteriorates under occlusions, lighting variations, and cluttered backgrounds, limiting its applicability in real-world operations. To overcome these limitations, we propose a multimodal gesture recognition framework that integrates inertial data (accelerometer, gyroscope, and orientation) from Apple Watches on both wrists with capacitive sensing signals from custom gloves. We design a late fusion strategy based on the log-likelihood ratio (LLR), which not only enhances recognition performance but also provides interpretability by quantifying modality-specific contributions. To support this research, we introduce a new dataset of 20 distinct gestures inspired by aircraft marshalling signals, comprising synchronized RGB video, IMU, and capacitive sensor data. Experimental results demonstrate that our framework achieves performance comparable to a state-of-the-art vision-based baseline while significantly reducing computational cost, model size, and training time, making it well suited for real-time robot control. We therefore underscore the potential of sensor-based multimodal fusion as a robust and interpretable solution for gesture-driven mobile robot and drone teleoperation.

</details>


### [114] [A Reliable Indoor Navigation System for Humans Using AR-based Technique](https://arxiv.org/abs/2602.23706)
*Vijay U. Rathod,Manav S. Sharma,Shambhavi Verma,Aadi Joshi,Sachin Aage,Sujal Shahane*

Main category: cs.RO

TL;DR: 该论文提出了一种基于AR的室内导航系统，结合Vuforia环境建模、AI导航的NavMesh组件和A*算法，相比传统方法显著提升了导航精度和用户体验。


<details>
  <summary>Details</summary>
Motivation: 室内环境如校园和小型区域缺乏可靠的导航系统，用户只能依赖混乱、耗时的静态标识或楼层地图，需要更直观、高效的导航解决方案。

Method: 使用Vuforia Area Target进行环境建模，采用AI导航的NavMesh组件进行导航规划，在组件内部使用A*算法计算最短路径。相比Dijkstra算法，A*在较小搜索空间中快2-3倍，更适合高复杂度环境。

Result: 实验结果显示导航精度显著提升，用户体验更好，效率高于传统方法。AR技术与现有路径规划算法结合可行且可扩展，为用户提供了友好的室内导航解决方案。

Conclusion: AR技术与路径规划算法集成在有限定义的室内空间中非常有效，但NavMesh在大型或高度动态环境中需要进一步优化。该系统为室内导航提供了可行的用户友好解决方案。

Abstract: Reliable navigation systems are not available indoors, such as in campuses and small areas. Users must depend on confusing, time-consuming static signage or floor maps. In this paper, an AR-based technique has been applied to campus and small-site navigation, where Vuforia Area Target is used for environment modeling. AI navigation's NavMesh component is used for navigation purposes, and the A* algorithm is used within this component for shortest path calculation. Compared to Dijkstra's algorithm, it can reach a solution about two to three times faster for smaller search spaces. In many cases, Dijkstra's algorithm has difficulty performing well in high-complexity environments where memory usage grows and processing times increase. Compared to older approaches such as GPS, real-time processing and AR overlays can be combined to provide intuitive directions for users while dynamically updating the path in response to environmental changes. Experimental results indicate significantly improved navigation accuracy, better user experience, and greater efficiency compared to traditional methods. These results show that AR technology integrated with existing pathfinding algorithms is feasible and scalable, making it a user-friendly solution for indoor navigation. Although highly effective in limited and defined indoor spaces, further optimization of NavMesh is required for large or highly dynamic environments.

</details>


### [115] [SAGE-LLM: Towards Safe and Generalizable LLM Controller with Fuzzy-CBF Verification and Graph-Structured Knowledge Retrieval for UAV Decision](https://arxiv.org/abs/2602.23719)
*Wenzhe Zhao,Yang Zhao,Ganchao Liu,Zhiyu Jiang,Dandan Ma,Zihao Li,Xuelong Li*

Main category: cs.RO

TL;DR: 提出基于大语言模型的无训练双层决策架构，通过模糊控制屏障函数验证和星型层次图检索增强生成，提升无人机动态决策的安全性和泛化能力


<details>
  <summary>Details</summary>
Motivation: 无人机动态决策中复杂多变的危险因素对算法泛化能力构成严峻挑战，而大语言模型虽然具备语义理解和场景泛化能力，但缺乏特定领域控制知识和形式化安全保障，限制了其直接应用

Method: 提出无训练双层决策架构：高层安全规划与底层精确控制相结合；引入模糊控制屏障函数验证机制为LLM输出提供可证明的安全认证；采用星型层次图检索增强生成系统实现高效、弹性、可解释的场景适应

Result: 在具有未知障碍和突发威胁的追逃场景中进行系统实验验证，SAGE-LLM在保持性能的同时显著提升安全性和泛化能力，无需在线训练

Conclusion: 该框架展现出强大的可扩展性，有望推广到更广泛的具身智能系统和安全关键控制领域

Abstract: In UAV dynamic decision, complex and variable hazardous factors pose severe challenges to the generalization capability of algorithms. Despite offering semantic understanding and scene generalization, Large Language Models (LLM) lack domain-specific UAV control knowledge and formal safety assurances, restricting their direct applicability. To bridge this gap, this paper proposes a train-free two-layer decision architecture based on LLMs, integrating high-level safety planning with low-level precise control. The framework introduces three key contributions: 1) A fuzzy Control Barrier Function verification mechanism for semantically-augmented actions, providing provable safety certification for LLM outputs. 2) A star-hierarchical graph-based retrieval-augmented generation system, enabling efficient, elastic, and interpretable scene adaptation. 3) Systematic experimental validation in pursuit-evasion scenarios with unknown obstacles and emergent threats, demonstrating that our SAGE-LLM maintains performance while significantly enhancing safety and generalization without online training. The proposed framework demonstrates strong extensibility, suggesting its potential for generalization to broader embodied intelligence systems and safety-critical control domains.

</details>


### [116] [Acceleration-Based Control of Fixed-Wing UAVs for Guidance Applications](https://arxiv.org/abs/2602.23821)
*Jixiang Wang,Siyuan Yang,Ziyi Wu,Siqi Wei,Ashay Wakode,Agata Barcis,Hung Nguyen,Shaoming He*

Main category: cs.RO

TL;DR: 该论文提出了一种加速度指令外环控制框架，将切向和法向加速度命令转换为可执行的机体角速率和归一化推力命令，使加速度指令制导律（如比例导引）能直接部署在固定翼无人机上。


<details>
  <summary>Details</summary>
Motivation: 加速度指令制导律（如比例导引）对于高层决策很有吸引力，但直接部署在固定翼无人机上具有挑战性，因为加速度不是直接驱动的，必须在飞行包线约束下通过姿态和推力实现。现有方法需要复杂的推进系统建模或推力台校准。

Method: 1. 法向通道：在假设小角度条件下，推导从期望法向加速度到滚转和俯仰速率命令的工程映射，调节升力矢量的方向和大小。2. 切向通道：引入基于能量的公式（受总能量控制启发），直接从飞行数据中识别经验推力-能量加速度关系，避免显式推进建模或推力台校准。3. 讨论饱和和非水平机动下法向与切向加速度之间的优先级处理。

Result: 在VTOL固定翼平台上进行了大量实际飞行实验，展示了精确的加速度跟踪能力，并实现了仅使用机体角速率和归一化推力接口的比例导引实际应用。

Conclusion: 该加速度级外环控制框架成功地将加速度命令转换为与主流自动驾驶仪（如PX4/APM）兼容的可执行命令，使加速度指令制导律能够直接部署在固定翼无人机上，无需复杂的推进系统建模。

Abstract: Acceleration-commanded guidance laws (e.g., proportional navigation) are attractive for high-level decision making, but their direct deployment on fixed-wing UAVs is challenging because accelerations are not directly actuated and must be realized through attitude and thrust under flight-envelope constraints. This paper presents an acceleration-level outer-loop control framework that converts commanded tangential and normal accelerations into executable body-rate and normalized thrust commands compatible with mainstream autopilots (e.g., PX4/APM). For the normal channel, we derive an engineering mapping from the desired normal acceleration to roll- and pitch-rate commands that regulate the direction and magnitude of the lift vector under small-angle assumptions. For the tangential channel, we introduce an energy-based formulation inspired by total energy control and identify an empirical thrust-energy acceleration relationship directly from flight data, avoiding explicit propulsion modeling or thrust bench calibration. We further discuss priority handling between normal and tangential accelerations under saturation and non-level maneuvers. Extensive real-flight experiments on a VTOL fixed-wing platform demonstrate accurate acceleration tracking and enable practical implementation of proportional navigation using only body-rate and normalized thrust interfaces.

</details>


### [117] [OmniTrack: General Motion Tracking via Physics-Consistent Reference](https://arxiv.org/abs/2602.23832)
*Yuhan Li,Peiyuan Zhi,Yunshen Wang,Tengyu Liu,Sixu Yan,Wenyu Liu,Xinggang Wang,Baoxiong Jia,Siyuan Huang*

Main category: cs.RO

TL;DR: OmniTrack是一个两阶段框架，通过解耦物理可行性和运动跟踪，解决人形机器人运动跟踪中因形态差异和数据噪声导致的物理不可行问题，实现稳定、通用的运动控制。


<details>
  <summary>Details</summary>
Motivation: 人类与机器人之间的形态和动力学差异，加上数据噪声，会导致参考运动中出现物理不可行的伪影（如漂浮和穿透）。这些伪影在训练和执行过程中造成跟踪不准确参考运动与保持机器人稳定性之间的冲突，阻碍了通用运动跟踪策略的发展。

Method: OmniTrack采用两阶段框架：第一阶段，特权通用策略通过仿真中的轨迹展开生成严格遵循机器人动力学的物理可行运动；第二阶段，通用控制策略被训练来跟踪这些物理可行的运动，确保稳定和连贯的控制迁移到真实机器人。

Result: 实验表明OmniTrack提高了跟踪精度，并对未见运动表现出强大的泛化能力。在真实世界测试中，OmniTrack实现了长达数小时的一致稳定跟踪，包括复杂的杂技动作如空翻和侧手翻。此外，OmniTrack支持人类风格的稳定动态在线遥操作，突显其对不同用户输入的鲁棒性和适应性。

Conclusion: OmniTrack通过明确解耦物理可行性和通用运动跟踪，解决了人形机器人运动控制中的关键挑战，实现了稳定、通用且可迁移到真实机器人的运动跟踪框架。

Abstract: Learning motion tracking from rich human motion data is a foundational task for achieving general control in humanoid robots, enabling them to perform diverse behaviors. However, discrepancies in morphology and dynamics between humans and robots, combined with data noise, introduce physically infeasible artifacts in reference motions, such as floating and penetration. During both training and execution, these artifacts create a conflict between following inaccurate reference motions and maintaining the robot's stability, hindering the development of a generalizable motion tracking policy. To address these challenges, we introduce OmniTrack, a general tracking framework that explicitly decouples physical feasibility from general motion tracking. In the first stage, a privileged generalist policy generates physically plausible motions that strictly adhere to the robot's dynamics via trajectory rollout in simulation. In the second stage, the general control policy is trained to track these physically feasible motions, ensuring stable and coherent control transfer to the real robot. Experiments show that OmniTrack improves tracking accuracy and demonstrates strong generalization to unseen motions. In real-world tests, OmniTrack achieves hour-long, consistent, and stable tracking, including complex acrobatic motions such as flips and cartwheels. Additionally, we show that OmniTrack supports human-style stable and dynamic online teleoperation, highlighting its robustness and adaptability to varying user inputs.

</details>


### [118] [OmniXtreme: Breaking the Generality Barrier in High-Dynamic Humanoid Control](https://arxiv.org/abs/2602.23843)
*Yunshen Wang,Shaohang Zhu,Peiyuan Zhi,Yuhan Li,Jiaxin Li,Yong-Lu Li,Yuchen Xiao,Xingxing Wang,Baoxiong Jia,Siyuan Huang*

Main category: cs.RO

TL;DR: OmniXtreme框架通过解耦通用运动技能学习与仿真到现实的物理技能精炼，解决了高动态人形控制中保真度与可扩展性的长期权衡问题。


<details>
  <summary>Details</summary>
Motivation: 当前策略在运动库多样性扩展时面临"通用性障碍"：随着运动库规模扩大，跟踪保真度不可避免地崩溃，特别是在高动态运动的现实部署中。这源于两个复合因素：多运动优化的学习瓶颈和现实执行中的物理可执行性约束。

Method: 引入OmniXtreme框架，将通用运动技能学习与仿真到现实的物理技能精炼解耦。使用具有高容量架构的流匹配策略扩展表示能力，避免干扰密集的多运动RL优化，然后进行执行器感知的精炼阶段，确保在物理硬件上的鲁棒性能。

Result: 广泛实验表明，OmniXtreme在多样高难度数据集上保持高保真度跟踪。在真实机器人上，统一策略成功执行多个极端运动，有效打破了高动态人形控制中长期存在的保真度-可扩展性权衡。

Conclusion: OmniXtreme通过解耦学习与精炼的方法，成功解决了高动态人形控制中的保真度-可扩展性权衡问题，为通用、人类级别运动技能的规模化学习提供了可行方案。

Abstract: High-fidelity motion tracking serves as the ultimate litmus test for generalizable, human-level motor skills. However, current policies often hit a "generality barrier": as motion libraries scale in diversity, tracking fidelity inevitably collapses - especially for real-world deployment of high-dynamic motions. We identify this failure as the result of two compounding factors: the learning bottleneck in scaling multi-motion optimization and the physical executability constraints that arise in real-world actuation. To overcome these challenges, we introduce OmniXtreme, a scalable framework that decouples general motor skill learning from sim-to-real physical skill refinement. Our approach uses a flow-matching policy with high-capacity architectures to scale representation capacity without interference-intensive multi-motion RL optimization, followed by an actuation-aware refinement phase that ensures robust performance on physical hardware. Extensive experiments demonstrate that OmniXtreme maintains high-fidelity tracking across diverse, high-difficulty datasets. On real robots, the unified policy successfully executes multiple extreme motions, effectively breaking the long-standing fidelity-scalability trade-off in high-dynamic humanoid control.

</details>


### [119] [Hybrid Offline-Online Reinforcement Learning for Sensorless, High-Precision Force Regulation in Surgical Robotic Grasping](https://arxiv.org/abs/2602.23870)
*Edoardo Fazzari,Omar Mohamed,Khalfan Hableel,Hamdan Alhadhrami,Cesare Stefanini*

Main category: cs.RO

TL;DR: 该论文提出了一种无传感器控制框架，结合物理一致性建模和混合强化学习，实现了手术器械末端抓握力的高精度调节，无需远端力传感。


<details>
  <summary>Details</summary>
Motivation: 肌腱驱动手术器械的精确抓握力调节受到电机动力学、传动柔顺性、摩擦和远端力学之间非线性耦合的根本限制。现有解决方案通常依赖远端力传感或分析补偿，增加了硬件复杂性或在动态运动下性能下降。

Method: 提出无传感器控制框架，结合物理一致性建模和混合强化学习。开发达芬奇Xi抓握机构的第一原理数字孪生模型，捕捉耦合的电气、传动和钳口动力学。采用三阶段管道：(i)使用后退视野CMA-ES生成动态可行专家轨迹，(ii)通过隐式Q学习进行完全离线策略学习确保稳定初始化，(iii)使用TD3进行在线细化以适应在线策略动态。

Result: 在仿真中，控制器在多谐波钳口运动期间将抓握力保持在期望参考值的1%以内。硬件实验显示，在不同轨迹上的平均力误差低于4%，验证了仿真到现实的迁移。学习策略包含约71k参数，以kHz速率执行，支持实时部署。

Conclusion: 高保真建模结合结构化离线-在线强化学习可以在无需额外传感的情况下恢复精确的远端力行为，为手术机器人操作提供了可扩展且机械兼容的解决方案。

Abstract: Precise grasp force regulation in tendon-driven surgical instruments is fundamentally limited by nonlinear coupling between motor dynamics, transmission compliance, friction, and distal mechanics. Existing solutions typically rely on distal force sensing or analytical compensation, increasing hardware complexity or degrading performance under dynamic motion. We present a sensorless control framework that combines physics-consistent modeling and hybrid reinforcement learning to achieve high-precision distal force regulation in a proximally actuated surgical end-effector. We develop a first-principles digital twin of the da Vinci Xi grasping mechanism that captures coupled electrical, transmission, and jaw dynamics within a unified differential-algebraic formulation. To safely learn control policies in this stiff and highly nonlinear system, we introduce a three-stage pipeline:(i)a receding-horizon CMA-ES oracle that generates dynamically feasible expert trajectories,(ii)fully offline policy learning via Implicit Q-Learning to ensure stable initialization without unsafe exploration, and (iii)online refinement using TD3 for adaptation to on-policy dynamics. The resulting policy directly maps proximal measurements to motor voltages and requires no distal sensing. In simulation, the controller maintains grasp force within 1% of the desired reference during multi-harmonic jaw motion. Hardware experiments demonstrate average force errors below 4% across diverse trajectories, validating sim-to-real transfer. The learned policy contains approximately 71k param and executes at kH rates, enabling real-time deployment. These results demonstrate that high-fidelity modeling combined with structured offline-online RL can recover precise distal force behavior without additional sensing, offering a scalable and mechanically compatible solution for surgical robotic manipulation.

</details>


### [120] [TSC: Topology-Conditioned Stackelberg Coordination for Multi-Agent Reinforcement Learning in Interactive Driving](https://arxiv.org/abs/2602.23896)
*Xiaotong Zhang,Gang Xiong,Yuanjing Wang,Siyu Teng,Alois Knoll,Long Chen*

Main category: cs.RO

TL;DR: TSC框架通过提取轨迹间的编织关系构建时变有向优先级图，将密集交互分解为局部Stackelberg子博弈，在CTDE范式下学习顺序协调策略，提升密集交通中的训练稳定性和安全性。


<details>
  <summary>Details</summary>
Motivation: 解决密集交通中自动驾驶的分散式多智能体协调问题。现有MARL方法要么采用同步决策加剧非平稳性，要么依赖集中式排序机制在交通密度增加时扩展性差。

Method: 提出拓扑条件Stackelberg协调(TSC)框架：1)从轨迹编织关系中提取时变有向优先级图，定义局部领导者-跟随者依赖关系；2)基于该图将密集交互分解为图局部Stackelberg子博弈；3)在CTDE范式下，通过动作预测学习领导者，通过动作条件价值学习训练跟随者近似局部最优响应。

Result: 在四个密集交通场景中的实验表明，TSC在关键指标上优于代表性MARL基线，最显著的是减少碰撞，同时保持竞争力的交通效率和控制平滑性。

Conclusion: TSC通过提取局部优先级图并分解为Stackelberg子博弈，有效解决了密集交通中分散式交互驾驶的协调问题，提高了训练稳定性和安全性，无需全局排序机制。

Abstract: Safe and efficient autonomous driving in dense traffic is fundamentally a decentralized multi-agent coordination problem, where interactions at conflict points such as merging and weaving must be resolved reliably under partial observability. With only local and incomplete cues, interaction patterns can change rapidly, often causing unstable behaviors such as oscillatory yielding or unsafe commitments. Existing multi-agent reinforcement learning (MARL) approaches either adopt synchronous decision-making, which exacerbate non-stationarity, or depend on centralized sequencing mechanisms that scale poorly as traffic density increases. To address these limitations, we propose Topology-conditioned Stackelberg Coordination (TSC), a learning framework for decentralized interactive driving under communication-free execution, which extracts a time-varying directed priority graph from braid-inspired weaving relations between trajectories, thereby defining local leader-follower dependencies without constructing a global order of play. Conditioned on this graph, TSC endogenously factorizes dense interactions into graph-local Stackelberg subgames and, under centralized training and decentralized execution (CTDE), learns a sequential coordination policy that anticipates leaders via action prediction and trains followers through action-conditioned value learning to approximate local best responses, improving training stability and safety in dense traffic. Experiments across four dense traffic scenarios show that TSC achieves superior performance over representative MARL baselines across key metrics, most notably reducing collisions while maintaining competitive traffic efficiency and control smoothness.

</details>


### [121] [ABPolicy: Asynchronous B-Spline Flow Policy for Real-Time and Smooth Robotic Manipulation](https://arxiv.org/abs/2602.23901)
*Fan Yang,Peiguang Jing,Kaihua Qu,Ningyuan Zhao,Yuting Su*

Main category: cs.RO

TL;DR: ABPolicy是一种异步流匹配策略，通过在B样条控制点动作空间中操作来解决机器人操作中的平滑性和响应性问题，减少轨迹抖动并提高性能。


<details>
  <summary>Details</summary>
Motivation: 机器人操作需要平滑且能响应环境变化的策略，但原始动作空间中的同步推理会导致块内抖动、块间不连续和启停执行等问题，影响策略的平滑性和响应性。

Method: 提出ABPolicy异步流匹配策略，在B样条控制点动作空间中操作：1）B样条表示确保块内平滑性；2）引入双向动作预测结合重新拟合优化来强制块间连续性；3）利用异步推理实现实时连续更新。

Result: 在包含静态和动态环境的七个任务中评估ABPolicy，经验结果表明ABPolicy减少了轨迹抖动，实现了更平滑的运动并提高了性能。

Conclusion: ABPolicy通过B样条表示、双向预测和异步推理的组合，有效解决了机器人操作策略中的平滑性和响应性问题，为实时连续控制提供了有效解决方案。

Abstract: Robotic manipulation requires policies that are smooth and responsive to evolving observations. However, synchronous inference in the raw action space introduces several challenges, including intra-chunk jitter, inter-chunk discontinuities, and stop-and-go execution. These issues undermine a policy's smoothness and its responsiveness to environmental changes. We propose ABPolicy, an asynchronous flow-matching policy that operates in a B-spline control-point action space. First, the B-spline representation ensures intra-chunk smoothness. Second, we introduce bidirectional action prediction coupled with refitting optimization to enforce inter-chunk continuity. Finally, by leveraging asynchronous inference, ABPolicy delivers real-time, continuous updates. We evaluate ABPolicy across seven tasks encompassing both static settings and dynamic settings with moving objects. Empirical results indicate that ABPolicy reduces trajectory jerk, leading to smoother motion and improved performance. Project website: https://teee000.github.io/ABPolicy/.

</details>


### [122] [Teleoperated Omni-directional Dual Arm Mobile Manipulation Robotic System with Shared Control for Retail Store](https://arxiv.org/abs/2602.23923)
*Rolif Lima,Somdeb Saha,Nijil George,Vismay Vakharia,Shubham Parab,Sahil Gaonkar,Vighnesh Vatsal,Kaushik Das*

Main category: cs.RO

TL;DR: 提出了一种面向零售环境的全向双臂移动机器人系统，结合VR远程操作和异构夹爪设计，实现零售物品的灵活抓取


<details>
  <summary>Details</summary>
Motivation: 零售业快速发展，AI驱动的自主移动机器人面临动态零售产品环境的适应挑战，特别是在新情境下的自主操作困难

Method: 开发全向双臂移动机器人，采用VR运动捕捉系统实现人机共享控制远程操作，双臂配备异构夹爪以处理多样化物品

Result: 在模拟零售环境中验证了系统有效性，能够使用单臂和双臂协调操作技术处理各种常见零售物品

Conclusion: 提出的机器人系统和远程操作方法能够有效解决零售环境中机器人自主操作的适应性问题，提升零售自动化的灵活性

Abstract: The swiftly expanding retail sector is increasingly adopting autonomous mobile robots empowered by artificial intelligence and machine learning algorithms to gain an edge in the competitive market. However, these autonomous robots encounter challenges in adapting to the dynamic nature of retail products, often struggling to operate autonomously in novel situations. In this study, we introduce an omni-directional dual-arm mobile robot specifically tailored for use in retail environments. Additionally, we propose a tele-operation method that enables shared control between the robot and a human operator. This approach utilizes a Virtual Reality (VR) motion capture system to capture the operator's commands, which are then transmitted to the robot located remotely in a retail setting. Furthermore, the robot is equipped with heterogeneous grippers on both manipulators, facilitating the handling of a wide range of items. We validate the efficacy of the proposed system through testing in a mockup of retail environment, demonstrating its ability to manipulate various commonly encountered retail items using both single and dual-arm coordinated manipulation techniques.

</details>


### [123] [Learning to Build: Autonomous Robotic Assembly of Stable Structures Without Predefined Plans](https://arxiv.org/abs/2602.23934)
*Jingwen Wang,Johannes Kirschner,Paul Rolland,Luis Salamanca,Stefana Parascho*

Main category: cs.RO

TL;DR: 提出基于强化学习的自主机器人装配框架，无需预定义蓝图，通过目标和障碍定义任务，在15个2D离散块装配任务中验证可行性


<details>
  <summary>Details</summary>
Motivation: 传统机器人装配依赖预定义蓝图，缺乏对施工过程中环境不确定性和变化的适应性。需要更灵活、鲁棒的自主装配方法

Method: 使用基于深度Q学习和后继特征的强化学习策略作为决策组件，通过目标和障碍定义装配任务而非固定计划，实现闭环机器人系统

Result: 在15个2D机器人装配任务基准测试中验证了方法的可行性，真实世界闭环机器人实验表明能够处理施工噪声，展示了良好的适应性

Conclusion: 该框架为现实环境中更适应性强、鲁棒的机器人施工提供了有前景的方向，实现了无需预定义蓝图的自主装配

Abstract: This paper presents a novel autonomous robotic assembly framework for constructing stable structures without relying on predefined architectural blueprints. Instead of following fixed plans, construction tasks are defined through targets and obstacles, allowing the system to adapt more flexibly to environmental uncertainty and variations during the building process. A reinforcement learning (RL) policy, trained using deep Q-learning with successor features, serves as the decision-making component. As a proof of concept, we evaluate the approach on a benchmark of 15 2D robotic assembly tasks of discrete block construction. Experiments using a real-world closed-loop robotic setup demonstrate the feasibility of the method and its ability to handle construction noise. The results suggest that our framework offers a promising direction for more adaptable and robust robotic construction in real-world environments.

</details>


### [124] [Enhancing Vision-Language Navigation with Multimodal Event Knowledge from Real-World Indoor Tour Videos](https://arxiv.org/abs/2602.23937)
*Haoxuan Xu,Tianfu Li,Wenbo Chen,Yi Liu,Xingxing Zuo,Yaoxian Song,Haoang Li*

Main category: cs.RO

TL;DR: 提出基于事件中心知识增强的视觉语言导航方法，通过构建多模态时空知识图谱和分层检索机制，解决粗粒度指令和长时程推理问题


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航（VLN）智能体在未见环境中处理长时程推理和模糊粗粒度指令时存在困难。虽然已有研究使用知识图谱增强推理，但受人类情景记忆启发的多模态事件知识潜力尚未充分挖掘。

Method: 1. 构建YE-KG：首个大规模多模态时空知识图谱，包含超过8.6万个节点和8.3万条边，从真实室内视频中提取结构化语义-动作-效果事件作为显式情景记忆。2. 提出STE-VLN：通过粗到细分层检索机制将知识图谱集成到VLN模型中，使智能体能够检索因果事件序列并动态融合自我中心视觉观察。

Result: 在REVERIE、R2R和R2R-CE基准测试中表现出色，超越了现有最先进方法，证明了事件中心策略在不同动作空间中的有效性。

Conclusion: 提出的基于事件中心知识增强策略通过构建多模态时空知识图谱和分层检索机制，有效解决了VLN任务中的粗粒度指令理解和长时程推理问题，为智能体提供了类似人类情景记忆的推理能力。

Abstract: Vision-Language Navigation (VLN) agents often struggle with long-horizon reasoning in unseen environments, particularly when facing ambiguous, coarse-grained instructions. While recent advances use knowledge graph to enhance reasoning, the potential of multimodal event knowledge inspired by human episodic memory remains underexplored. In this work, we propose an event-centric knowledge enhancement strategy for automated process knowledge mining and feature fusion to solve coarse-grained instruction and long-horizon reasoning in VLN task. First, we construct YE-KG, the first large-scale multimodal spatiotemporal knowledge graph, with over 86k nodes and 83k edges, derived from real-world indoor videos. By leveraging multimodal large language models (i.e., LLaVa, GPT4), we extract unstructured video streams into structured semantic-action-effect events to serve as explicit episodic memory. Second, we introduce STE-VLN, which integrates the above graph into VLN models via a Coarse-to-Fine Hierarchical Retrieval mechanism. This allows agents to retrieve causal event sequences and dynamically fuse them with egocentric visual observations. Experiments on REVERIE, R2R, and R2R-CE benchmarks demonstrate the efficiency of our event-centric strategy, outperforming state-of-the-art approaches across diverse action spaces. Our data and code are available on the project website https://sites.google.com/view/y-event-kg/.

</details>


### [125] [Learning Robust Control Policies for Inverted Pose on Miniature Blimp Robots](https://arxiv.org/abs/2602.23972)
*Yuanlin Yang,Lin Hong,Fumin Zhang*

Main category: cs.RO

TL;DR: 提出一个三阶段框架，通过高保真仿真、强化学习和映射层实现微型飞艇机器人的倒立姿态控制


<details>
  <summary>Details</summary>
Motivation: 微型飞艇机器人(MBRs)的倒立姿态控制对于发挥其全部敏捷性至关重要，但由于其复杂和欠驱动的动力学特性，开发可靠的控制方法具有挑战性

Method: 三阶段框架：1)构建基于真实数据校准的高保真3D仿真环境；2)通过域随机化和改进的TD3算法在仿真中训练鲁棒控制策略；3)设计映射层来弥合仿真到现实的差距

Result: 仿真评估显示学习策略比能量整形控制器有更高的成功率；实验结果表明带映射层的学习策略能使MBR在真实环境中实现并保持完全倒立姿态

Conclusion: 提出的框架成功实现了微型飞艇机器人的倒立姿态控制，通过仿真训练和映射层设计有效解决了复杂动力学和仿真到现实转移的挑战

Abstract: The ability to achieve and maintain inverted poses is essential for unlocking the full agility of miniature blimp robots (MBRs). However, developing reliable control methods for MBRs remains challenging due to their complex and underactuated dynamics. To address this challenge, we propose a novel framework that enables robust control policy learning for inverted pose on MBRs. The proposed framework operates through three core stages: First, a high-fidelity three-dimensional (3D) simulation environment was constructed, which was calibrated against real-world MBR motion data to ensure accurate replication of inverted-state dynamics. Second, a robust policy for MBR inverted control was trained within the simulation environment via a domain randomization strategy and a modified Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm. Third, a mapping layer was designed to bridge the sim-to-real gap for the learned policy deployment. Comprehensive evaluations in the simulation environment demonstrate that the learned policy achieves a higher success rate compared to the energy-shaping controller. Furthermore, experimental results confirm that the learned policy with a mapping layer enables an MBR to achieve and maintain a fully upside-down pose in real-world settings.

</details>


### [126] [Geometry-based pneumatic actuators for soft robotics](https://arxiv.org/abs/2602.24104)
*Rui Chen,Daniele Leonardis,Domenico Chiaradia,Antonio Frisoli*

Main category: cs.RO

TL;DR: 提出几何基气动执行器(GPAs)，通过可配置CNC热封腔室实现复杂驱动模式，应用于腕部外骨骼、触觉接口和双足机器人


<details>
  <summary>Details</summary>
Motivation: 软气动执行器在安全人机交互方面有优势，但在复杂驱动模式方面存在设计限制，如最小弯曲半径、多状态能力和结构稳定性不足

Method: 采用几何基气动执行器(GPAs)设计方法，引入具有可配置CNC热封腔室的约束层，实现可预测变形、近零弯曲半径和多状态驱动

Result: 数学建模验证了可预测的线性角度变换和非线性扭矩-角度关系；49g腕部外骨骼减少肌肉活动达51%；30.8g触觉接口提供8N力反馈；208g双足机器人实现多步态运动

Conclusion: GPAs为下一代可穿戴机器人、触觉系统和软体运动设备建立了可配置平台，解决了传统软气动执行器的设计限制

Abstract: Soft pneumatic actuators enable safe human-machine interaction with lightweight and powerful applied parts. On the other side, they suffer design limitations as regards complex actuation patterns, including minimum bending radii, multi-states capabilities and structural stability. We present geometry-based pneumatic actuators (GPAs), a design and implementation approach that introduces constraint layers with configurable CNC heat-sealed chambers. The approach achieves predictable deformation, near-zero bending radii, multi-states actuation, and enables customizable and repeatable complex actuated geometries. Mathematical modeling reveals predictable linear angle transformations and validates nonlinear torque-angle relationships across diverse configurations. We demonstrate versatility of the GPAs approach through three applications: a 49 g wrist exoskeleton reducing muscle activity by up to 51%, a 30.8 g haptic interface delivering 8 N force feedback with fast response, and a 208 g bipedal robot achieving multi-gait locomotion. GPAs establish a configurable platform for next-generation wearable robotics, haptic systems, and soft locomotion devices.

</details>


### [127] [Planning from Observation and Interaction](https://arxiv.org/abs/2602.24121)
*Tyler Han,Siyang Shen,Rohan Baijal,Harine Ravichandiran,Bat Nemekhbold,Kevin Huang,Sanghun Jung,Byron Boots*

Main category: cs.RO

TL;DR: 提出基于规划的反向强化学习算法，仅通过观察和交互实现机器人世界建模，无需人工设计奖励或演示者动作，能在1小时内从零学习图像操作任务


<details>
  <summary>Details</summary>
Motivation: 解决机器人学习中的观察学习问题，在无法获取人工设计奖励和演示者动作的约束条件下，仅通过观察任务执行过程来学习

Method: 提出基于规划的反向强化学习算法，仅通过观察和交互进行世界建模，不依赖先验知识、预训练或额外数据

Result: 在真实世界中实验证明，该方法能在1小时内从零学习图像操作任务，样本效率和成功率显著优于现有IRL、RL和BC方法，并能实现在线迁移学习

Conclusion: 该方法为仅通过观察和交互进行在线世界建模和规划提供了实用路径，在数据受限的机器人学习场景中具有显著优势

Abstract: Observational learning requires an agent to learn to perform a task by referencing only observations of the performed task. This work investigates the equivalent setting in real-world robot learning where access to hand-designed rewards and demonstrator actions are not assumed. To address this data-constrained setting, this work presents a planning-based Inverse Reinforcement Learning (IRL) algorithm for world modeling from observation and interaction alone. Experiments conducted entirely in the real-world demonstrate that this paradigm is effective for learning image-based manipulation tasks from scratch in under an hour, without assuming prior knowledge, pre-training, or data of any kind beyond task observations. Moreover, this work demonstrates that the learned world model representation is capable of online transfer learning in the real-world from scratch. In comparison to existing approaches, including IRL, RL, and Behavior Cloning (BC), which have more restrictive assumptions, the proposed approach demonstrates significantly greater sample efficiency and success rates, enabling a practical path forward for online world modeling and planning from observation and interaction. Videos and more at: https://uwrobotlearning.github.io/mpail2/.

</details>


### [128] [Robust Skills, Brittle Grounding: Diagnosing Restricted Generalization in Vision-Language Action Policies via Multi-Object Picking](https://arxiv.org/abs/2602.24143)
*David Emukpere,Romain Deffayet,Jean-Michel Renders*

Main category: cs.RO

TL;DR: 该研究通过控制性多物体拾取实验发现，视觉语言动作策略在操作技能获取与指令跟随之间存在脱节，建议使用任务阶梯和分解指标来更好评估指令基础泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究视觉语言动作策略在操作基准测试中的强性能是否真正反映了稳健的语言到物体基础能力，还是仅仅依赖于训练分布中的物体-位置相关性，这种相关性在超出训练分布时无法迁移。

Method: 采用控制性多物体拾取研究，逐步增加物体放置变异性直至完全工作空间随机化，评估打破熟悉关联的保留物体-位置配对，同时不增加空间难度。对代表性VLA策略（包括SmolVLA和π₀.₅）进行压力测试和数据缩放分析。

Result: 研究发现，在较难的任务状态下，代表性VLA策略的操作原语执行可靠性显著高于指令条件化任务成功率，表明操作技能获取与指令跟随之间存在脱节。操作原语执行比指令条件化任务成功更为可靠。

Conclusion: 建议增强操作基准测试，加入任务阶梯和分解指标，分别测量原语执行和指令条件化成功率，以更好地诊断指令基础泛化能力。这有助于区分操作技能获取与真正的语言指令理解能力。

Abstract: Vision-language action (VLA) policies often report strong manipulation benchmark performance with relatively few demonstrations, but it remains unclear whether this reflects robust language-to-object grounding or reliance on object--location correlations that do not transfer beyond the training distribution. We present a controlled multi-object picking study that progressively increases object placement variability up to full workspace randomization and evaluates held-out object--location pairings that break familiar associations without increasing spatial difficulty. Across these stress tests and data scaling, we find that for representative VLA policies, including SmolVLA and $π_{0.5}$, execution of the manipulation primitive remains substantially more reliable than instruction-conditioned task success in harder regimes, suggesting that manipulation skill acquisition is decoupled from instruction following. We recommend augmenting manipulation benchmarks with task ladders and decomposed metrics that separately measure primitive execution and instruction-conditioned success to better diagnose instruction-grounded generalization.

</details>


### [129] [Humanoid Robots as First Assistants in Endoscopic Surgery](https://arxiv.org/abs/2602.24156)
*Sue Min Cho,Jan Emily Mangulabnan,Han Zhang,Zhekai Mao,Yufan He,Pengfei Guo,Daguang Xu,Gregory Hager,Masaru Ishii,Mathias Unberath*

Main category: cs.RO

TL;DR: 首个概念验证：人形机器人Unitree G1在尸体蝶窦切除术中成功提供内窥镜可视化辅助，证明了人形形态在手术辅助中的物理可行性


<details>
  <summary>Details</summary>
Motivation: 当前关于人形机器人手术能力的预测缺乏实证基础，尚无任何人形机器人实际辅助外科手术。本研究旨在打破这一空白，验证人形形态能否满足手术辅助的物理需求。

Method: 采用远程操作的Unitree G1人形机器人，在耳鼻喉科医生进行尸体蝶窦切除术时提供内窥镜可视化支持。通过远程操作评估人形形态在持久性和精确性方面能否满足手术辅助的物理要求。

Result: 手术成功完成，整个过程中保持了稳定的可视化。远程操作证实人形形态能够满足手术辅助的物理需求，而认知需求目前由操作员满足。术后分析确定了临床转化的工程目标。

Conclusion: 本研究确立了人形手术辅助的形态可行性，同时指出了持续开发面临的挑战，为自主诊断内窥镜等近期应用提供了机会。

Abstract: Humanoid robots have become a focal point of technological ambition, with claims of surgical capability within years in mainstream discourse. These projections are aspirational yet lack empirical grounding. To date, no humanoid has assisted a surgeon through an actual procedure, let alone performed one. The work described here breaks this new ground. Here we report a proof of concept in which a teleoperated Unitree G1 provided endoscopic visualization while an attending otolaryngologist performed a cadaveric sphenoidectomy. The procedure was completed successfully, with stable visualization maintained throughout. Teleoperation allowed assessment of whether the humanoid form factor could meet the physical demands of surgical assistance in terms of sustenance and precision; the cognitive demands were satisfied -- for now -- by the operator. Post-procedure analysis identified engineering targets for clinical translation, alongside near-term opportunities such as autonomous diagnostic scoping. This work establishes form-factor feasibility for humanoid surgical assistance while identifying challenges for continued development.

</details>


### [130] [How IMU Drift Influences Multi-Radar Inertial Odometry for Ground Robots in Subterranean Terrains](https://arxiv.org/abs/2602.24192)
*Moumita Mukherjee,Magnus Norén,Anton Koval,Avijit Banerjee,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 提出MRIO框架，结合IMU偏置估计器和雷达自速度估计，用于GPS拒止的地下环境中实现鲁棒的定位与建图，特别是在烟雾条件下优于传统EKF-RIO方法。


<details>
  <summary>Details</summary>
Motivation: 在地下环境中，低成本IMU（如Pixhawk）存在偏置漂移问题，而雷达数据稀疏、噪声大且闪烁，使得雷达惯性里程计融合不稳定。虽然激光雷达在烟雾、灰尘和气溶胶条件下失效，但FMCW雷达在这些情况下仍保持紧凑、轻量、经济且鲁棒的特性，因此需要解决IMU偏置漂移和雷达数据质量问题。

Method: 提出两阶段MRIO框架：1）使用最小二乘法进行雷达自速度估计，并集成到EKF中进行在线IMU偏置校正；2）将校正后的IMU加速度与多个雷达和IMU的异构测量值融合以优化里程计。该框架还支持仅使用雷达进行建图，利用估计的平移和旋转位移。

Result: 在地下实地测试中，MRIO实现了鲁棒的定位和建图，性能优于EKF-RIO。该方法在不同成本效益的FMCW雷达设置和不同IMU（包括Pixhawk和更高级的VectorNav）上均保持准确性，展现了良好的适应性。

Conclusion: MRIO框架有效解决了地下环境中IMU偏置漂移和雷达数据质量问题，在GPS拒止且存在烟雾的条件下实现了鲁棒的定位与建图。该方法对低成本硬件具有适应性，并将作为开源资源提供给社区。

Abstract: Reliable radar inertial odometry (RIO) requires mitigating IMU bias drift, a challenge that intensifies in subterranean environments due to extreme temperatures and gravity-induced accelerations. Cost-effective IMUs such as the Pixhawk, when paired with FMCW TI IWR6843AOP EVM radars, suffer from drift-induced degradation compounded by sparse, noisy, and flickering radar returns, making fusion less stable than LiDAR-based odometry. Yet, LiDAR fails under smoke, dust, and aerosols, whereas FMCW radars remain compact, lightweight, cost-effective, and robust in these situations. To address these challenges, we propose a two-stage MRIO framework that combines an IMU bias estimator for resilient localization and mapping in GPS-denied subterranean environments affected by smoke. Radar-based ego-velocity estimation is formulated through a least-squares approach and incorporated into an EKF for online IMU bias correction; the corrected IMU accelerations are fused with heterogeneous measurements from multiple radars and an IMU to refine odometry. The proposed framework further supports radar-only mapping by exploiting the robot's estimated translational and rotational displacements. In subterranean field trials, MRIO delivers robust localization and mapping, outperforming EKF-RIO. It maintains accuracy across cost-efficient FMCW radar setups and different IMUs, showing resilience with Pixhawk and higher-grade units such as VectorNav. The implementation will be provided as an open-source resource to the community (code available at https://github.com/LTU-RAI/MRIO

</details>


### [131] [Evaluating Accuracy of Vine Robot Shape Sensing with Distributed Inertial Measurement Units](https://arxiv.org/abs/2602.24202)
*Alexis E. Laudenslager,Antonio Alvarez Valdivia,Nathaniel Hanson,Margaret McGuinness*

Main category: cs.RO

TL;DR: 本研究系统评估了基于分布式IMU的藤蔓机器人形状感知精度，量化了在不同操作条件下的误差表现


<details>
  <summary>Details</summary>
Motivation: 藤蔓机器人在城市搜救等狭窄环境中具有优势，但现有形状感知方法在主动转向、变长度和不同传感器间距下的精度尚未系统量化

Method: 使用沿机器人身体分布的IMU进行形状感知实验，量化IMU漂移率，评估被动转向、主动转向、不同长度条件下的尖端位置误差，并分析传感器间距的影响

Result: IMU平均方向漂移率为1.33度/分钟；被动转向时尖端位置误差为机器人长度的11%；主动转向时增加到16%；30-175cm长度范围内平均误差为8%；中等传感器间距对单曲率形状误差最小

Conclusion: 分布式IMU形状感知对藤蔓机器人具有可行性，但需改进建模和算法集成以应对实际部署中的关键限制

Abstract: Soft, tip-extending vine robots are well suited for navigating tight, debris-filled environments, making them ideal for urban search and rescue. Sensing the full shape of a vine robot's body is helpful both for localizing information from other sensors placed along the robot body and for determining the robot's configuration within the space being explored. Prior approaches have localized vine robot tips using a single inertial measurement unit (IMU) combined with force sensing or length estimation, while one method demonstrated full-body shape sensing using distributed IMUs on a passively steered robot in controlled maze environments. However, the accuracy of distributed IMU-based shape sensing under active steering, varying robot lengths, and different sensor spacings has not been systematically quantified. In this work, we experimentally evaluate the accuracy of vine robot shape sensing using distributed IMUs along the robot body. We quantify IMU drift, measuring an average orientation drift rate of 1.33 degrees/min across 15 sensors. For passive steering, mean tip position error was 11% of robot length. For active steering, mean tip position error increased to 16%. During growth experiments across lengths from 30-175 cm, mean tip error was 8%, with a positive trend with increasing length. We also analyze the influence of sensor spacing and observe that intermediate spacings can minimize error for single-curvature shapes. These results demonstrate the feasibility of distributed IMU-based shape sensing for vine robots while highlighting key limitations and opportunities for improved modeling and algorithmic integration for field deployment.

</details>


### [132] [SafeGen-LLM: Enhancing Safety Generalization in Task Planning for Robotic Systems](https://arxiv.org/abs/2602.24235)
*Jialiang Fan,Weizhe Xu,Mengyu Liu,Oleg Sokolsky,Insup Lee,Fangxin Kong*

Main category: cs.RO

TL;DR: SafeGen-LLM：一种安全可泛化的大型语言模型，通过两阶段后训练框架解决机器人任务规划中的安全挑战，在多个领域实现安全约束的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前机器人任务规划面临挑战：经典规划器可扩展性差，基于强化学习的方法泛化能力弱，基础大语言模型无法保证安全性。需要一种既能保证安全又能泛化到新安全属性的解决方案。

Method: 1) 构建多领域PDDL3基准测试集；2) 两阶段后训练框架：监督微调学习规划语法语义，基于细粒度奖励机的组相对策略优化实现安全对齐，结合课程学习处理复杂任务。

Result: SafeGen-LLM在多领域规划任务和多种输入格式（PDDL和自然语言）上表现出强大的安全泛化能力，超越了前沿的专有基线模型。

Conclusion: SafeGen-LLM通过形式化验证指导的强化学习和课程学习，成功解决了机器人任务规划中的安全泛化问题，为安全关键系统提供了有效的解决方案。

Abstract: Safety-critical task planning in robotic systems remains challenging: classical planners suffer from poor scalability, Reinforcement Learning (RL)-based methods generalize poorly, and base Large Language Models (LLMs) cannot guarantee safety. To address this gap, we propose safety-generalizable large language models, named SafeGen-LLM. SafeGen-LLM can not only enhance the safety satisfaction of task plans but also generalize well to novel safety properties in various domains. We first construct a multi-domain Planning Domain Definition Language 3 (PDDL3) benchmark with explicit safety constraints. Then, we introduce a two-stage post-training framework: Supervised Fine-Tuning (SFT) on a constraint-compliant planning dataset to learn planning syntax and semantics, and Group Relative Policy Optimization (GRPO) guided by fine-grained reward machines derived from formal verification to enforce safety alignment and by curriculum learning to better handle complex tasks. Extensive experiments show that SafeGen-LLM achieves strong safety generalization and outperforms frontier proprietary baselines across multi-domain planning tasks and multiple input formats (e.g., PDDLs and natural language).

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [133] [HumanMCP: A Human-Like Query Dataset for Evaluating MCP Tool Retrieval Performance](https://arxiv.org/abs/2602.23367)
*Shubh Laddha,Lucas Changbencharoen,Win Kuptivej,Surya Shringla,Archana Vaidheeswaran,Yash Bhaskar*

Main category: cs.AI

TL;DR: 本文提出了首个大规模MCP数据集，包含针对2800个工具生成的多样化、高质量用户查询，解决了现有数据集缺乏真实用户查询模式的问题。


<details>
  <summary>Details</summary>
Motivation: 现有MCP服务器数据集和基准测试缺乏真实、人性化的用户查询，无法反映不同用户如何表达请求，导致泛化能力差和基准测试可靠性被夸大。

Method: 基于MCP Zero数据集，为308个MCP服务器中的2800个工具生成多样化、高质量的用户查询，每个工具配以多个独特的用户角色，捕捉从精确任务请求到模糊探索性命令的不同用户意图。

Result: 创建了首个大规模MCP数据集，包含针对2800个工具生成的多样化用户查询，反映了真实世界交互模式的复杂性。

Conclusion: 该数据集填补了MCP服务器工具使用和生态系统评估的关键空白，为更准确地评估工具使用提供了基础。

Abstract: Model Context Protocol (MCP) servers contain a collection of thousands of open-source standardized tools, linking LLMs to external systems; however, existing datasets and benchmarks lack realistic, human-like user queries, remaining a critical gap in evaluating the tool usage and ecosystems of MCP servers. Existing datasets often do contain tool descriptions but fail to represent how different users portray their requests, leading to poor generalization and inflated reliability of certain benchmarks. This paper introduces the first large-scale MCP dataset featuring diverse, high-quality diverse user queries generated specifically to match 2800 tools across 308 MCP servers, developing on the MCP Zero dataset. Each tool is paired with multiple unique user personas that we have generated, to capture varying levels of user intent ranging from precise task requests, and ambiguous, exploratory commands, reflecting the complexity of real-world interaction patterns.

</details>


### [134] [Causal Identification from Counterfactual Data: Completeness and Bounding Results](https://arxiv.org/abs/2602.23541)
*Arvind Raghavan,Elias Bareinboim*

Main category: cs.AI

TL;DR: 本文提出了CTFIDU+算法，用于从任意Layer 3分布中识别反事实查询，证明了其完备性，并建立了非参数设置中精确因果推理的理论极限。


<details>
  <summary>Details</summary>
Motivation: 先前关于反事实识别完备性的研究仅限于观测或干预分布（因果层级的第1、2层），因为一般认为无法获得第3层的反事实分布数据。但最近研究发现某些反事实分布可以通过实验方法直接估计（反事实可实现性），这引发了新的问题：在能够获取部分Layer 3数据的情况下，哪些额外的反事实量变得可识别？

Method: 开发了CTFIDU+算法，用于从任意Layer 3分布集合中识别反事实查询，并证明了该算法对此任务的完备性。基于此，建立了从物理可实现分布中识别反事实的理论极限。对于不可识别的反事实量，推导了使用可实现反事实数据的新解析边界。

Result: CTFIDU+算法被证明是完备的，能够识别从任意Layer 3分布集合中可识别的所有反事实查询。研究确定了非参数设置中精确因果推理的基本极限。通过模拟验证，反事实数据在实践中确实有助于收紧不可识别量的边界。

Conclusion: 本文建立了反事实识别的新理论框架，明确了在能够获取部分Layer 3数据情况下的识别能力极限，并为不可识别的反事实量提供了实用的边界估计方法，推进了因果推理的理论和实践发展。

Abstract: Previous work establishing completeness results for $\textit{counterfactual identification}$ has been circumscribed to the setting where the input data belongs to observational or interventional distributions (Layers 1 and 2 of Pearl's Causal Hierarchy), since it was generally presumed impossible to obtain data from counterfactual distributions, which belong to Layer 3. However, recent work (Raghavan & Bareinboim, 2025) has formally characterized a family of counterfactual distributions which can be directly estimated via experimental methods - a notion they call $\textit{counterfactual realizabilty}$. This leaves open the question of what $\textit{additional}$ counterfactual quantities now become identifiable, given this new access to (some) Layer 3 data. To answer this question, we develop the CTFIDU+ algorithm for identifying counterfactual queries from an arbitrary set of Layer 3 distributions, and prove that it is complete for this task. Building on this, we establish the theoretical limit of which counterfactuals can be identified from physically realizable distributions, thus implying the $\textit{fundamental limit to exact causal inference in the non-parametric setting}$. Finally, given the impossibility of identifying certain critical types of counterfactuals, we derive novel analytic bounds for such quantities using realizable counterfactual data, and corroborate using simulations that counterfactual data helps tighten the bounds for non-identifiable quantities in practice.

</details>


### [135] [Planning under Distribution Shifts with Causal POMDPs](https://arxiv.org/abs/2602.23545)
*Matteo Ceriscioli,Karthika Mohan*

Main category: cs.AI

TL;DR: 提出基于因果知识的POMDP框架，用于处理部分可观测环境下的分布偏移问题，通过将环境变化表示为因果干预，保持值函数的PWLC特性，确保规划的可处理性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的规划常面临分布偏移的挑战，环境模型在状态分布或环境动态变化时可能失效，导致先前学习策略失败。需要处理部分可观测性下的分布偏移问题。

Method: 提出基于因果知识的POMDP理论框架，将环境偏移表示为因果POMDP上的干预，能够评估假设变化下的计划并主动识别环境变化组件。维护和更新潜在状态和底层领域的信念。

Result: 证明了值函数在增强信念空间中保持分段线性凸(PWLC)特性，这一特性在分布偏移下的保持使得基于α向量的POMDP方法保持可处理性。

Conclusion: 该框架为部分可观测环境下的分布偏移问题提供了理论基础，通过因果表示和PWLC特性的保持，确保了规划方法在环境变化下的有效性和可处理性。

Abstract: In the real world, planning is often challenged by distribution shifts. As such, a model of the environment obtained under one set of conditions may no longer remain valid as the distribution of states or the environment dynamics change, which in turn causes previously learned strategies to fail. In this work, we propose a theoretical framework for planning under partial observability using Partially Observable Markov Decision Processes (POMDPs) formulated using causal knowledge. By representing shifts in the environment as interventions on this causal POMDP, the framework enables evaluating plans under hypothesized changes and actively identifying which components of the environment have been altered. We show how to maintain and update a belief over both the latent state and the underlying domain, and we prove that the value function remains piecewise linear and convex (PWLC) in this augmented belief space. Preservation of PWLC under distribution shifts has the advantage of maintaining the tractability of planning via $α$-vector-based POMDP methods.

</details>


### [136] [Construct, Merge, Solve & Adapt with Reinforcement Learning for the min-max Multiple Traveling Salesman Problem](https://arxiv.org/abs/2602.23579)
*Guillem Rodríguez-Corominas,Maria J. Blesa,Christian Blum*

Main category: cs.AI

TL;DR: 提出RL-CMSA混合方法解决对称单仓库min-max mTSP问题，结合强化学习引导的构造、精确优化和自适应池管理，在平衡工作负载方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决多旅行商问题中的min-max变体，目标是平衡多个销售员的工作负载，最小化最长路线，这在物流调度和资源分配中具有实际应用价值。

Method: 提出RL-CMSA混合方法：1) 使用基于学习到的成对q值的概率聚类构造多样化解；2) 将路线合并到紧凑池中；3) 求解受限集合覆盖MILP；4) 通过跨路线移除、移动和交换操作改进解；5) 通过强化高质量解中的城市对共现更新q值；6) 通过老化和剪枝自适应管理池。

Result: 在随机和TSPLIB实例上的计算结果表明，RL-CMSA能持续找到（接近）最优解，在可比时间限制下优于最先进的混合遗传算法，特别是在实例规模和销售员数量增加时表现更优。

Conclusion: RL-CMSA方法成功结合了精确优化和强化学习引导的构造，平衡了探索和利用，为解决min-max mTSP问题提供了有效方案，在平衡工作负载方面表现出色。

Abstract: The Multiple Traveling Salesman Problem (mTSP) extends the Traveling Salesman Problem to m tours that start and end at a common depot and jointly visit all customers exactly once. In the min-max variant, the objective is to minimize the longest tour, reflecting workload balance. We propose a hybrid approach, Construct, Merge, Solve & Adapt with Reinforcement Learning (RL-CMSA), for the symmetric single-depot min-max mTSP. The method iteratively constructs diverse solutions using probabilistic clustering guided by learned pairwise q-values, merges routes into a compact pool, solves a restricted set-covering MILP, and refines solutions via inter-route remove, shift, and swap moves. The q-values are updated by reinforcing city-pair co-occurrences in high-quality solutions, while the pool is adapted through ageing and pruning. This combination of exact optimization and reinforcement-guided construction balances exploration and exploitation. Computational results on random and TSPLIB instances show that RL-CMSA consistently finds (near-)best solutions and outperforms a state-of-the-art hybrid genetic algorithm under comparable time limits, especially as instance size and the number of salesmen increase.

</details>


### [137] [SleepLM: Natural-Language Intelligence for Human Sleep](https://arxiv.org/abs/2602.23605)
*Zongzhe Xu,Zitao Shuai,Eideen Mozaffari,Ravi S. Aysola,Rajesh Kumar,Yuzhe Yang*

Main category: cs.AI

TL;DR: SleepLM是一个睡眠-语言基础模型，通过自然语言与多模态多导睡眠图对齐，实现了人类睡眠的对齐、解释和交互，在零样本和少样本学习、跨模态检索等任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的睡眠分析系统在封闭标签空间（如预定义阶段或事件）中运行，无法描述、查询或泛化到新的睡眠现象，需要一种能够连接自然语言和睡眠生理学的系统。

Method: 1. 引入多级睡眠描述生成流程，创建首个大规模睡眠-文本数据集（超过10万小时数据，来自1万多个个体）；2. 提出统一的预训练目标，结合对比对齐、描述生成和信号重建，以更好地捕捉生理保真度和跨模态交互。

Result: SleepLM在真实世界睡眠理解任务中表现优于最先进方法，在零样本和少样本学习、跨模态检索和睡眠描述方面表现优异。模型还展现出语言引导事件定位、针对性洞察生成和零样本泛化到未见任务的能力。

Conclusion: SleepLM成功构建了自然语言与多模态多导睡眠图之间的桥梁，实现了语言基础的睡眠生理学表示，为睡眠分析提供了更灵活和通用的框架。所有代码和数据将开源。

Abstract: We present SleepLM, a family of sleep-language foundation models that enable human sleep alignment, interpretation, and interaction with natural language. Despite the critical role of sleep, learning-based sleep analysis systems operate in closed label spaces (e.g., predefined stages or events) and fail to describe, query, or generalize to novel sleep phenomena. SleepLM bridges natural language and multimodal polysomnography, enabling language-grounded representations of sleep physiology. To support this alignment, we introduce a multilevel sleep caption generation pipeline that enables the curation of the first large-scale sleep-text dataset, comprising over 100K hours of data from more than 10,000 individuals. Furthermore, we present a unified pretraining objective that combines contrastive alignment, caption generation, and signal reconstruction to better capture physiological fidelity and cross-modal interactions. Extensive experiments on real-world sleep understanding tasks verify that SleepLM outperforms state-of-the-art in zero-shot and few-shot learning, cross-modal retrieval, and sleep captioning. Importantly, SleepLM also exhibits intriguing capabilities including language-guided event localization, targeted insight generation, and zero-shot generalization to unseen tasks. All code and data will be open-sourced.

</details>


### [138] [MMKG-RDS: Reasoning Data Synthesis via Deep Mining of Multimodal Knowledge Graphs](https://arxiv.org/abs/2602.23632)
*Lun Zhan,Feng Xiong,Huanyong Liu,Feng Zhang,Yuhui Yin*

Main category: cs.AI

TL;DR: MMKG-RDS是一个基于多模态知识图谱的推理数据合成框架，通过细粒度知识提取、可定制路径采样和多维质量评分，生成高质量训练数据，提升领域模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在长尾知识覆盖、有效性验证和可解释性方面存在局限，基于知识图谱的方法在功能性、粒度、可定制性和评估方面仍有不足，需要更灵活的推理数据合成框架。

Method: 提出MMKG-RDS框架，利用多模态知识图谱支持细粒度知识提取、可定制路径采样和多维数据质量评分，并构建了包含5个领域、17种任务类型、14,950个样本的MMKG-RDS-Bench数据集。

Result: 在Qwen3模型（0.6B/8B/32B）上使用少量合成样本进行微调，推理准确率提升9.2%，框架生成的数据对涉及表格和公式的任务具有挑战性，可用于复杂基准构建。

Conclusion: MMKG-RDS是一个有效的推理数据合成框架，能够生成高质量训练数据提升模型推理能力，其生成的数据对现有模型具有挑战性，可用于构建复杂基准测试。

Abstract: Synthesizing high-quality training data is crucial for enhancing domain models' reasoning abilities. Existing methods face limitations in long-tail knowledge coverage, effectiveness verification, and interpretability. Knowledge-graph-based approaches still fall short in functionality, granularity, customizability, and evaluation. To address these issues, we propose MMKG-RDS, a flexible framework for reasoning data synthesis that leverages multimodal knowledge graphs. It supports fine-grained knowledge extraction, customizable path sampling, and multidimensional data quality scoring. We validate MMKG-RDS with the MMKG-RDS-Bench dataset, covering five domains, 17 task types, and 14,950 samples. Experimental results show fine-tuning Qwen3 models (0.6B/8B/32B) on a small number of synthesized samples improves reasoning accuracy by 9.2%. The framework also generates distinct data, challenging existing models on tasks involving tables and formulas, useful for complex benchmark construction. The dataset and code are available at https://github.com/360AILAB-NLP/MMKG-RDS

</details>


### [139] [AI Must Embrace Specialization via Superhuman Adaptable Intelligence](https://arxiv.org/abs/2602.23643)
*Judah Goldfeder,Philippe Wyder,Yann LeCun,Ravid Shwartz Ziv*

Main category: cs.AI

TL;DR: 该论文批判了当前对通用人工智能（AGI）的定义，认为人类本身并非真正的"通用"，因此以人类为标准的AGI概念存在缺陷。作者提出用"超人适应性智能（SAI）"替代AGI，强调AI应追求专业化而非通用性，并在专业领域实现超越人类的性能。


<details>
  <summary>Details</summary>
Motivation: 当前AI界对AGI的定义存在混乱和矛盾，不同群体对AGI的理解各不相同。作者认为以"能做人类能做的一切"作为AGI定义存在问题，因为人类本身并非真正的通用智能。需要重新审视AI发展的方向和目标，建立更清晰、实用的概念框架。

Method: 通过分析当前AGI定义的缺陷，论证人类智能的局限性，提出SAI概念作为替代框架。SAI定义为能够学习在人类重要能力上超越人类，并填补人类能力空白的智能系统。该方法包括概念分析、逻辑论证和替代框架构建。

Result: 成功识别了AGI概念的三个主要问题：定义不清晰、以人类为基准存在问题、实用性不足。提出了SAI作为更清晰、实用的替代概念，能够更好地指导AI发展方向，避免AGI概念的模糊性带来的讨论混乱。

Conclusion: AI发展应放弃追求通用性，转而专注于专业化，在特定领域实现超越人类的性能。SAI概念比AGI更清晰、实用，能够为AI发展提供更好的指导框架，帮助澄清当前模糊的AI讨论，推动AI向更有意义的方向发展。

Abstract: Everyone from AI executives and researchers to doomsayers, politicians, and activists is talking about Artificial General Intelligence (AGI). Yet, they often don't seem to agree on its exact definition. One common definition of AGI is an AI that can do everything a human can do, but are humans truly general? In this paper, we address what's wrong with our conception of AGI, and why, even in its most coherent formulation, it is a flawed concept to describe the future of AI. We explore whether the most widely accepted definitions are plausible, useful, and truly general. We argue that AI must embrace specialization, rather than strive for generality, and in its specialization strive for superhuman performance, and introduce Superhuman Adaptable Intelligence (SAI). SAI is defined as intelligence that can learn to exceed humans at anything important that we can do, and that can fill in the skill gaps where humans are incapable. We then lay out how SAI can help hone a discussion around AI that was blurred by an overloaded definition of AGI, and extrapolate the implications of using it as a guide for the future.

</details>


### [140] [PseudoAct: Leveraging Pseudocode Synthesis for Flexible Planning and Action Control in Large Language Model Agents](https://arxiv.org/abs/2602.23668)
*Yihan,Wen,Xin Chen*

Main category: cs.AI

TL;DR: PseudoAct框架通过伪代码合成实现LLM智能体的灵活规划和行动控制，解决了传统反应式决策在复杂长时任务中的冗余工具使用、不稳定推理和高token消耗问题。


<details>
  <summary>Details</summary>
Motivation: 传统LLM智能体依赖反应式决策范式（如ReAct），在涉及分支、迭代或多工具协调的复杂长时任务中，会导致冗余工具使用、不稳定推理和高token消耗，需要更有效的规划和控制方法。

Method: 提出PseudoAct框架，利用LLM将任务解决策略表达为代码的能力，合成结构化伪代码计划，将任务分解为子任务并显式编码控制流（包括序列、条件、循环、并行组合等逻辑原语），然后按照这个全局计划执行行动。

Result: 在基准数据集上的实验表明，该方法显著优于现有的反应式智能体方法，在FEVER上实现了20.93%的绝对成功率提升，并在HotpotQA上创造了新的最先进水平。

Conclusion: PseudoAct通过伪代码合成实现了显式和时间一致的决策逻辑，减少了冗余行动，防止了无限循环，避免了无信息量的替代探索，实现了一致且高效的长时决策。

Abstract: Large language model (LLM) agents typically rely on reactive decision-making paradigms such as ReAct, selecting actions conditioned on growing execution histories. While effective for short tasks, these approaches often lead to redundant tool usage, unstable reasoning, and high token consumption in complex long-horizon tasks involving branching, iteration, or multi-tool coordination. To address these limitations, this paper introduces PseudoAct, a novel framework for flexible planning and action control in LLM agents through pseudocode synthesis. Leveraging the ability of LLMs to express task-solving strategies as code, PseudoAct synthesizes a structured pseudocode plan that decomposes a task into subtasks and explicitly encodes control flow, including sequencing, conditionals, loops, parallel composition, and combinations of these logic primitives. Actions are then executed by following this global plan, making the decision logic explicit and temporally coherent. This design reduces redundant actions, prevents infinite loops, and avoids uninformative alternative exploration, enabling consistent and efficient long-horizon decision-making. Experiments on benchmark datasets show that our method significantly outperforms existing reactive agent approaches, achieving a 20.93% absolute gain in success rate on FEVER and setting a new state-of-the-art on HotpotQA.

</details>


### [141] [From Flat Logs to Causal Graphs: Hierarchical Failure Attribution for LLM-based Multi-Agent Systems](https://arxiv.org/abs/2602.23701)
*Yawen Wang,Wenjie Wu,Junjie Wang,Qing Wang*

Main category: cs.AI

TL;DR: CHIEF框架通过将多智能体系统的混沌轨迹转换为层次化因果图，使用层次化oracle引导回溯和渐进因果筛选策略，显著提升了故障归因的准确性。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的多智能体系统在复杂领域表现出色，但存在固有的脆弱性和不透明的故障机制。现有的故障归因方法通常将执行日志视为扁平序列，这种线性视角无法解构MAS中复杂的因果联系，导致弱可观测性和模糊的责任边界。

Method: 提出CHIEF框架：1) 将混沌轨迹转换为结构化层次因果图；2) 使用层次化oracle引导回溯，通过合成虚拟oracle高效剪枝搜索空间；3) 通过渐进因果筛选策略实现反事实归因，严格区分真正的根本原因和传播的症状。

Result: 在Who&When基准测试中，CHIEF在智能体级别和步骤级别准确性上都优于八个强大的最先进基线方法。消融研究进一步证实了每个提出模块的关键作用。

Conclusion: CHIEF通过结构化层次因果图表示和高效的因果分析策略，显著提升了多智能体系统故障归因的准确性和可解释性，为解决MAS的脆弱性和不透明性提供了有效方案。

Abstract: LLM-powered Multi-Agent Systems (MAS) have demonstrated remarkable capabilities in complex domains but suffer from inherent fragility and opaque failure mechanisms. Existing failure attribution methods, whether relying on direct prompting, costly replays, or supervised fine-tuning, typically treat execution logs as flat sequences. This linear perspective fails to disentangle the intricate causal links inherent to MAS, leading to weak observability and ambiguous responsibility boundaries. To address these challenges, we propose CHIEF, a novel framework that transforms chaotic trajectories into a structured hierarchical causal graph. It then employs hierarchical oracle-guided backtracking to efficiently prune the search space via sybthesized virtual oracles. Finally, it implements counterfactual attribution via a progressive causal screening strategy to rigorously distinguish true root causes from propagated symptoms. Experiments on Who&When benchmark show that CHIEF outperforms eight strong and state-of-the-art baselines on both agent- and step-level accuracy. Ablation studies further confirm the critical role of each proposed module.

</details>


### [142] [Unlocking Cognitive Capabilities and Analyzing the Perception-Logic Trade-off](https://arxiv.org/abs/2602.23730)
*Longyin Zhang,Shuo Sun,Yingxu He,Won Cheng Yi Lewis,Muhammad Huzaifah Bin Md Shahrin,Hardik Bhupendra Sailor,Heng Meng Jeremy Wong,Tarun Kumar Vangani,Yi Ma,Qiongqiong Wang,Minh Duc Pham,Ridong Jiang,Jingtao Li,Jingyi Liao,Zhuohan Liu,Yanfeng Lu,Manas Gupta,Ai Ti Aw*

Main category: cs.AI

TL;DR: MERaLiON2-Omni (Alpha)是一个针对东南亚地区的10B参数多语言全感知MLLM，通过分离和整合"系统1"（感知）与"系统2"（推理）能力，在区域特定音频视觉线索对齐和低成本数据生成方面取得进展，但发现推理能力在提升抽象任务表现的同时会降低低级感官处理的稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型追求全感知能力，但将稳健的感官基础与复杂推理相结合仍然具有挑战性，特别是在代表性不足的地区如东南亚。需要解决区域特定感知与高级推理能力的整合问题。

Method: 采用渐进式训练流程：1）通过正交模态适应建立稳健的感知骨干，将区域特定音频视觉线索与多语言LLM对齐；2）提出低成本Generate-Judge-Refine流程，利用Super-LLM过滤幻觉并通过共识机制解决冲突，合成高质量银数据，将文本链式思维推理转移到多模态场景。

Result: 在新引入的SEA-Omni基准套件评估中发现效率-稳定性悖论：推理能力作为抽象任务的非线性放大器（显著提升数学和指令跟随性能），但在低级感官处理中引入不稳定性，具体表现为长上下文音频中的时间漂移和视觉过度解释问题。

Conclusion: 该研究展示了针对东南亚地区的全感知MLLM架构、数据高效训练方法，并诊断分析了稳健感知与结构化推理之间的权衡关系，为区域特定多模态模型开发提供了重要见解。

Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) pursue omni-perception capabilities, yet integrating robust sensory grounding with complex reasoning remains a challenge, particularly for underrepresented regions. In this report, we introduce the research preview of MERaLiON2-Omni (Alpha), a 10B-parameter multilingual omni-perception tailored for Southeast Asia (SEA). We present a progressive training pipeline that explicitly decouples and then integrates "System 1" (Perception) and "System 2" (Reasoning) capabilities. First, we establish a robust Perception Backbone by aligning region-specific audio-visual cues (e.g., Singlish code-switching, local cultural landmarks) with a multilingual LLM through orthogonal modality adaptation. Second, to inject cognitive capabilities without large-scale supervision, we propose a cost-effective Generate-Judge-Refine pipeline. By utilizing a Super-LLM to filter hallucinations and resolve conflicts via a consensus mechanism, we synthesize high-quality silver data that transfers textual Chain-of-Thought reasoning to multimodal scenarios.
  Comprehensive evaluation on our newly introduced SEA-Omni Benchmark Suite reveals an Efficiency-Stability Paradox: while reasoning acts as a non-linear amplifier for abstract tasks (boosting mathematical and instruction-following performance significantly), it introduces instability in low-level sensory processing. Specifically, we identify Temporal Drift in long-context audio, where extended reasoning desynchronizes the model from acoustic timestamps, and Visual Over-interpretation, where logic overrides pixel-level reality. This report details the architecture, the data-efficient training recipe, and a diagnostic analysis of the trade-offs between robust perception and structured reasoning.

</details>


### [143] [Reasoning-Driven Multimodal LLM for Domain Generalization](https://arxiv.org/abs/2602.23777)
*Zhipeng Xu,Zilong Wang,Xinyang Jiang,Dongsheng Li,De Cheng,Nannan Wang*

Main category: cs.AI

TL;DR: 该论文提出RD-MLDG框架，利用多模态大语言模型的推理能力解决领域泛化问题，通过推理链构建实现更鲁棒的跨域预测。


<details>
  <summary>Details</summary>
Motivation: 现有领域泛化方法主要关注视觉特征不变性，而本文探索利用多模态大语言模型的推理能力，通过构建推理链来获得更鲁棒的跨域预测性能。

Method: 提出RD-MLDG框架，包含两个核心组件：1) MTCT（多任务交叉训练），引入直接分类路径来指导推理监督；2) SARR（自对齐推理正则化），通过迭代自标注保持推理链的语义丰富性同时缓解推理模式不匹配问题。

Result: 在标准DomainBed数据集（PACS、VLCS、OfficeHome、TerraInc）上的实验表明，RD-MLDG达到了最先进的性能，验证了推理作为鲁棒跨域泛化的有效补充信号。

Conclusion: 研究表明推理链可以成为领域泛化的有效补充信号，RD-MLDG框架通过平衡语义丰富性和优化效率，在多模态大语言模型中实现了更好的跨域泛化能力。

Abstract: This paper addresses the domain generalization (DG) problem in deep learning. While most DG methods focus on enforcing visual feature invariance, we leverage the reasoning capability of multimodal large language models (MLLMs) and explore the potential of constructing reasoning chains that derives image categories to achieve more robust predictions under domain shift. To this end, we systematically study the role of reasoning in DG using DomainBed-Reasoning, a newly constructed extension of DomainBed dataset, in which each sample is paired with class-relevant reasoning chains. Our analysis reveals two key challenges: (i) fine-tuning MLLMs with reasoning chains for classification is more challenging than direct label supervision, since the model must optimize complex reasoning sequences before label prediction; and (ii) mismatches in reasoning patterns between supervision signals and fine-tuned MLLMs lead to a trade-off between semantic richness (informative but harder to optimize) and optimization efficiency (easier to optimize but less informative). To address these issues, we propose RD-MLDG (Reasoning-Driven Multimodal LLM for Domain Generalization), a framework with two components: (i) MTCT (Multi-Task Cross-Training), which introduces an additional direct classification pathway to guide reasoning supervision; and (ii) SARR (Self-Aligned Reasoning Regularization), which preserves the semantic richness of reasoning chains while mitigating reasoning-pattern mismatches via iterative self-labeling. Experiments on standard DomainBed datasets (PACS, VLCS, OfficeHome, TerraInc) demonstrate that RD-MLDG achieves state-of-the-art performances, highlighting reasoning as a promising complementary signal for robust out-of-domain generalization.

</details>


### [144] [EMO-R3: Reflective Reinforcement Learning for Emotional Reasoning in Multimodal Large Language Models](https://arxiv.org/abs/2602.23802)
*Yiyang Fang,Wenke Huang,Pei Fu,Yihao Yang,Kehua Su,Zhenbo Luo,Jian Luan,Mang Ye*

Main category: cs.AI

TL;DR: EMO-R3框架通过结构化情感思维和反思性情感奖励，增强多模态大语言模型的情感推理能力，提升解释性和情感智能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在视觉推理方面取得显著进展，但在捕捉人类情感的复杂性和主观性方面仍存在困难。现有监督微调方法泛化能力有限且解释性差，而强化学习方法如GRPO未能与情感认知的内在特性对齐。

Method: 提出EMO-R3框架，包含两个核心组件：1) 结构化情感思维，引导模型以结构化、可解释的方式进行逐步情感推理；2) 反思性情感奖励，使模型能够基于视觉-文本一致性和情感连贯性重新评估其推理过程。

Result: 大量实验表明，EMO-R3显著提升了多模态大语言模型的解释性和情感智能，在多个视觉情感理解基准测试中取得了优越性能。

Conclusion: EMO-R3框架有效解决了多模态大语言模型在情感推理方面的局限性，通过结构化思维和反思性奖励机制，实现了更好的情感理解和解释能力。

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable progress in visual reasoning and understanding tasks but still struggle to capture the complexity and subjectivity of human emotions. Existing approaches based on supervised fine-tuning often suffer from limited generalization and poor interpretability, while reinforcement learning methods such as Group Relative Policy Optimization fail to align with the intrinsic characteristics of emotional cognition. To address these challenges, we propose Reflective Reinforcement Learning for Emotional Reasoning (EMO-R3), a framework designed to enhance the emotional reasoning ability of MLLMs. Specifically, we introduce Structured Emotional Thinking to guide the model to perform step-by-step emotional reasoning in a structured and interpretable manner, and design a Reflective Emotional Reward that enables the model to re-evaluate its reasoning based on visual-text consistency and emotional coherence. Extensive experiments demonstrate that EMO-R3 significantly improves both the interpretability and emotional intelligence of MLLMs, achieving superior performance across multiple visual emotional understanding benchmarks.

</details>


### [145] [RF-Agent: Automated Reward Function Design via Language Agent Tree Search](https://arxiv.org/abs/2602.23876)
*Ning Gao,Xiuhui Zhang,Xingyu Jiang,Mukang You,Mohan Zhang,Yue Deng*

Main category: cs.AI

TL;DR: RF-Agent：将LLM作为语言智能体，通过蒙特卡洛树搜索框架设计强化学习奖励函数，在17个低层控制任务中取得优异表现


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的奖励函数设计方法存在历史反馈利用不足和搜索效率低的问题，在复杂控制任务中改进有限

Method: 提出RF-Agent框架，将LLM视为语言智能体，将奖励函数设计建模为序列决策过程，集成蒙特卡洛树搜索来管理奖励设计和优化过程

Result: 在17个多样化的低层控制任务中取得了出色的实验效果

Conclusion: RF-Agent通过更好的上下文推理能力，提高了历史信息利用率和搜索效率，能发现更有前景的奖励函数

Abstract: Designing efficient reward functions for low-level control tasks is a challenging problem. Recent research aims to reduce reliance on expert experience by using Large Language Models (LLMs) with task information to generate dense reward functions. These methods typically rely on training results as feedback, iteratively generating new reward functions with greedy or evolutionary algorithms. However, they suffer from poor utilization of historical feedback and inefficient search, resulting in limited improvements in complex control tasks. To address this challenge, we propose RF-Agent, a framework that treats LLMs as language agents and frames reward function design as a sequential decision-making process, enhancing optimization through better contextual reasoning. RF-Agent integrates Monte Carlo Tree Search (MCTS) to manage the reward design and optimization process, leveraging the multi-stage contextual reasoning ability of LLMs. This approach better utilizes historical information and improves search efficiency to identify promising reward functions. Outstanding experimental results in 17 diverse low-level control tasks demonstrate the effectiveness of our method. The source code is available at https://github.com/deng-ai-lab/RF-Agent.

</details>


### [146] [Pessimistic Auxiliary Policy for Offline Reinforcement Learning](https://arxiv.org/abs/2602.23974)
*Fan Zhang,Baoru Huang,Xin Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种悲观辅助策略，通过最大化Q函数的下置信界来采样可靠动作，缓解离线强化学习中分布外动作导致的误差累积问题。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习从预收集的数据集中学习智能体，避免了实时交互的不安全性和低效率。然而，在学习过程中不可避免地访问分布外动作会引入近似误差，导致误差累积和严重的高估问题。

Method: 构建了一个新的悲观辅助策略来采样可靠动作。具体来说，通过最大化Q函数的下置信界来开发悲观辅助策略。该策略在学习策略附近表现出相对较高的价值和较低的不确定性，避免了学习策略在训练过程中采样具有潜在高误差的高价值动作。

Result: 悲观辅助策略引入的近似误差较少，从而缓解了误差累积问题。在离线强化学习基准测试上的大量实验表明，利用悲观辅助策略可以有效提高其他离线RL方法的效能。

Conclusion: 提出的悲观辅助策略通过采样可靠动作来减少分布外动作引入的近似误差，有效缓解了离线强化学习中的误差累积问题，提高了现有方法的性能。

Abstract: Offline reinforcement learning aims to learn an agent from pre-collected datasets, avoiding unsafe and inefficient real-time interaction. However, inevitable access to out-ofdistribution actions during the learning process introduces approximation errors, causing the error accumulation and considerable overestimation. In this paper, we construct a new pessimistic auxiliary policy for sampling reliable actions. Specifically, we develop a pessimistic auxiliary strategy by maximizing the lower confidence bound of the Q-function. The pessimistic auxiliary strategy exhibits a relatively high value and low uncertainty in the vicinity of the learned policy, avoiding the learned policy sampling high-value actions with potentially high errors during the learning process. Less approximation error introduced by sampled action from pessimistic auxiliary strategy leads to the alleviation of error accumulation. Extensive experiments on offline reinforcement learning benchmarks reveal that utilizing the pessimistic auxiliary strategy can effectively improve the efficacy of other offline RL approaches.

</details>


### [147] [CIRCLE: A Framework for Evaluating AI from a Real-World Lens](https://arxiv.org/abs/2602.24055)
*Reva Schwartz,Carina Westling,Morgan Briggs,Marzieh Fadaee,Isar Nejadgholi,Matthew Holmes,Fariza Rashid,Maya Carlyle,Afaf Taïk,Kyra Wilson,Peter Douglas,Theodora Skeadas,Gabriella Waters,Rumman Chowdhury,Thiago Lacerda*

Main category: cs.AI

TL;DR: CIRCLE是一个六阶段生命周期框架，旨在弥合模型中心性能指标与AI实际部署结果之间的现实差距，通过将利益相关者关注转化为可测量信号，实现基于实际下游效应的治理。


<details>
  <summary>Details</summary>
Motivation: 现有MLOps框架关注系统稳定性，基准测试衡量抽象能力，但AI堆栈外的决策者缺乏关于AI技术在真实世界用户变异性和约束下行为的系统性证据，需要连接上下文敏感的定性洞察与可扩展的定量指标。

Method: CIRCLE是一个六阶段生命周期框架，将TEVV（测试、评估、验证和验证）中的验证阶段操作化，通过结构化前瞻性协议，整合实地测试、红队测试和纵向研究等方法，将利益相关者关注转化为可测量信号。

Result: CIRCLE产生系统性知识：在不同站点间可比但对本地上下文敏感的证据，支持基于实际下游效应而非理论能力的治理，提供连接定性洞察与定量指标的结构化方法。

Conclusion: CIRCLE框架通过弥合模型中心指标与AI实际部署结果之间的现实差距，使治理能够基于AI技术的实际下游效应，为决策者提供关于AI在真实世界约束下行为的系统性证据。

Abstract: This paper proposes CIRCLE, a six-stage, lifecycle-based framework to bridge the reality gap between model-centric performance metrics and AI's materialized outcomes in deployment. While existing frameworks like MLOps focus on system stability and benchmarks measure abstract capabilities, decision-makers outside the AI stack lack systematic evidence about the behavior of AI technologies under real-world user variability and constraints. CIRCLE operationalizes the Validation phase of TEVV (Test, Evaluation, Verification, and Validation) by formalizing the translation of stakeholder concerns outside the stack into measurable signals. Unlike participatory design, which often remains localized, or algorithmic audits, which are often retrospective, CIRCLE provides a structured, prospective protocol for linking context-sensitive qualitative insights to scalable quantitative metrics. By integrating methods such as field testing, red teaming, and longitudinal studies into a coordinated pipeline, CIRCLE produces systematic knowledge: evidence that is comparable across sites yet sensitive to local context. This can enable governance based on materialized downstream effects rather than theoretical capabilities.

</details>


### [148] [Human or Machine? A Preliminary Turing Test for Speech-to-Speech Interaction](https://arxiv.org/abs/2602.24080)
*Xiang Li,Jiabao Gao,Sipei Lin,Xuan Zhou,Chi Zhang,Bo Cheng,Jiale Han,Benyou Wang*

Main category: cs.AI

TL;DR: 首个语音到语音系统的图灵测试显示，现有系统均未通过，主要瓶颈在于副语言特征、情感表达和对话个性，而非语义理解。


<details>
  <summary>Details</summary>
Motivation: 现代语音到语音系统能否像人类一样对话是一个关键但未解决的问题，需要建立首个针对S2S系统的人类相似性评估框架。

Method: 进行了首个S2S系统图灵测试，收集了2,968个人类判断，涉及9个最先进S2S系统与28名人类参与者的对话；开发了包含18个人类相似性维度的细粒度分类法，并对收集的对话进行众包标注。

Result: 所有评估的S2S系统均未通过图灵测试；瓶颈主要在于副语言特征、情感表达和对话个性，而非语义理解；现成的AI模型作为图灵测试评判者表现不可靠。

Conclusion: 建立了首个S2S系统人类相似性评估框架，超越了二元结果，提供了详细的诊断洞察；提出了一个利用细粒度人类相似性评分的可解释模型，为自动人类相似性评估提供了强大工具。

Abstract: The pursuit of human-like conversational agents has long been guided by the Turing test. For modern speech-to-speech (S2S) systems, a critical yet unanswered question is whether they can converse like humans. To tackle this, we conduct the first Turing test for S2S systems, collecting 2,968 human judgments on dialogues between 9 state-of-the-art S2S systems and 28 human participants. Our results deliver a clear finding: no existing evaluated S2S system passes the test, revealing a significant gap in human-likeness. To diagnose this failure, we develop a fine-grained taxonomy of 18 human-likeness dimensions and crowd-annotate our collected dialogues accordingly. Our analysis shows that the bottleneck is not semantic understanding but stems from paralinguistic features, emotional expressivity, and conversational persona. Furthermore, we find that off-the-shelf AI models perform unreliably as Turing test judges. In response, we propose an interpretable model that leverages the fine-grained human-likeness ratings and delivers accurate and transparent human-vs-machine discrimination, offering a powerful tool for automatic human-likeness evaluation. Our work establishes the first human-likeness evaluation for S2S systems and moves beyond binary outcomes to enable detailed diagnostic insights, paving the way for human-like improvements in conversational AI systems.

</details>


### [149] [Recycling Failures: Salvaging Exploration in RLVR via Fine-Grained Off-Policy Guidance](https://arxiv.org/abs/2602.24110)
*Yanwei Ren,Haotian Zhang,Likang Xiao,Xikai Zhang,Jiaxing Huang,Jiayan Qiu,Baosheng Yu,Quan Chen,Liu Liu*

Main category: cs.AI

TL;DR: SCOPE框架通过过程奖励模型定位推理轨迹中的首个错误步骤，进行细粒度修正，有效利用部分正确的推理轨迹，提升探索多样性，在数学推理任务上达到46.6%的平均准确率。


<details>
  <summary>Details</summary>
Motivation: 传统的基于结果的强化学习监督存在关键局限：对大部分正确但有几个错误步骤的轨迹与完全错误的轨迹给予同样惩罚，导致模型丢弃有价值的部分正确推理轨迹，降低了探索多样性并过早缩小了探索空间。

Method: 提出SCOPE框架，利用过程奖励模型精确定位次优推理轨迹中的第一个错误步骤，应用细粒度的、步骤级别的离策略修正。通过对部分正确轨迹进行精确修正，有效挽救这些轨迹并保持广阔的探索空间。

Result: SCOPE将多样性分数提升了13.5%，在数学推理任务上达到46.6%的平均准确率，在分布外推理任务上表现出53.4%的准确率，展现了强大的泛化能力。

Conclusion: SCOPE框架通过步骤级别的修正有效利用了部分正确的推理轨迹，维持了探索多样性，在强化学习从可验证奖励范式下取得了新的最先进结果，并展现出良好的泛化性能。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a powerful paradigm for enhancing the complex reasoning capabilities of Large Reasoning Models. However, standard outcome-based supervision suffers from a critical limitation that penalizes trajectories that are largely correct but fail due to several missteps as heavily as completely erroneous ones. This coarse feedback signal causes the model to discard valuable largely correct rollouts, leading to a degradation in rollout diversity that prematurely narrows the exploration space. Process Reward Models have demonstrated efficacy in providing reliable step-wise verification for test-time scaling, naively integrating these signals into RLVR as dense rewards proves ineffective.Prior methods attempt to introduce off-policy guided whole-trajectory replacement that often outside the policy model's distribution, but still fail to utilize the largely correct rollouts generated by the model itself and thus do not effectively mitigate the narrowing of the exploration space. To address these issues, we propose SCOPE (Step-wise Correction for On-Policy Exploration), a novel framework that utilizes Process Reward Models to pinpoint the first erroneous step in suboptimal rollouts and applies fine-grained, step-wise off-policy rectification. By applying precise refinement on partially correct rollout, our method effectively salvages partially correct trajectories and increases diversity score by 13.5%, thereby sustaining a broad exploration space. Extensive experiments demonstrate that our approach establishes new state-of-the-art results, achieving an average accuracy of 46.6% on math reasoning and exhibiting robust generalization with 53.4% accuracy on out-of-distribution reasoning tasks.

</details>


### [150] [LemmaBench: A Live, Research-Level Benchmark to Evaluate LLM Capabilities in Mathematics](https://arxiv.org/abs/2602.24173)
*Antoine Peyronnet,Fabian Gloeckle,Amaury Hayat*

Main category: cs.AI

TL;DR: 提出一个基于arXiv最新数学研究结果的动态可更新LLM基准测试框架，替代传统的静态竞赛题基准


<details>
  <summary>Details</summary>
Motivation: 现有LLM数学能力基准主要依赖静态的手工整理竞赛题或教科书习题，无法反映真实数学研究水平，需要建立直接评估模型在最新数学研究成果上表现的动态基准

Method: 开发自动流水线从arXiv提取引理，通过显式化所有假设和定义将其重写为自包含的陈述，创建可定期更新的基准测试集

Result: 当前最先进LLM在定理证明任务上准确率约为10-15%（pass@1），表明LLM距离人类研究水平的证明能力仍有较大差距

Conclusion: 该动态基准能够持续评估LLM在真实数学研究环境中的能力，为模型发展提供更有意义的评估标准，同时旧实例可用于训练而不影响未来评估

Abstract: We present a new approach for benchmarking Large Language Model (LLM) capabilities on research-level mathematics. Existing benchmarks largely rely on static, hand-curated sets of contest or textbook-style problems as proxies for mathematical research. Instead, we establish an updatable benchmark evaluating models directly on the latest research results in mathematics. This consists of an automatic pipeline that extracts lemmas from arXiv and rewrites them into self-contained statements by making all assumptions and required definitions explicit. It results in a benchmark that can be updated regularly with new problems taken directly from human mathematical research, while previous instances can be used for training without compromising future evaluations. We benchmark current state-of-the-art LLMs, which obtain around 10-15$\%$ accuracy in theorem proving (pass@1) depending on the model, showing that there is currently a large margin of progression for LLMs to reach human-level proving capabilities in a research context.

</details>


### [151] [Uncertainty Quantification for Multimodal Large Language Models with Incoherence-adjusted Semantic Volume](https://arxiv.org/abs/2602.24195)
*Gregory Kang Ruey Lau,Hieu Dao,Nicole Kan Hui Lin,Bryan Kian Hsiang Low*

Main category: cs.AI

TL;DR: UMPIRE是一个无需训练的多模态大语言模型不确定性量化框架，通过计算采样响应的语义体积来评估不确定性，在多种模态和任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型可能产生看似合理但错误的输出，阻碍可靠部署。现有不确定性度量方法存在局限性：仅适用于特定模态、依赖外部工具或计算成本高。

Method: UMPIRE框架利用模型内部模态特征，计算给定任务实例采样响应的不连贯调整语义体积，捕捉样本的全局语义多样性和基于内部模型置信度的局部不连贯性。

Result: 在图像、音频和视频-文本基准测试（包括对抗性和分布外设置）中，UMPIRE在错误检测和不确定性校准方面持续优于基线指标，并能推广到非文本输出任务如图像和音频生成。

Conclusion: UMPIRE是一个高效、无需训练的不确定性量化框架，适用于多种输入输出模态，无需外部工具，为多模态大语言模型的可靠部署提供了有效的解决方案。

Abstract: Despite their capabilities, Multimodal Large Language Models (MLLMs) may produce plausible but erroneous outputs, hindering reliable deployment. Accurate uncertainty metrics could enable escalation of unreliable queries to human experts or larger models for improved performance. However, existing uncertainty metrics have practical constraints, such as being designed only for specific modalities, reliant on external tools, or computationally expensive. We introduce UMPIRE, a training-free uncertainty quantification framework for MLLMs that works efficiently across various input and output modalities without external tools, relying only on the models' own internal modality features. UMPIRE computes the incoherence-adjusted semantic volume of sampled MLLM responses for a given task instance, effectively capturing both the global semantic diversity of samples and the local incoherence of responses based on internal model confidence. We propose uncertainty desiderata for MLLMs and provide theoretical analysis motivating UMPIRE's design. Extensive experiments show that UMPIRE consistently outperforms baseline metrics in error detection and uncertainty calibration across image, audio, and video-text benchmarks, including adversarial and out-of-distribution settings. We also demonstrate UMPIRE's generalization to non-text output tasks, including image and audio generation.

</details>


### [152] [A Minimal Agent for Automated Theorem Proving](https://arxiv.org/abs/2602.24273)
*Borja Requena Pozo,Austin Letson,Krystian Nowakowski,Izan Beltran Ferreiro,Leopoldo Sarra*

Main category: cs.AI

TL;DR: 提出一个最小化的智能体基准系统，用于系统比较不同AI定理证明器架构，展示迭代方法相比单次生成的优越性


<details>
  <summary>Details</summary>
Motivation: 为了系统比较不同AI定理证明器架构，需要一个共享核心功能的最小化基准系统，避免复杂架构带来的混淆因素

Method: 设计实现包含迭代证明精炼、库搜索和上下文管理等核心功能的最小化智能体基线，使用不同基准评估各种流行模型和设计选择

Result: 该基线系统在保持显著简化架构的同时，实现了与最先进方法相竞争的性能，迭代方法在样本效率和成本效益方面优于多次单次生成

Conclusion: 迭代方法相比多次单次生成具有明显优势，该开源实现可作为未来研究的参考基准和社区可访问的证明器

Abstract: We propose a minimal agentic baseline that enables systematic comparison across different AI-based theorem prover architectures. This design implements the core features shared among state-of-the-art systems: iterative proof refinement, library search and context management. We evaluate our baseline using qualitatively different benchmarks and compare various popular models and design choices, and demonstrate competitive performance compared to state-of-the-art approaches, while using a significantly simpler architecture. Our results demonstrate consistent advantages of an iterative approach over multiple single-shot generations, especially in terms of sample efficiency and cost effectiveness. The implementation is released open-source as a candidate reference for future research and as an accessible prover for the community.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [153] [Detoxifying LLMs via Representation Erasure-Based Preference Optimization](https://arxiv.org/abs/2602.23391)
*Nazanin Mohammadi Sepahvand,Eleni Triantafillou,Hugo Larochelle,Doina Precup,Daniel M. Roy,Gintare Karolina Dziugaite*

Main category: cs.LG

TL;DR: REPO是一种新的语言模型去毒方法，通过表示擦除偏好优化在token级别处理毒性问题，相比现有方法能更深度地编辑毒性编码神经元，实现更强的鲁棒性防御。


<details>
  <summary>Details</summary>
Motivation: 现有基于DPO、NPO等算法的去毒方法存在局限性：它们只能降低有害输出的可能性，但不够鲁棒，容易受到对抗性提示和微调再学习攻击的影响。研究表明这些编辑是表面的，有害"方向"仍然存在于表示中。

Method: 提出表示擦除偏好优化（REPO），将去毒重新定义为token级别的偏好问题。使用带有偏好数据的新目标函数，强制有毒延续的表示向良性对应物收敛。这种方法在机制上实现深度、局部化的毒性编码神经元编辑。

Result: REPO实现了最先进的鲁棒性，能够阻止复杂的威胁，包括再学习攻击和增强的GCG越狱攻击，而现有的基于表示和输出的方法都失败了。同时保持模型的一般效用。

Conclusion: REPO通过token级别的表示擦除方法，实现了比现有方法更深度的去毒效果，提供了更鲁棒的防御机制，解决了语言模型安全部署中的关键问题。

Abstract: Large language models (LLMs) trained on webscale data can produce toxic outputs, raising concerns for safe deployment. Prior defenses, based on applications of DPO, NPO, and similar algorithms, reduce the likelihood of harmful continuations, but not robustly so: they are vulnerable to adversarial prompting and easily undone by fine-tuning-based relearning attacks. Indeed, research has shown that these edits to the model are superficial: linear probing reveals that harmful "directions" remain present in representations. To address this, we propose Representation Erasure-based Preference Optimization (REPO), reformulating detoxification as a token-level preference problem. Using a novel objective with preference data, we force the representations of toxic continuations to converge toward their benign counterparts. Our mechanistic analysis reveals that this granular approach is critical: unlike baselines, REPO induces deep, localized edits to toxicity-encoding neurons while preserving general model utility. Exhaustive evaluations show that REPO achieves state-of-the-art robustness, stopping sophisticated threats-including relearning attacks and enhanced GCG jailbreaks-where existing representation- and output-based methods fail.

</details>


### [154] [U-CAN: Utility-Aware Contrastive Attenuation for Efficient Unlearning in Generative Recommendation](https://arxiv.org/abs/2602.23400)
*Zezheng Wu,Rui Wang,Xinghe Cheng,Yang Shao,Qing Yang,Jiapu Wang,Jingwei Zhang*

Main category: cs.LG

TL;DR: U-CAN是一个用于生成式推荐系统的隐私保护框架，通过低秩适配器的对比衰减机制，在保持模型性能的同时选择性遗忘敏感数据。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐系统在微调时会无意中将敏感属性编码到模型参数中，引发隐私担忧。现有的机器学习遗忘技术面临多义性困境，导致灾难性的效用损失。

Method: 提出Utility-aware Contrastive AttenuatioN (U-CAN)框架，在低秩适配器上操作。通过对比激活量化风险，识别对遗忘集敏感但对保留集抑制的神经元。引入效用感知校准机制，结合权重大小和保留集激活规范，为对保留性能贡献大的维度分配更高的效用分数。采用自适应软衰减和可微衰减函数，选择性降低LoRA适配器上的高风险参数。

Result: 在两个公共数据集上的七个指标实验表明，U-CAN实现了强大的隐私遗忘、效用保留和计算效率。

Conclusion: U-CAN框架有效解决了生成式推荐系统中的隐私保护问题，通过精确的对比衰减机制在保持模型性能的同时实现敏感数据遗忘，避免了传统梯度或剪枝方法带来的灾难性效用损失。

Abstract: Generative Recommendation (GenRec) typically leverages Large Language Models (LLMs) to redefine personalization as an instruction-driven sequence generation task. However, fine-tuning on user logs inadvertently encodes sensitive attributes into model parameters, raising critical privacy concerns. Existing Machine Unlearning (MU) techniques struggle to navigate this tension due to the Polysemy Dilemma, where neurons superimpose sensitive data with general reasoning patterns, leading to catastrophic utility loss under traditional gradient or pruning methods. To address this, we propose Utility-aware Contrastive AttenuatioN (U-CAN), a precision unlearning framework that operates on low-rank adapters. U-CAN quantifies risk by contrasting activations and focuses on neurons with asymmetric responses that are highly sensitive to the forgetting set but suppressed on the retention set. To safeguard performance, we introduce a utility-aware calibration mechanism that combines weight magnitudes with retention-set activation norms, assigning higher utility scores to dimensions that contribute strongly to retention performance. Unlike binary pruning, which often fragments network structure, U-CAN develop adaptive soft attenuation with a differentiable decay function to selectively down-scale high-risk parameters on LoRA adapters, suppressing sensitive retrieval pathways and preserving the topological connectivity of reasoning circuits. Experiments on two public datasets across seven metrics demonstrate that U-CAN achieves strong privacy forgetting, utility retention, and computational efficiency.

</details>


### [155] [Long Range Frequency Tuning for QML](https://arxiv.org/abs/2602.23409)
*Michael Poppel,Jonas Stein,Sebastian Wölckert,Markus Baumann,Claudia Linnhoff-Popien*

Main category: cs.LG

TL;DR: 量子机器学习中的角度编码方法存在频率可训练性限制，传统可训练频率方法在实际中难以优化到目标频率值。论文提出基于三元编码的网格初始化方法，显著提升频率可达范围和模型性能。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习中使用角度编码的方法理论上可以通过可训练频率实现高效学习，但实际优化过程中发现频率预因子存在可训练性限制：梯度优化只能将频率值调整到约±1单位范围内，当目标频率超出此范围时优化经常失败。

Method: 提出基于三元编码的网格初始化方法，生成密集的整数频率谱。该方法需要O(log_3(ω_max))个编码门，虽然比理论最优方案多，但比固定频率方法指数级减少，确保目标频率位于局部可达范围内。

Result: 在三频移高频率合成目标上，三元网格初始化获得中位数R²分数0.9969，而可训练频率基线仅为0.1841。在实际Flight Passengers数据集上，三元网格初始化获得中位数R²分数0.9671，比可训练频率初始化（0.7876）提升22.8%。

Conclusion: 频率预因子的可训练性限制是量子机器学习中角度编码方法的关键瓶颈。三元网格初始化方法通过确保目标频率位于梯度优化可达范围内，显著提升了模型性能，为实际应用提供了有效解决方案。

Abstract: Quantum machine learning models using angle encoding naturally represent truncated Fourier series, providing universal function approximation capabilities with sufficient circuit depth. For unary fixed-frequency encodings, circuit depth scales as O(omega_max * (omega_max + epsilon^{-2})) with target frequency magnitude omega_max and precision epsilon. Trainable-frequency approaches theoretically reduce this to match the target spectrum size, requiring only as many encoding gates as frequencies in the target spectrum. Despite this compelling efficiency, their practical effectiveness hinges on a key assumption: that gradient-based optimization can drive prefactors to arbitrary target values. We demonstrate through systematic experiments that frequency prefactors exhibit limited trainability: movement is constrained to approximately +/-1 units with typical learning rates. When target frequencies lie outside this reachable range, optimization frequently fails. To overcome this frequency reachability limitation, we propose grid-based initialization using ternary encodings, which generate dense integer frequency spectra. While this approach requires O(log_3(omega_max)) encoding gates -- more than the theoretical optimum but exponentially fewer than fixed-frequency methods -- it ensures target frequencies lie within the locally reachable range. On synthetic targets with three shifted high frequencies, ternary grid initialization achieves a median R^2 score of 0.9969, compared to 0.1841 for the trainable-frequency baseline. For the real-world Flight Passengers dataset, ternary grid initialization achieves a median R^2 score of 0.9671, representing a 22.8% improvement over trainable-frequency initialization (median R^2 = 0.7876).

</details>


### [156] [EvoX: Meta-Evolution for Automated Discovery](https://arxiv.org/abs/2602.23413)
*Shu Liu,Shubham Agarwal,Monishwaran Maheswaran,Mert Cemri,Zhifei Li,Qiuyang Mang,Ashwin Naren,Ethan Boneh,Audrey Cheng,Melissa Z. Pan,Alexander Du,Kurt Keutzer,Alexandros G. Dimakis,Koushik Sen,Matei Zaharia,Ion Stoica*

Main category: cs.LG

TL;DR: EvoX是一种自适应进化方法，通过联合进化候选解和搜索策略，动态调整进化过程，在近200个真实世界优化任务中优于现有AI驱动的进化方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法如AlphaEvolve虽然结合了LLM驱动的优化和进化搜索，但依赖固定的搜索策略和预定义的参数，无法适应不同任务或任务中搜索空间随时间变化的情况。

Method: EvoX联合进化候选解和生成这些解的搜索策略，持续更新如何选择和变异先前解的方法，使系统能够在优化过程中动态切换不同的搜索策略。

Result: 在近200个真实世界优化任务中，EvoX在大多数任务上优于现有的AI驱动进化方法，包括AlphaEvolve、OpenEvolve、GEPA和ShinkaEvolve。

Conclusion: EvoX通过自适应优化自身的进化过程，能够动态调整搜索策略，显著提升了进化方法在各种优化任务中的性能表现。

Abstract: Recent work such as AlphaEvolve has shown that combining LLM-driven optimization with evolutionary search can effectively improve programs, prompts, and algorithms across domains. In this paradigm, previously evaluated solutions are reused to guide the model toward new candidate solutions. Crucially, the effectiveness of this evolution process depends on the search strategy: how prior solutions are selected and varied to generate new candidates. However, most existing methods rely on fixed search strategies with predefined knobs (e.g., explore-exploit ratios) that remain static throughout execution. While effective in some settings, these approaches often fail to adapt across tasks, or even within the same task as the search space changes over time. We introduce EvoX, an adaptive evolution method that optimizes its own evolution process. EvoX jointly evolves candidate solutions and the search strategies used to generate them, continuously updating how prior solutions are selected and varied based on progress. This enables the system to dynamically shift between different search strategies during the optimization process. Across nearly 200 real-world optimization tasks, EvoX outperforms existing AI-driven evolutionary methods including AlphaEvolve, OpenEvolve, GEPA, and ShinkaEvolve on the majority of tasks.

</details>


### [157] [Human Supervision as an Information Bottleneck: A Unified Theory of Error Floors in Human-Guided Learning](https://arxiv.org/abs/2602.23446)
*Alejandro Rodriguez Dominguez*

Main category: cs.LG

TL;DR: 论文提出"人类有界智能极限"理论，认为仅依赖人类监督的LLMs存在固有误差下限，源于标注噪声、偏好扭曲和语义压缩等监督通道的结构性限制，而非模型规模或优化问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型主要基于人类生成的数据和反馈进行训练，但表现出持续的误差，这些误差源于标注噪声、主观偏好和自然语言的有限表达能力。作者认为这些限制反映了监督通道的结构特性，而非模型规模或优化问题。

Method: 开发统一理论框架，证明当人类监督通道不足以捕捉潜在评估目标时，它会作为信息减少通道，为任何受其支配的学习器引入严格正的超额风险下限。通过六个互补框架（算子理论、PAC-Bayes、信息论、因果推断、范畴论和RLHF的博弈论分析）形式化这一"人类有界智能极限"。

Result: 理论解释了为什么仅靠扩展无法消除持续的人类对齐误差，并描述了辅助非人类信号（如检索、程序执行、工具）增加有效监督容量并消除误差下限的条件。在真实偏好数据、合成已知目标任务和外部可验证基准上的实验证实了预测的结构特征。

Conclusion: 仅依赖人类监督存在固有误差下限，而足够信息丰富的辅助通道可以严格减少或消除超额误差。这为理解LLMs的局限性提供了理论基础，并指出了通过结合非人类信号来超越人类监督限制的途径。

Abstract: Large language models are trained primarily on human-generated data and feedback, yet they exhibit persistent errors arising from annotation noise, subjective preferences, and the limited expressive bandwidth of natural language. We argue that these limitations reflect structural properties of the supervision channel rather than model scale or optimization. We develop a unified theory showing that whenever the human supervision channel is not sufficient for a latent evaluation target, it acts as an information-reducing channel that induces a strictly positive excess-risk floor for any learner dominated by it. We formalize this Human-Bounded Intelligence limit and show that across six complementary frameworks (operator theory, PAC-Bayes, information theory, causal inference, category theory, and game-theoretic analyses of reinforcement learning from human feedback), non-sufficiency yields strictly positive lower bounds arising from the same structural decomposition into annotation noise, preference distortion, and semantic compression. The theory explains why scaling alone cannot eliminate persistent human-aligned errors and characterizes conditions under which auxiliary non-human signals (e.g., retrieval, program execution, tools) increase effective supervision capacity and collapse the floor by restoring information about the latent target. Experiments on real preference data, synthetic known-target tasks, and externally verifiable benchmarks confirm the predicted structural signatures: human-only supervision exhibits a persistent floor, while sufficiently informative auxiliary channels strictly reduce or eliminate excess error.

</details>


### [158] [Global Interpretability via Automated Preprocessing: A Framework Inspired by Psychiatric Questionnaires](https://arxiv.org/abs/2602.23459)
*Eric V. Strobl*

Main category: cs.LG

TL;DR: REFINE方法通过将非线性处理限制在基线预处理阶段，然后使用线性模型预测未来症状严重程度，在保持可解释性的同时提高了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 精神病学问卷具有高度情境敏感性，对后续症状严重程度的预测能力较弱。虽然非线性模型可以提高预测准确性，但其有限的可解释性会削弱临床信任。需要一种既能提高预测准确性又能保持可解释性的方法。

Method: 采用两阶段方法：1）将非线性能力限制在基线预处理模块中，估计稳定的项目值；2）学习从这些稳定化的基线项目到未来严重程度的线性映射。这种方法被称为REFINE（冗余利用随访知情非线性增强）。

Result: REFINE在实验中优于其他可解释方法，同时在精神病学和非精神病学纵向预测任务中保持了预后因素的清晰全局归因。

Conclusion: 通过将非线性集中在预处理阶段，同时保持预后关系的透明线性，REFINE方法在提高预测准确性的同时保持了全局可解释性，为临床实践提供了可信的预测工具。

Abstract: Psychiatric questionnaires are highly context sensitive and often only weakly predict subsequent symptom severity, which makes the prognostic relationship difficult to learn. Although flexible nonlinear models can improve predictive accuracy, their limited interpretability can erode clinical trust. In fields such as imaging and omics, investigators commonly address visit- and instrument-specific artifacts by extracting stable signal through preprocessing and then fitting an interpretable linear model. We adopt the same strategy for questionnaire data by decoupling preprocessing from prediction: we restrict nonlinear capacity to a baseline preprocessing module that estimates stable item values, and then learn a linear mapping from these stabilized baseline items to future severity. We refer to this two-stage method as REFINE (Redundancy-Exploiting Follow-up-Informed Nonlinear Enhancement), which concentrates nonlinearity in preprocessing while keeping the prognostic relationship transparently linear and therefore globally interpretable through a coefficient matrix, rather than through post hoc local attributions. In experiments, REFINE outperforms other interpretable approaches while preserving clear global attribution of prognostic factors across psychiatric and non-psychiatric longitudinal prediction tasks.

</details>


### [159] [Uncertainty-aware Language Guidance for Concept Bottleneck Models](https://arxiv.org/abs/2602.23495)
*Yangyi Li,Mengdi Huai*

Main category: cs.LG

TL;DR: 提出一种不确定性感知的概念瓶颈模型方法，通过量化LLM标注概念的不确定性并纳入模型训练，解决现有方法忽视LLM标注不确定性和缺乏有效量化机制的问题。


<details>
  <summary>Details</summary>
Motivation: 传统概念瓶颈模型需要大量专家知识标注概念，限制了广泛应用。现有利用LLM构建概念瓶颈的方法存在两个关键局限：忽视LLM标注概念的不确定性，缺乏有效的量化机制；未能将标注不确定性纳入模型学习过程。

Method: 提出一种新颖的不确定性感知CBM方法，不仅严格量化LLM标注概念标签的不确定性（具有有效且无分布假设的保证），还将量化的概念不确定性纳入CBM训练过程，以考虑LLM标注概念的不同可靠性水平。

Result: 在真实世界数据集上进行广泛实验，验证了所提出方法的期望特性。

Conclusion: 该方法通过量化LLM标注概念的不确定性并将其纳入训练过程，解决了现有方法的局限性，为概念瓶颈模型提供了更可靠的实现途径。

Abstract: Concept Bottleneck Models (CBMs) provide inherent interpretability by first mapping input samples to high-level semantic concepts, followed by a combination of these concepts for the final classification. However, the annotation of human-understandable concepts requires extensive expert knowledge and labor, constraining the broad adoption of CBMs. On the other hand, there are a few works that leverage the knowledge of large language models (LLMs) to construct concept bottlenecks. Nevertheless, they face two essential limitations: First, they overlook the uncertainty associated with the concepts annotated by LLMs and lack a valid mechanism to quantify uncertainty about the annotated concepts, increasing the risk of errors due to hallucinations from LLMs. Additionally, they fail to incorporate the uncertainty associated with these annotations into the learning process for concept bottleneck models. To address these limitations, we propose a novel uncertainty-aware CBM method, which not only rigorously quantifies the uncertainty of LLM-annotated concept labels with valid and distribution-free guarantees, but also incorporates quantified concept uncertainty into the CBM training procedure to account for varying levels of reliability across LLM-annotated concepts. We also provide the theoretical analysis for our proposed method. Extensive experiments on the real-world datasets validate the desired properties of our proposed methods.

</details>


### [160] [FedDAG: Clustered Federated Learning via Global Data and Gradient Integration for Heterogeneous Environments](https://arxiv.org/abs/2602.23504)
*Anik Pramanik,Murat Kantarcioglu,Vincent Oria,Shantanu Sharma*

Main category: cs.LG

TL;DR: FedDAG提出了一种新的聚类联邦学习框架，通过整合数据和梯度信息的加权类相似性度量进行聚类，并采用双编码器架构实现跨集群特征转移，在异构数据场景下显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统聚类联邦学习方法存在两个主要问题：1) 仅依赖数据相似性或梯度相似性进行聚类，导致对客户端相似性的评估不完整；2) 限制知识和表征共享仅限于同一集群内，使得集群模型无法从跨集群的多样化客户端群体中受益。

Method: FedDAG采用加权类相似性度量，整合数据和梯度信息进行更全面的客户端聚类。同时，采用双编码器架构：主编码器在自身客户端数据上训练，辅助编码器利用互补集群的梯度进行精炼，实现跨集群特征转移同时保持集群特定专业化。

Result: 在多种基准测试和数据异构设置下的实验表明，FedDAG在准确率方面持续优于最先进的聚类联邦学习基线方法。

Conclusion: FedDAG通过更全面的相似性度量和跨集群知识共享机制，有效解决了传统聚类联邦学习在数据异构场景下的局限性，显著提升了模型性能。

Abstract: Federated Learning (FL) enables a group of clients to collaboratively train a model without sharing individual data, but its performance drops when client data are heterogeneous. Clustered FL tackles this by grouping similar clients. However, existing clustered FL approaches rely solely on either data similarity or gradient similarity; however, this results in an incomplete assessment of client similarities. Prior clustered FL approaches also restrict knowledge and representation sharing to clients within the same cluster. This prevents cluster models from benefiting from the diverse client population across clusters. To address these limitations, FedDAG introduces a clustered FL framework, FedDAG, that employs a weighted, class-wise similarity metric that integrates both data and gradient information, providing a more holistic measure of similarity during clustering. In addition, FedDAG adopts a dual-encoder architecture for cluster models, comprising a primary encoder trained on its own clients' data and a secondary encoder refined using gradients from complementary clusters. This enables cross-cluster feature transfer while preserving cluster-specific specialization. Experiments on diverse benchmarks and data heterogeneity settings show that FedDAG consistently outperforms state-of-the-art clustered FL baselines in accuracy.

</details>


### [161] [Sample Size Calculations for Developing Clinical Prediction Models: Overview and pmsims R package](https://arxiv.org/abs/2602.23507)
*Diana Shamsutdinova,Felix Zimmer,Oyebayo Ridwan Olaniran,Sarah Markham,Daniel Stahl,Gordon Forbes,Ewan Carr*

Main category: cs.LG

TL;DR: 本文提出了一种新的临床预测模型样本量确定方法，结合学习曲线、高斯过程优化和保证原则，开发了开源的R包pmsims，为复杂数据结构和机器学习模型提供灵活高效的样本量估计解决方案。


<details>
  <summary>Details</summary>
Motivation: 临床预测模型在医疗决策中的应用日益广泛，但确定其开发所需的最小样本量仍然是一个关键且未解决的挑战。样本量不足会导致过拟合、泛化能力差和预测偏差。现有方法（如经验法则、封闭公式和基于模拟的方法）在灵活性和准确性方面存在差异，特别是对于复杂数据结构和机器学习模型。

Method: 本文回顾了预测建模中样本量估计的现有方法，提出了一个区分均值标准和保证标准的概念框架。在此基础上，提出了一种新颖的基于模拟的方法，该方法整合了学习曲线、高斯过程优化和保证原则，以确定能够以高概率达到目标性能的样本量。该方法在开源的、模型无关的R包pmsims中实现。

Result: 通过案例研究证明，样本量估计在不同方法、性能指标和建模策略之间存在显著差异。与现有工具相比，pmsims提供了灵活、高效且可解释的解决方案，能够适应多样化的模型和用户定义的指标，同时明确考虑模型性能的变异性。

Conclusion: 本文提出的框架和软件通过将灵活性与计算效率相结合，推进了临床预测建模的样本量方法学。未来工作应将这些方法扩展到分层和多模态数据，纳入公平性和稳定性指标，并解决缺失数据和复杂依赖结构等挑战。

Abstract: Background: Clinical prediction models are increasingly used to inform healthcare decisions, but determining the minimum sample size for their development remains a critical and unresolved challenge. Inadequate sample sizes can lead to overfitting, poor generalisability, and biased predictions. Existing approaches, such as heuristic rules, closed-form formulas, and simulation-based methods, vary in flexibility and accuracy, particularly for complex data structures and machine learning models. Methods: We review current methodologies for sample size estimation in prediction modelling and introduce a conceptual framework that distinguishes between mean-based and assurance-based criteria. Building on this, we propose a novel simulation-based approach that integrates learning curves, Gaussian Process optimisation, and assurance principles to identify sample sizes that achieve target performance with high probability. This approach is implemented in pmsims, an open-source, model-agnostic R package. Results: Through case studies, we demonstrate that sample size estimates vary substantially across methods, performance metrics, and modelling strategies. Compared to existing tools, pmsims provides flexible, efficient, and interpretable solutions that accommodate diverse models and user-defined metrics while explicitly accounting for variability in model performance. Conclusions: Our framework and software advance sample size methodology for clinical prediction modelling by combining flexibility with computational efficiency. Future work should extend these methods to hierarchical and multimodal data, incorporate fairness and stability metrics, and address challenges such as missing data and complex dependency structures.

</details>


### [162] [Neural Operators Can Discover Functional Clusters](https://arxiv.org/abs/2602.23528)
*Yicen Li,Jose Antonio Lara Benitez,Ruiyang Hong,Anastasis Kratsios,Paul David McNicholas,Maarten Valentijn de Hoop*

Main category: cs.LG

TL;DR: 论文证明了基于样本的神经算子能够学习无限维再生核希尔伯特空间中任意有限类别集合，即使类别非凸非连通，并开发了用于函数数据聚类的神经算子管道，在ODE轨迹分析中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 神经算子在回归任务中已有深入研究，但在分类及其无监督对应任务——聚类方面了解甚少。本文旨在填补这一空白，探索神经算子在无限维函数空间中的聚类能力。

Method: 1. 理论证明：在温和的核采样假设下，证明基于样本的神经算子能够学习无限维再生核希尔伯特空间中任意有限类别集合；2. 实用管道：开发神经算子驱动的函数数据聚类管道，包括预训练编码器将离散轨迹提升为连续特征映射，轻量级可训练头部映射到软分配。

Result: 1. 提出通用聚类定理：任何K个闭类都可以在闭集的上Kuratowski拓扑中被神经算子参数化的类以任意精度逼近；2. 在合成ODE基准测试中，提出的实用SNO方法在经典方法失败的场景下成功恢复潜在动态结构。

Conclusion: 神经算子不仅适用于回归任务，也能有效处理无限维函数空间中的聚类问题。理论证明和实验结果一致表明，神经算子能够学习复杂非凸非连通的类别结构，为函数数据分析提供了新的强大工具。

Abstract: Operator learning is reshaping scientific computing by amortizing inference across infinite families of problems. While neural operators (NOs) are increasingly well understood for regression, far less is known for classification and its unsupervised analogue: clustering. We prove that sample-based neural operators can learn any finite collection of classes in an infinite-dimensional reproducing kernel Hilbert space, even when the classes are neither convex nor connected, under mild kernel sampling assumptions. Our universal clustering theorem shows that any $K$ closed classes can be approximated to arbitrary precision by NO-parameterized classes in the upper Kuratowski topology on closed sets, a notion that can be interpreted as disallowing false-positive misclassifications.
  Building on this, we develop an NO-powered clustering pipeline for functional data and apply it to unlabeled families of ordinary differential equation (ODE) trajectories. Discretized trajectories are lifted by a fixed pre-trained encoder into a continuous feature map and mapped to soft assignments by a lightweight trainable head. Experiments on diverse synthetic ODE benchmarks show that the resulting practical SNO recovers latent dynamical structure in regimes where classical methods fail, providing evidence consistent with our universal clustering theory.

</details>


### [163] [Active Value Querying to Minimize Additive Error in Subadditive Set Function Learning](https://arxiv.org/abs/2602.23529)
*Martin Černý,David Sychrovský,Filip Úradník,Jakub Černý*

Main category: cs.LG

TL;DR: 研究如何通过添加额外子集值来最小化不完全次可加集函数的补全距离，包括理论分析和在线/离线算法设计


<details>
  <summary>Details</summary>
Motivation: 次可加集函数在多个领域有重要应用，但完整指定需要指数级数量的值，实践中往往不完整。不完全集函数在优化时会产生歧义，需要研究如何有效近似未知的次可加集函数

Method: 1) 探索不同类别集函数的最小和最大补全及其距离分析；2) 开发在已知先验下通过披露额外子集值来最小化距离的方法，包括离线和在线方式；3) 在实际场景中进行算法性能的实证演示

Result: 提出了系统的方法来处理不完全次可加集函数的近似问题，包括理论分析和实用算法，并在实际场景中验证了算法性能

Conclusion: 该研究为解决不完全次可加集函数的近似问题提供了理论和算法框架，能够有效减少补全距离，在实际应用中具有重要价值

Abstract: Subadditive set functions play a pivotal role in computational economics (especially in combinatorial auctions), combinatorial optimization or artificial intelligence applications such as interpretable machine learning. However, specifying a set function requires assigning values to an exponentially large number of subsets in general, a task that is often resource-intensive in practice, particularly when the values derive from external sources such as retraining of machine learning models. A~simple omission of certain values introduces ambiguity that becomes even more significant when the incomplete set function has to be further optimized over. Motivated by the well-known result about inapproximability of subadditive functions using deterministic value queries with respect to a multiplicative error, we study a problem of approximating an unknown subadditive (or a subclass of thereof) set function with respect to an additive error -- i. e., we aim to efficiently close the distance between minimal and maximal completions. Our contributions are threefold: (i) a thorough exploration of minimal and maximal completions of different classes of set functions with missing values and an analysis of their resulting distance; (ii) the development of methods to minimize this distance over classes of set functions with a known prior, achieved by disclosing values of additional subsets in both offline and online manner; and (iii) empirical demonstrations of the algorithms' performance in practical scenarios.

</details>


### [164] [Dynamics of Learning under User Choice: Overspecialization and Peer-Model Probing](https://arxiv.org/abs/2602.23565)
*Adhyyan Narang,Sarah Dean,Lillian J Ratliff,Maryam Fazel*

Main category: cs.LG

TL;DR: 论文研究了多平台机器学习中的"过度专业化陷阱"问题，提出通过知识蒸馏技术让平台"探测"同行模型预测来解决数据选择偏差，确保收敛到全局性能良好的模型。


<details>
  <summary>Details</summary>
Motivation: 在多平台机器学习部署场景中，用户会选择最适合自己的平台，导致每个平台只能观察到选择自己的用户数据。现有算法只关注局部损失，可能导致模型全局性能极差，即使存在低全人口损失的模型。

Method: 提出基于知识蒸馏的算法，允许学习者"探测"同行模型的预测，从而了解不选择自己的用户信息。当探测源足够信息丰富时（如已知的市场领导者或大多数具有良好全局性能的同行），该算法能收敛到具有有界全人口风险的稳定点。

Result: 分析表明，当探测源足够信息丰富时，提出的算法几乎必然收敛到具有有界全人口风险的稳定点。在MovieLens、Census和Amazon Sentiment数据集上的半合成实验验证了这一发现。

Conclusion: 在多平台机器学习环境中，通过知识蒸馏让平台探测同行模型预测可以有效避免"过度专业化陷阱"，确保模型具有良好的全局性能，特别是在探测源信息丰富的情况下。

Abstract: In many economically relevant contexts where machine learning is deployed, multiple platforms obtain data from the same pool of users, each of whom selects the platform that best serves them. Prior work in this setting focuses exclusively on the "local" losses of learners on the distribution of data that they observe. We find that there exist instances where learners who use existing algorithms almost surely converge to models with arbitrarily poor global performance, even when models with low full-population loss exist. This happens through a feedback-induced mechanism, which we call the overspecialization trap: as learners optimize for users who already prefer them, they become less attractive to users outside this base, which further restricts the data they observe. Inspired by the recent use of knowledge distillation in modern ML, we propose an algorithm that allows learners to "probe" the predictions of peer models, enabling them to learn about users who do not select them. Our analysis characterizes when probing succeeds: this procedure converges almost surely to a stationary point with bounded full-population risk when probing sources are sufficiently informative, e.g., a known market leader or a majority of peers with good global performance. We verify our findings with semi-synthetic experiments on the MovieLens, Census, and Amazon Sentiment datasets.

</details>


### [165] [SDMixer: Sparse Dual-Mixer for Time Series Forecasting](https://arxiv.org/abs/2602.23581)
*Xiang Ao*

Main category: cs.LG

TL;DR: 提出双流稀疏Mixer预测框架，通过频域和时域分别提取序列的全局趋势和局部动态特征，使用稀疏机制过滤无效信息，提升跨变量依赖建模精度


<details>
  <summary>Details</summary>
Motivation: 多元时间序列预测在交通、能源、金融等领域广泛应用，但数据常存在多尺度特征、弱相关性和噪声干扰等问题，限制了现有模型的预测性能

Method: 双流稀疏Mixer预测框架，分别从频域和时域提取序列的全局趋势和局部动态特征，采用稀疏机制过滤无效信息，增强跨变量依赖建模能力

Result: 在多个真实场景数据集上取得了领先性能，验证了方法的有效性和通用性

Conclusion: 提出的双流稀疏Mixer框架能有效处理多元时间序列的多尺度特征、弱相关性和噪声问题，提升预测性能，具有实际应用价值

Abstract: Multivariate time series forecasting is widely applied in fields such as transportation, energy, and finance. However, the data commonly suffers from issues of multi-scale characteristics, weak correlations, and noise interference, which limit the predictive performance of existing models. This paper proposes a dual-stream sparse Mixer prediction framework that extracts global trends and local dynamic features from sequences in both the frequency and time domains, respectively. It employs a sparsity mechanism to filter out invalid information, thereby enhancing the accuracy of cross-variable dependency modeling. Experimental results demonstrate that this method achieves leading performance on multiple real-world scenario datasets, validating its effectiveness and generality. The code is available at https://github.com/SDMixer/SDMixer

</details>


### [166] [When Does Multimodal Learning Help in Healthcare? A Benchmark on EHR and Chest X-Ray Fusion](https://arxiv.org/abs/2602.23614)
*Kejing Yin,Haizhou Xu,Wenfang Yao,Chen Liu,Zijie Chen,Yui Haang Cheung,William K. Cheung,Jing Qin*

Main category: cs.LG

TL;DR: 该研究系统评估了电子健康记录（EHR）和胸部X光（CXR）的多模态融合在临床预测中的效果，分析了融合策略、模态缺失鲁棒性和算法公平性，并发布了开源基准工具包。


<details>
  <summary>Details</summary>
Motivation: 机器学习在临床决策支持中具有潜力，但多模态学习在实际应用中何时真正有效尚不明确，特别是在模态缺失和公平性约束下。本研究旨在回答四个基本问题：多模态融合何时能改善临床预测、不同融合策略的比较、现有方法对缺失模态的鲁棒性，以及多模态模型是否能实现算法公平。

Method: 使用MIMIC-IV和MIMIC-CXR标准化队列，系统性地对EHR和CXR的多模态融合进行基准测试。研究比较了不同的融合策略，评估了模型对模态缺失的鲁棒性，并分析了算法公平性。同时开发并发布了支持可插拔模型和数据集集成的灵活基准测试工具包。

Result: 研究发现：1）模态完整时多模态融合能提升性能，增益主要集中在需要EHR和CXR互补信息的疾病上；2）跨模态学习机制能捕获超越简单拼接的临床相关依赖关系，但EHR的丰富时间结构导致强烈的模态不平衡；3）在实际缺失情况下，多模态优势迅速下降，除非模型专门设计处理不完整输入；4）多模态融合并不固有地改善公平性，亚组差异主要源于不同人口群体间的敏感性不平等。

Conclusion: 该研究为多模态学习何时有效、何时失败以及原因提供了可操作的指导，为开发既有效又可靠的临床可部署多模态系统奠定了基础。开源工具包支持可重现和可扩展的评估。

Abstract: Machine learning holds promise for advancing clinical decision support, yet it remains unclear when multimodal learning truly helps in practice, particularly under modality missingness and fairness constraints. In this work, we conduct a systematic benchmark of multimodal fusion between Electronic Health Records (EHR) and chest X-rays (CXR) on standardized cohorts from MIMIC-IV and MIMIC-CXR, aiming to answer four fundamental questions: when multimodal fusion improves clinical prediction, how different fusion strategies compare, how robust existing methods are to missing modalities, and whether multimodal models achieve algorithmic fairness. Our study reveals several key insights. Multimodal fusion improves performance when modalities are complete, with gains concentrating in diseases that require complementary information from both EHR and CXR. While cross-modal learning mechanisms capture clinically meaningful dependencies beyond simple concatenation, the rich temporal structure of EHR introduces strong modality imbalance that architectural complexity alone cannot overcome. Under realistic missingness, multimodal benefits rapidly degrade unless models are explicitly designed to handle incomplete inputs. Moreover, multimodal fusion does not inherently improve fairness, with subgroup disparities mainly arising from unequal sensitivity across demographic groups. To support reproducible and extensible evaluation, we further release a flexible benchmarking toolkit that enables plug-and-play integration of new models and datasets. Together, this work provides actionable guidance on when multimodal learning helps, when it fails, and why, laying the foundation for developing clinically deployable multimodal systems that are both effective and reliable. The open-source toolkit can be found at https://github.com/jakeykj/CareBench.

</details>


### [167] [On the Convergence of Single-Loop Stochastic Bilevel Optimization with Approximate Implicit Differentiation](https://arxiv.org/abs/2602.23633)
*Yubo Zhou,Luo Luo,Guang Dai,Haishan Ye*

Main category: cs.LG

TL;DR: 本文对单层随机近似隐式微分算法（SSAID）进行了收敛性分析，证明了该算法达到ε-平稳点的Oracle复杂度为O(κ⁷ε⁻²)，匹配了多层方法的最优收敛率。


<details>
  <summary>Details</summary>
Motivation: 随机双层优化在元学习和超参数优化中具有重要应用。单层算法在实践中广泛应用，但其理论分析（特别是在随机环境下）远落后于多层算法。现有分析通常收敛率次优，且未能清晰揭示对下层条件数κ的依赖关系。

Method: 本文对单层随机近似隐式微分算法（SSAID）进行了精细化的收敛性分析。该方法采用单层更新策略，同时更新上层和下层变量，避免了多层算法中交替优化的计算开销。

Result: 证明了SSAID算法达到ε-平稳点的Oracle复杂度为O(κ⁷ε⁻²)。这一结果在两个方面具有重要意义：1）匹配了最先进多层方法（如stocBiO）的最优O(ε⁻²)收敛率；2）首次为基于随机AID的单层方法提供了明确的、细粒度的κ依赖关系分析。

Conclusion: SSAID不仅是一种启发式方法，而且具有严格的理论基础，其收敛保证与主流多层框架具有竞争力。该工作填补了单层随机双层优化算法理论分析的空白，为实际应用提供了理论支持。

Abstract: Stochastic Bilevel Optimization has emerged as a fundamental framework for meta-learning and hyperparameter optimization. Despite the practical prevalence of single-loop algorithms--which update lower and upper variables concurrently--their theoretical understanding, particularly in the stochastic regime, remains significantly underdeveloped compared to their multi-loop counterparts. Existing analyses often yield suboptimal convergence rates or obscure the critical dependence on the lower-level condition number $κ$, frequently burying it within generic Lipschitz constants. In this paper, we bridge this gap by providing a refined convergence analysis of the Single-loop Stochastic Approximate Implicit Differentiation (SSAID) algorithm. We prove that SSAID achieves an $ε$-stationary point with an oracle complexity of $\mathcal{O}(κ^7 ε^{-2})$. Our result is noteworthy in two aspects: (i) it matches the optimal $\mathcal{O}(ε^{-2})$ rate of state-of-the-art multi-loop methods (e.g., stocBiO) while maintaining the computational efficiency of a single-loop update; and (ii) it provides the first explicit, fine-grained characterization of the $κ$-dependence for stochastic AID-based single-loop methods. This work demonstrates that SSAID is not merely a heuristic approach, but admits a rigorous theoretical foundation with convergence guarantees competitive with mainstream multi-loop frameworks.

</details>


### [168] [FlexGuard: Continuous Risk Scoring for Strictness-Adaptive LLM Content Moderation](https://arxiv.org/abs/2602.23636)
*Zhihao Ding,Jinming Li,Ze Lu,Jieming Shi*

Main category: cs.LG

TL;DR: 论文提出FlexGuard方法解决LLM内容审核中严格度变化的问题，通过连续风险评分和阈值调整来适应不同平台和时间的审核需求。


<details>
  <summary>Details</summary>
Motivation: 现有LLM内容安全审核模型通常采用固定的二元分类方法，假设有害内容的定义是固定的。但实际上，不同平台的执行严格度（如何定义和强制执行有害内容）各不相同且随时间演变，导致二元审核器在需求变化时变得脆弱。

Method: 首先创建FlexBench基准，支持多严格度制度下的受控评估。然后提出FlexGuard方法：基于LLM的审核器输出校准的连续风险评分反映风险严重程度，通过阈值调整支持特定严格度决策。通过风险对齐优化训练提高评分-严重度一致性，并提供实用的阈值选择策略以适应部署时的目标严格度。

Result: 在FlexBench和公共基准测试上的实验表明，FlexGuard实现了更高的审核准确性，并在不同严格度下显著提高了鲁棒性。现有审核器在不同严格度制度下存在显著的跨严格度不一致性，而FlexGuard有效解决了这一问题。

Conclusion: FlexGuard通过连续风险评分和阈值调整机制，为LLM内容审核提供了灵活适应不同严格度要求的解决方案，提高了实际部署中的可用性和鲁棒性。

Abstract: Ensuring the safety of LLM-generated content is essential for real-world deployment. Most existing guardrail models formulate moderation as a fixed binary classification task, implicitly assuming a fixed definition of harmfulness. In practice, enforcement strictness - how conservatively harmfulness is defined and enforced - varies across platforms and evolves over time, making binary moderators brittle under shifting requirements. We first introduce FlexBench, a strictness-adaptive LLM moderation benchmark that enables controlled evaluation under multiple strictness regimes. Experiments on FlexBench reveal substantial cross-strictness inconsistency in existing moderators: models that perform well under one regime can degrade substantially under others, limiting their practical usability. To address this, we propose FlexGuard, an LLM-based moderator that outputs a calibrated continuous risk score reflecting risk severity and supports strictness-specific decisions via thresholding. We train FlexGuard via risk-alignment optimization to improve score-severity consistency and provide practical threshold selection strategies to adapt to target strictness at deployment. Experiments on FlexBench and public benchmarks demonstrate that FlexGuard achieves higher moderation accuracy and substantially improved robustness under varying strictness. We release the source code and data to support reproducibility.

</details>


### [169] [FedRot-LoRA: Mitigating Rotational Misalignment in Federated LoRA](https://arxiv.org/abs/2602.23638)
*Haoran Zhang,Dongjun Kim,Seohyeon Cha,Haris Vikalo*

Main category: cs.LG

TL;DR: FedRot-LoRA：通过正交变换对齐客户端更新的联邦LoRA框架，解决因子平均导致的旋转不对齐问题，提升训练稳定性和性能


<details>
  <summary>Details</summary>
Motivation: 联邦LoRA在去中心化数据上微调大语言模型时，因子平均与数学正确聚合之间的差异会导致显著的聚合误差和不稳定训练。主要问题是旋转不对齐——由于低秩分解的旋转不变性，语义等效的更新在不同客户端可能表示在不同的潜在子空间中，直接平均这些不对齐的因子会产生破坏性干扰。

Method: 提出FedRot-LoRA框架，在聚合前通过正交变换对齐客户端更新。这种对齐在保持语义更新的同时减少跨客户端子空间不匹配，不增加通信成本或限制模型表达能力。提供了收敛分析，检查因子平均引起的聚合误差，并展示旋转对齐如何产生更紧的误差上界。

Result: 在自然语言理解和生成任务上的大量实验表明，FedRot-LoRA在各种异构程度和LoRA秩的设置下，始终优于现有的联邦LoRA基线方法。

Conclusion: FedRot-LoRA通过解决联邦LoRA中的旋转不对齐问题，提供了一种通信高效且稳定的微调框架，显著提升了联邦学习场景下的模型性能。

Abstract: Federated LoRA provides a communication-efficient mechanism for fine-tuning large language models on decentralized data. In practice, however, a discrepancy between the factor-wise averaging used to preserve low rank and the mathematically correct aggregation of local updates can cause significant aggregation error and unstable training. We argue that a major source of this problem is rotational misalignment, arising from the rotational invariance of low-rank factorizations -- semantically equivalent updates can be represented in different latent subspaces across clients since $(B_i R_i)(R_i^\top A_i) = B_i A_i$. When such misaligned factors are averaged directly, they interfere destructively and degrade the global update. To address this issue, we propose FedRot-LoRA, a federated LoRA framework that aligns client updates via orthogonal transformations prior to aggregation. This alignment preserves the semantic update while reducing cross-client subspace mismatch, without increasing communication cost or restricting model expressivity. We provide a convergence analysis that examines the aggregation error induced by factor-wise averaging and shows how rotational alignment yields a tighter upper bound on this error. Extensive experiments on natural language understanding and generative tasks demonstrate that FedRot-LoRA consistently outperforms existing federated LoRA baselines across a range of heterogeneity levels and LoRA ranks.

</details>


### [170] [Selective Denoising Diffusion Model for Time Series Anomaly Detection](https://arxiv.org/abs/2602.23662)
*Kohei Obata,Zheng Chen,Yasuko Matsubara,Lingwei Zhu,Yasushi Sakurai*

Main category: cs.LG

TL;DR: 提出了一种名为AnomalyFilter的新型扩散模型方法，通过选择性过滤仅对时间序列中的异常部分进行去噪，同时保留正常部分，从而提升异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的时间序列异常检测方法采用条件策略，从白噪声中重建输入实例，但难以准确重建正常部分，导致检测性能不理想。需要一种能选择性处理异常部分的方法。

Method: 提出AnomalyFilter方法，在训练阶段对高斯噪声进行掩码处理，在去噪过程中不向实例添加噪声，构建一个选择性过滤器，仅对异常部分进行去噪而保留正常部分。

Result: 在五个数据集上的广泛实验表明，AnomalyFilter在正常部分实现了显著较低的重建误差，为异常检测的有效性提供了实证支持。

Conclusion: AnomalyFilter代表了一种专注于为时间序列异常检测量身定制的扩散模型噪声设计的开创性方法，通过两个简单组件的协同作用大大提升了朴素扩散模型的性能。

Abstract: Time series anomaly detection (TSAD) has been an important area of research for decades, with reconstruction-based methods, mostly based on generative models, gaining popularity and demonstrating success. Diffusion models have recently attracted attention due to their advanced generative capabilities. Existing diffusion-based methods for TSAD rely on a conditional strategy, which reconstructs input instances from white noise with the aid of the conditioner. However, this poses challenges in accurately reconstructing the normal parts, resulting in suboptimal detection performance. In response, we propose a novel diffusion-based method, named AnomalyFilter, which acts as a selective filter that only denoises anomaly parts in the instance while retaining normal parts. To build such a filter, we mask Gaussian noise during the training phase and conduct the denoising process without adding noise to the instances. The synergy of the two simple components greatly enhances the performance of naive diffusion models. Extensive experiments on five datasets demonstrate that AnomalyFilter achieves notably low reconstruction error on normal parts, providing empirical support for its effectiveness in anomaly detection. AnomalyFilter represents a pioneering approach that focuses on the noise design of diffusion models specifically tailored for TSAD.

</details>


### [171] [Disentangled Mode-Specific Representations for Tensor Time Series via Contrastive Learning](https://arxiv.org/abs/2602.23663)
*Kohei Obata,Taichi Murayama,Zheng Chen,Yasuko Matsubara,Yasushi Sakurai*

Main category: cs.LG

TL;DR: MoST：一种针对多模态张量时间序列的表示学习方法，通过张量切片降低复杂度，学习可解耦为各非时序模态的表示，结合对比学习框架提升分类和预测性能。


<details>
  <summary>Details</summary>
Motivation: 多模态张量时间序列（如搜索引擎、环境监测系统）的表示学习对多种应用有益，但由于张量结构的复杂性，难以获得丰富的表示。

Method: 提出MoST方法：1）使用张量切片降低TTS结构复杂度；2）学习可解耦为各非时序模态的表示；3）每个表示包含模态特定特征（同一模态内变量关系）和模态不变特征（不同模态共有）；4）采用对比学习框架，损失函数包含模态特定学习和模态不变学习两部分，有效利用解耦表示作为增强。

Result: 在真实世界数据集上的大量实验表明，MoST在分类和预测准确率方面持续优于现有最先进方法。

Conclusion: MoST是一种专门为张量时间序列设计的有效表示学习方法，能够处理张量结构的复杂性，通过解耦表示学习模态特定和模态不变特征，在多个任务上表现优异。

Abstract: Multi-mode tensor time series (TTS) can be found in many domains, such as search engines and environmental monitoring systems. Learning representations of a TTS benefits various applications, but it is also challenging since the complexities inherent in the tensor hinder the realization of rich representations. In this paper, we propose a novel representation learning method designed specifically for TTS, namely MoST. Specifically, MoST uses a tensor slicing approach to reduce the complexity of the TTS structure and learns representations that can be disentangled into individual non-temporal modes. Each representation captures mode-specific features, which are the relationship between variables within the same mode, and mode-invariant features, which are in common in representations of different modes. We employ a contrastive learning framework to learn parameters; the loss function comprises two parts intended to learn representation in a mode-specific way and mode-invariant way, effectively exploiting disentangled representations as augmentations. Extensive experiments on real-world datasets show that MoST consistently outperforms the state-of-the-art methods in terms of classification and forecasting accuracy. Code is available at https://github.com/KoheiObata/MoST.

</details>


### [172] [Optimizer-Induced Low-Dimensional Drift and Transverse Dynamics in Transformer Training](https://arxiv.org/abs/2602.23696)
*Yongzhong Xu*

Main category: cs.LG

TL;DR: 研究发现小Transformer模型的训练轨迹具有主导漂移方向与横向残余动力学的几何结构，不同优化器（AdamW vs SGD）在轨迹几何上存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 研究训练轨迹的几何结构，探索优化器选择如何影响学习轨迹的有效维度和结构，而不仅仅是损失值的变化。

Method: 使用未中心化、行归一化的轨迹PCA分析小Transformer模型的参数更新轨迹，比较AdamW与SGD变体在匹配损失水平下的轨迹几何差异，并通过重新加热实验验证。

Result: 参数更新组织成主导漂移方向与横向残余动力学；单一方向在训练早期捕获大部分累积参数移动；瞬时梯度与主导方向对齐度低；AdamW产生多维漂移结构，而SGD产生近乎共线的参数演化；重新加热选择性地扰动横向分量。

Conclusion: 优化器选择塑造了学习轨迹的有效维度和结构，超越了仅从损失值观察到的效果，AdamW和SGD在训练轨迹几何上存在本质差异。

Abstract: We study the geometry of training trajectories in small transformer models and find that parameter updates organize into a dominant drift direction with transverse residual dynamics. Using uncentered, row-normalized trajectory PCA, we show that a single direction captures a large fraction of cumulative parameter movement early in training, while remaining components encode oscillatory behavior in auxiliary probe performance. Instantaneous gradients exhibit little alignment with this dominant direction, indicating that it arises from accumulated optimizer updates rather than per-batch gradient structure. Comparing AdamW with SGD variants at matched loss levels reveals substantial differences in trajectory geometry: AdamW develops multi-dimensional drift structure, whereas SGD-family optimizers produce nearly colinear parameter evolution and weaker probe dynamics. Reheating selectively perturbs transverse components with minimal effect on the dominant drift coordinate. These findings suggest that optimizer choice shapes the effective dimensionality and structure of learning trajectories beyond what is apparent from loss values alone.

</details>


### [173] [Bridging Dynamics Gaps via Diffusion Schrödinger Bridge for Cross-Domain Reinforcement Learning](https://arxiv.org/abs/2602.23737)
*Hanping Zhang,Yuhong Guo*

Main category: cs.LG

TL;DR: 提出BDGxRL框架，利用扩散薛定谔桥对齐源域和目标域动态，通过奖励调制机制估计奖励，实现在源域内学习适用于目标域的策略，无需目标域环境交互或奖励监督。


<details>
  <summary>Details</summary>
Motivation: 跨域强化学习面临的主要挑战是缺乏目标域环境交互和奖励监督，这阻碍了直接策略学习。需要一种方法能够在源域内学习适用于目标域的策略。

Method: 提出BDGxRL框架：1）使用扩散薛定谔桥将源域状态转移与目标域离线演示编码的动态对齐；2）引入奖励调制机制，基于状态转移估计奖励，确保奖励与目标域动态的一致性。

Result: 在MuJoCo跨域基准测试中，BDGxRL优于现有最先进方法，在转移动态变化下表现出强大的适应性。

Conclusion: BDGxRL通过动态对齐和奖励调制，实现了在源域内进行目标导向的策略学习，无需访问目标环境或其奖励，有效解决了跨域强化学习中的动态差异问题。

Abstract: Cross-domain reinforcement learning (RL) aims to learn transferable policies under dynamics shifts between source and target domains. A key challenge lies in the lack of target-domain environment interaction and reward supervision, which prevents direct policy learning. To address this challenge, we propose Bridging Dynamics Gaps for Cross-Domain Reinforcement Learning (BDGxRL), a novel framework that leverages Diffusion Schrödinger Bridge (DSB) to align source transitions with target-domain dynamics encoded in offline demonstrations. Moreover, we introduce a reward modulation mechanism that estimates rewards based on state transitions, applying to DSB-aligned samples to ensure consistency between rewards and target-domain dynamics. BDGxRL performs target-oriented policy learning entirely within the source domain, without access to the target environment or its rewards. Experiments on MuJoCo cross-domain benchmarks demonstrate that BDGxRL outperforms state-of-the-art baselines and shows strong adaptability under transition dynamics shifts.

</details>


### [174] [OPTIAGENT: A Physics-Driven Agentic Framework for Automated Optical Design](https://arxiv.org/abs/2602.23761)
*Yuyu Geng,Lei Sun,Yao Gao,Xinxin Hu,Zhonghua Yi,Xiaolong Qian,Weijian Hu,Jian Bai,Kaiwei Wang*

Main category: cs.LG

TL;DR: 本文首次将大语言模型应用于光学设计领域，通过构建OptiDesignQA数据集和混合训练目标，结合物理驱动的奖励机制，使非专业用户也能设计功能性透镜系统。


<details>
  <summary>Details</summary>
Motivation: 光学设计是高度非凸的优化问题，严重依赖专家经验和领域知识。虽然大语言模型拥有丰富的光学知识，但在透镜系统设计方面的能力仍受限制。本文旨在填补这一空白，让没有正式光学训练的用户也能成功开发功能性透镜系统。

Method: 1) 构建OptiDesignQA数据集，包含经典透镜系统和自动设计算法生成的新配置；2) 通过全系统合成和透镜补全的混合目标向LLM注入领域知识；3) 使用DrGRPO算法和光学词典奖励进行物理驱动的策略对齐；4) 集成专业光学优化流程进行端到端微调和精度优化。

Result: 实验结果表明，该方法在传统基于优化的自动设计算法和LLM对比方法中表现出优越性，能够有效设计功能性透镜系统。

Conclusion: 本文成功将大语言模型引入光学设计领域，通过数据、训练目标和物理对齐机制的结合，显著提升了LLM在光学设计任务中的能力，为非专业用户参与光学设计提供了可行途径。

Abstract: Optical design is the process of configuring optical elements to precisely manipulate light for high-fidelity imaging. It is inherently a highly non-convex optimization problem that relies heavily on human heuristic expertise and domain-specific knowledge. While Large Language Models (LLMs) possess extensive optical knowledge, their capabilities in leveraging the knowledge in designing lens system remain significantly constrained. This work represents the first attempt to employ LLMs in the field of optical design. We bridge the expertise gap by enabling users without formal optical training to successfully develop functional lens systems. Concretely, we curate a comprehensive dataset, named OptiDesignQA, which encompasses both classical lens systems sourced from standard optical textbooks and novel configurations generated by automated design algorithms for training and evaluation. Furthermore, we inject domain-specific optical expertise into the LLM through a hybrid objective of full-system synthesis and lens completion. To align the model with optical principles, we employ Group Relative Policy Optimization Done Right (DrGRPO) guided by Optical Lexicographic Reward for physics-driven policy alignment. This reward system incorporates structural format rewards, physical feasibility rewards, light-manipulation accuracy, and LLM-based heuristics. Finally, our model integrates with specialized optical optimization routines for end-to-end fine-tuning and precision refinement. We benchmark our proposed method against both traditional optimization-based automated design algorithms and LLM counterparts, and experimental results show the superiority of our method.

</details>


### [175] [MAGE: Multi-scale Autoregressive Generation for Offline Reinforcement Learning](https://arxiv.org/abs/2602.23770)
*Chenxing Lin,Xinhui Gao,Haipeng Zhang,Xinran Li,Haitao Wang,Songzhu Mei,Chenglu Wen,Weiquan Liu,Siqi Shen,Cheng Wang*

Main category: cs.LG

TL;DR: MAGE是一种基于多尺度自回归生成的离线强化学习方法，通过多尺度轨迹建模解决长时程稀疏奖励任务。


<details>
  <summary>Details</summary>
Motivation: 现有生成式离线RL方法在长时程稀疏奖励任务中表现不佳，传统分层生成方法忽略了轨迹固有的多尺度时间结构，导致次优性能。

Method: 提出MAGE方法：1）条件引导的多尺度自编码器学习分层轨迹表示；2）多尺度Transformer从粗到细自回归生成轨迹表示；3）条件引导解码器精确控制短期行为。

Result: 在5个离线RL基准测试中与15个基线算法对比，MAGE成功整合多尺度轨迹建模与条件引导，在长时程稀疏奖励场景中生成连贯可控的轨迹。

Conclusion: MAGE通过多尺度自回归生成有效捕捉轨迹的多分辨率时间依赖，解决了生成式离线RL在长时程稀疏奖励任务中的局限性。

Abstract: Generative models have gained significant traction in offline reinforcement learning (RL) due to their ability to model complex trajectory distributions. However, existing generation-based approaches still struggle with long-horizon tasks characterized by sparse rewards. Some hierarchical generation methods have been developed to mitigate this issue by decomposing the original problem into shorter-horizon subproblems using one policy and generating detailed actions with another. While effective, these methods often overlook the multi-scale temporal structure inherent in trajectories, resulting in suboptimal performance. To overcome these limitations, we propose MAGE, a Multi-scale Autoregressive GEneration-based offline RL method. MAGE incorporates a condition-guided multi-scale autoencoder to learn hierarchical trajectory representations, along with a multi-scale transformer that autoregressively generates trajectory representations from coarse to fine temporal scales. MAGE effectively captures temporal dependencies of trajectories at multiple resolutions. Additionally, a condition-guided decoder is employed to exert precise control over short-term behaviors. Extensive experiments on five offline RL benchmarks against fifteen baseline algorithms show that MAGE successfully integrates multi-scale trajectory modeling with conditional guidance, generating coherent and controllable trajectories in long-horizon sparse-reward settings.

</details>


### [176] [Provable Subspace Identification of Nonlinear Multi-view CCA](https://arxiv.org/abs/2602.23785)
*Zhiwei Han,Stefan Matthes,Hao Shen*

Main category: cs.LG

TL;DR: 本文研究了多视图非线性典型相关分析(CCA)的可识别性问题，证明了在多视图设置下，即使存在非线性变换，CCA仍能恢复共享潜在子空间，但存在视图特定的正交模糊性。


<details>
  <summary>Details</summary>
Motivation: 传统非线性CCA的精确解混被证明是不适定问题，作者希望重新构建多视图CCA作为一个基不变子空间识别问题，探索在什么条件下可以识别共享的潜在结构。

Method: 将多视图CCA重新定义为基不变子空间识别问题，在合适的潜在先验和谱分离条件下，证明多视图CCA能够恢复成对相关的信号子空间。对于N≥3个视图，该方法能够分离出所有视图共享的联合相关子空间，同时消除视图私有变异。

Result: 理论证明：1) 多视图CCA恢复成对相关信号子空间，但存在视图特定的正交模糊性；2) N≥3时能够分离出所有视图共享的联合相关子空间；3) 建立了有限样本一致性保证，通过谱扰动理论将经验交叉协方差的集中性转化为明确的子空间误差界。

Conclusion: 多视图CCA能够识别共享潜在子空间，但存在视图特定的正交模糊性。实验验证了理论发现并确认了假设条件的必要性。该方法为非线性多视图分析提供了理论基础和实用保证。

Abstract: We investigate the identifiability of nonlinear Canonical Correlation Analysis (CCA) in a multi-view setup, where each view is generated by an unknown nonlinear map applied to a linear mixture of shared latents and view-private noise. Rather than attempting exact unmixing, a problem proven to be ill-posed, we instead reframe multi-view CCA as a basis-invariant subspace identification problem. We prove that, under suitable latent priors and spectral separation conditions, multi-view CCA recovers the pairwise correlated signal subspaces up to view-wise orthogonal ambiguity. For $N \geq 3$ views, the objective provably isolates the jointly correlated subspaces shared across all views while eliminating view-private variations. We further establish finite-sample consistency guarantees by translating the concentration of empirical cross-covariances into explicit subspace error bounds via spectral perturbation theory. Experiments on synthetic and rendered image datasets validate our theoretical findings and confirm the necessity of the assumed conditions.

</details>


### [177] [UPath: Universal Planner Across Topological Heterogeneity For Grid-Based Pathfinding](https://arxiv.org/abs/2602.23789)
*Aleksandr Ananikian,Daniil Drozdov,Konstantin Yakovlev*

Main category: cs.LG

TL;DR: 该论文提出了一种通用的启发式预测器，通过深度学习训练一次即可泛化到各种未见过的网格路径规划任务，将A*算法的计算量减少最多2.2倍，同时保持解决方案在最优成本的3%以内。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的启发式函数方法主要依赖训练和测试网格地图来自相同分布（如城市地图、室内地图等）的假设，在分布外任务上表现不佳。这限制了实际应用中需要能够高效处理任何问题实例的通用求解器的需求。

Method: 设计了一个通用的启发式预测器模型，通过深度学习训练一次，但能够泛化到完全未见过的任务谱系。该方法不依赖于特定地图分布，而是学习通用的路径规划启发式。

Result: 该方法将A*算法的计算工作量减少了最多2.2倍，同时在完全不同于训练任务的问题上，平均解决方案成本仍保持在最优成本的3%以内。这是可学习求解器首次达到这一里程碑。

Conclusion: 该研究填补了现有学习型路径规划方法的泛化能力空白，首次实现了训练一次即可泛化到各种未见任务的通用启发式预测器，为实际应用中的通用求解器提供了可行方案。

Abstract: The performance of search algorithms for grid-based pathfinding, e.g. A*, critically depends on the heuristic function that is used to focus the search. Recent studies have shown that informed heuristics that take the positions/shapes of the obstacles into account can be approximated with the deep neural networks. Unfortunately, the existing learning-based approaches mostly rely on the assumption that training and test grid maps are drawn from the same distribution (e.g., city maps, indoor maps, etc.) and perform poorly on out-of-distribution tasks. This naturally limits their application in practice when often a universal solver is needed that is capable of efficiently handling any problem instance. In this work, we close this gap by designing an universal heuristic predictor: a model trained once, but capable of generalizing across a full spectrum of unseen tasks. Our extensive empirical evaluation shows that the suggested approach halves the computational effort of A* by up to a factor of 2.2, while still providing solutions within 3% of the optimal cost on average altogether on the tasks that are completely different from the ones used for training $\unicode{x2013}$ a milestone reached for the first time by a learnable solver.

</details>


### [178] [GRAIL: Post-hoc Compensation by Linear Reconstruction for Compressed Networks](https://arxiv.org/abs/2602.23795)
*Wenwu Tang,Dong Wang,Lothar Thiele,Olga Saukh*

Main category: cs.LG

TL;DR: GRAIL是一种无需微调的后处理块补偿方法，通过小型校准集恢复压缩后模型的块级输入输出行为，使用Gram矩阵和岭回归线性重建原始隐藏表示。


<details>
  <summary>Details</summary>
Motivation: 结构化深度模型压缩方法虽然硬件友好且能显著降低内存和推理成本，但在激进压缩下会导致精度下降，而后续微调可能因缺少标记数据或训练成本高而不切实际。

Method: 提出GRAIL方法：1) 使用Gram矩阵总结隐藏激活；2) 应用岭回归从压缩后的表示线性重建原始隐藏表示；3) 将重建映射吸收到下游投影权重中，同时压缩上游层。该方法选择器无关、数据感知且无需反向传播。

Result: 在ResNets、ViTs和仅解码器LLMs上，GRAIL在实用压缩范围内持续改进数据无关和数据感知剪枝或折叠基线的准确性或困惑度，具有可控开销且无需反向传播。

Conclusion: GRAIL提供了一种简单有效的零微调后处理补偿方案，能够显著恢复压缩模型的性能，适用于多种模型架构和压缩方法。

Abstract: Structured deep model compression methods are hardware-friendly and substantially reduce memory and inference costs. However, under aggressive compression, the resulting accuracy degradation often necessitates post-compression finetuning, which can be impractical due to missing labeled data or high training cost. We propose post-hoc blockwise compensation, called GRAIL, a simple zero-finetuning step applied after model compression that restores each block's input-output behavior using a small calibration set. The method summarizes hidden activations via a Gram matrix and applies ridge regression to linearly reconstruct the original hidden representation from the reduced one. The resulting reconstruction map is absorbed into the downstream projection weights, while the upstream layer is compressed. The approach is selector-agnostic (Magnitude, Wanda, Gram-based selection, or folding), data-aware (requiring only a few forward passes without gradients or labels), and recovers classic pruning or folding when the Gram matrix is near identity, indicating weak inter-channel correlations. Across ResNets, ViTs, and decoder-only LLMs, GRAIL consistently improves accuracy or perplexity over data-free and data-aware pruning or folding baselines in practical compression regimes, with manageable overhead and no backpropagation. The code is available at https://github.com/TWWinde/GRAIL.

</details>


### [179] [MPU: Towards Secure and Privacy-Preserving Knowledge Unlearning for Large Language Models](https://arxiv.org/abs/2602.23798)
*Tiantong Wang,Xinyu Yan,Tiantong Wu,Yurong Hao,Yong Jiang,Fei Huang,Wei Yang Bryan Lim*

Main category: cs.LG

TL;DR: MPU是一个算法无关的隐私保护多扰动副本遗忘框架，通过服务器端预处理的随机副本生成和后处理的更新聚合，解决大语言模型遗忘中的双重非披露约束问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型遗忘面临隐私困境：严格约束禁止共享服务器参数或客户端遗忘集。需要解决这种双重非披露约束，同时保持有效的遗忘性能。

Method: 提出MPU框架，包含两个服务器端模块：预处理模块生成随机扰动和重参数化的模型副本，客户端在本地私有遗忘集上执行遗忘；后处理模块通过反重参数化和谐波去噪聚合更新，减轻扰动影响。

Result: 在7种遗忘算法上的实验表明，MPU在10%噪声下性能退化大多低于1%，与无噪声基线相当；在1%噪声下某些算法甚至优于无噪声基线。

Conclusion: MPU有效解决了大语言模型遗忘中的双重隐私约束问题，通过扰动副本和聚合机制实现了隐私保护与遗忘性能的良好平衡。

Abstract: Machine unlearning for large language models often faces a privacy dilemma in which strict constraints prohibit sharing either the server's parameters or the client's forget set. To address this dual non-disclosure constraint, we propose MPU, an algorithm-agnostic privacy-preserving Multiple Perturbed Copies Unlearning framework that primarily introduces two server-side modules: Pre-Process for randomized copy generation and Post-Process for update aggregation. In Pre-Process, the server distributes multiple perturbed and reparameterized model instances, allowing the client to execute unlearning locally on its private forget set without accessing the server's exact original parameters. After local unlearning, the server performs Post-Process by inverting the reparameterization and aggregating updates with a harmonic denoising procedure to alleviate the impact of perturbation. Experiments with seven unlearning algorithms show that MPU achieves comparable unlearning performance to noise-free baselines, with most algorithms' average degradation well below 1% under 10% noise, and can even outperform the noise-free baseline for some algorithms under 1% noise. Code is available at https://github.com/Tristan-SHU/MPU.

</details>


### [180] [Beyond State-Wise Mirror Descent: Offline Policy Optimization with Parameteric Policies](https://arxiv.org/abs/2602.23811)
*Xiang Li,Nan Jiang,Yuheng Zhang*

Main category: cs.LG

TL;DR: 本文研究了离线强化学习在一般函数逼近下的理论问题，解决了现有算法只能处理有限小动作空间、无法支持独立策略参数化的问题，将理论保证扩展到大规模或连续动作空间的参数化策略类。


<details>
  <summary>Details</summary>
Motivation: 现有离线RL算法（如PSPI）虽然计算可行，但仅适用于有限小动作空间，且依赖状态级镜像下降，要求从评价函数隐式推导行动者，无法支持实践中普遍使用的独立策略参数化。本文旨在解决这些限制。

Method: 将镜像下降扩展到参数化策略时，识别出上下文耦合是核心难点，通过将镜像下降与自然策略梯度连接起来，提出新的分析框架、理论保证和算法见解，包括离线RL与模仿学习的统一。

Result: 成功将离线RL的理论保证扩展到大规模或连续动作空间的参数化策略类，提出了能够处理独立策略参数化的新算法框架，揭示了离线RL与模仿学习之间的统一关系。

Conclusion: 本文通过连接镜像下降和自然策略梯度，解决了离线RL在参数化策略下的理论挑战，为实际应用中广泛使用的独立策略参数化提供了理论支持，并揭示了离线RL与模仿学习之间的深刻联系。

Abstract: We investigate the theoretical aspects of offline reinforcement learning (RL) under general function approximation. While prior works (e.g., Xie et al., 2021) have established the theoretical foundations of learning a good policy from offline data via pessimism, existing algorithms that are computationally tractable (often in an oracle-efficient sense), such as PSPI, only apply to finite and small action spaces. Moreover, these algorithms rely on state-wise mirror descent and require actors to be implicitly induced from the critic functions, failing to accommodate standalone policy parameterization which is ubiquitous in practice. In this work, we address these limitations and extend the theoretical guarantees to parameterized policy classes over large or continuous action spaces. When extending mirror descent to parameterized policies, we identify contextual coupling as the core difficulty, and show how connecting mirror descent to natural policy gradient leads to novel analyses, guarantees, and algorithmic insights, including a surprising unification between offline RL and imitation learning.

</details>


### [181] [Learning to maintain safety through expert demonstrations in settings with unknown constraints: A Q-learning perspective](https://arxiv.org/abs/2602.23816)
*George Papadopoulos,George A. Vouros*

Main category: cs.LG

TL;DR: 本文提出SafeQIL算法，在约束MDP中通过演示轨迹学习安全策略，平衡保守性与高奖励轨迹的可能性，使用Q值评估状态-动作对的安全性和奖励潜力。


<details>
  <summary>Details</summary>
Motivation: 在约束MDP环境中，给定演示轨迹但约束未知且成本不可观测的情况下，需要学习一个策略，既能最大化演示轨迹的可能性，又能平衡保守性与潜在不安全但高奖励轨迹的权衡。

Method: 提出SafeQIL算法，将状态-动作对的"承诺度"用Q值表示，综合考虑任务特定奖励和状态安全性评估，从安全Q学习的角度解决约束下的逆学习问题。

Result: 在具有挑战性的基准任务上与最先进的逆约束强化学习算法进行比较，展示了SafeQIL算法的优势。

Conclusion: SafeQIL算法能够有效学习安全策略，平衡演示轨迹的似然性与高奖励轨迹的可能性，在约束未知的环境中表现出色。

Abstract: Given a set of trajectories demonstrating the execution of a task safely in a constrained MDP with observable rewards but with unknown constraints and non-observable costs, we aim to find a policy that maximizes the likelihood of demonstrated trajectories trading the balance between being conservative and increasing significantly the likelihood of high-rewarding trajectories but with potentially unsafe steps. Having these objectives, we aim towards learning a policy that maximizes the probability of the most $promising$ trajectories with respect to the demonstrations. In so doing, we formulate the ``promise" of individual state-action pairs in terms of $Q$ values, which depend on task-specific rewards as well as on the assessment of states' safety, mixing expectations in terms of rewards and safety. This entails a safe Q-learning perspective of the inverse learning problem under constraints: The devised Safe $Q$ Inverse Constrained Reinforcement Learning (SafeQIL) algorithm is compared to state-of-the art inverse constraint reinforcement learning algorithms to a set of challenging benchmark tasks, showing its merits.

</details>


### [182] [Inferring Chronic Treatment Onset from ePrescription Data: A Renewal Process Approach](https://arxiv.org/abs/2602.23824)
*Pavlin G. Poličar,Dalibor Stanimirović,Blaž Zupan*

Main category: cs.LG

TL;DR: 提出一个概率框架，通过将处方动态建模为更新过程，检测从偶发性治疗到持续性治疗的转变，来推断慢性治疗的开始时间


<details>
  <summary>Details</summary>
Motivation: 纵向电子健康记录数据通常存在左截断问题，导致诊断记录不完整且不可靠，无法准确确定疾病发病时间。相比之下，门诊处方形成的更新轨迹提供了疾病管理的连续信号。

Method: 提出一个概率框架，将处方动态建模为更新过程，通过变化点检测来识别从偶发性治疗（基线泊松模型）到持续性治疗（特定机制的威布尔更新模型）的转变。

Result: 使用全国240万人的电子处方数据集，该方法比基于规则的触发方法产生更合理的时间发病估计，显著减少了在强左截断情况下的不合理早期检测。检测性能因疾病而异，与处方密度密切相关。

Conclusion: 该方法为基于治疗的发病时间推断提供了更可靠的框架，同时揭示了其在不同疾病和处方密度情况下的优势和局限性。

Abstract: Longitudinal electronic health record (EHR) data are often left-censored, making diagnosis records incomplete and unreliable for determining disease onset. In contrast, outpatient prescriptions form renewal-based trajectories that provide a continuous signal of disease management. We propose a probabilistic framework to infer chronic treatment onset by modeling prescription dynamics as a renewal process and detecting transitions from sporadic to sustained therapy via change-point detection between a baseline Poisson (sporadic prescribing) regime and a regime-specific Weibull (sustained therapy) renewal model. Using a nationwide ePrescription dataset of 2.4 million individuals, we show that the approach yields more temporally plausible onset estimates than naive rule-based triggering, substantially reducing implausible early detections under strong left censoring. Detection performance varies across diseases and is strongly associated with prescription density, highlighting both the strengths and limits of treatment-based onset inference.

</details>


### [183] [RewardUQ: A Unified Framework for Uncertainty-Aware Reward Models](https://arxiv.org/abs/2602.24040)
*Daniel Yang,Samuel Stante,Florian Redhardt,Lena Libon,Parnian Kassraie,Ido Hakimi,Barna Pásztor,Andreas Krause*

Main category: cs.LG

TL;DR: RewardUQ：一个系统评估奖励模型不确定性量化的统一框架，发现模型规模和初始化对性能影响最大，多数先前工作可通过替代设计选择改进。


<details>
  <summary>Details</summary>
Motivation: 奖励模型对于将大语言模型与人类偏好对齐至关重要，但现有方法主要依赖点估计，忽略了有限人类反馈带来的认知不确定性。虽然已有研究表明量化这种不确定性可以降低人工标注成本并缓解奖励过优化问题，但不确定性感知的奖励模型缺乏系统比较和深入理解。

Method: 提出了RewardUQ统一框架，系统评估奖励模型的不确定性量化方法。比较了常见方法在准确性和校准性方面的标准指标，并提出了一种结合这两个维度的新排名策略以简化比较。

Result: 实验结果表明，模型规模和初始化对性能影响最为显著，大多数先前工作本可以通过替代设计选择获得改进。作者发布了开源框架作为Python包，以促进新方法的开发和评估。

Conclusion: RewardUQ为系统评估奖励模型不确定性量化提供了统一框架，揭示了模型规模和初始化的关键作用，并通过开源工具支持该领域的进一步发展。

Abstract: Reward models are central to aligning large language models (LLMs) with human preferences. Yet most approaches rely on pointwise reward estimates that overlook the epistemic uncertainty in reward models arising from limited human feedback. Recent work suggests that quantifying this uncertainty can reduce the costs of human annotation via uncertainty-guided active learning and mitigate reward overoptimization in LLM post-training. However, uncertainty-aware reward models have so far been adopted without thorough comparison, leaving them poorly understood. This work introduces a unified framework, RewardUQ, to systematically evaluate uncertainty quantification for reward models. We compare common methods along standard metrics measuring accuracy and calibration, and we propose a new ranking strategy incorporating both dimensions for a simplified comparison. Our experimental results suggest that model size and initialization have the most meaningful impact on performance, and most prior work could have benefited from alternative design choices. To foster the development and evaluation of new methods and aid the deployment in downstream applications, we release our open-source framework as a Python package. Our code is available at https://github.com/lasgroup/rewarduq.

</details>


### [184] [FedNSAM:Consistency of Local and Global Flatness for Federated Learning](https://arxiv.org/abs/2602.23827)
*Junkang Liu,Fanhua Shang,Yuxuan Tian,Hongying Liu,Yuanyuan Liu*

Main category: cs.LG

TL;DR: FedNSAM：一种新的联邦学习算法，通过引入全局Nesterov动量来协调全局和局部平坦度的一致性，解决数据异构环境下SAM算法在FL中的局限性


<details>
  <summary>Details</summary>
Motivation: 联邦学习中多步本地更新和数据异构性通常导致更尖锐的全局最小值，这会降低全局模型的性能。现有的FL算法将SAM集成到本地训练中，但在高数据异构性设置下，本地训练的平坦度并不代表全局模型的平坦度，因此需要新的方法来协调全局和局部平坦度的一致性。

Method: 提出FedNSAM算法，通过引入全局Nesterov动量到本地更新中，将全局Nesterov动量作为客户端全局扰动的本地估计方向和外推方向，从而加速SAM算法并协调全局和局部平坦度的一致性。

Result: 理论上证明了FedNSAM比FedSAM具有更紧的收敛界；实证上在CNN和Transformer模型上进行了全面实验，验证了FedNSAM的优越性能和效率。

Conclusion: FedNSAM通过引入全局Nesterov动量有效解决了数据异构环境下SAM在FL中的局限性，在理论和实验上都表现出优越性，为联邦学习中的泛化能力提升提供了新方法。

Abstract: In federated learning (FL), multi-step local updates and data heterogeneity usually lead to sharper global minima, which degrades the performance of the global model. Popular FL algorithms integrate sharpness-aware minimization (SAM) into local training to address this issue. However, in the high data heterogeneity setting, the flatness in local training does not imply the flatness of the global model. Therefore, minimizing the sharpness of the local loss surfaces on the client data does not enable the effectiveness of SAM in FL to improve the generalization ability of the global model. We define the \textbf{flatness distance} to explain this phenomenon. By rethinking the SAM in FL and theoretically analyzing the \textbf{flatness distance}, we propose a novel \textbf{FedNSAM} algorithm that accelerates the SAM algorithm by introducing global Nesterov momentum into the local update to harmonize the consistency of global and local flatness. \textbf{FedNSAM} uses the global Nesterov momentum as the direction of local estimation of client global perturbations and extrapolation. Theoretically, we prove a tighter convergence bound than FedSAM by Nesterov extrapolation. Empirically, we conduct comprehensive experiments on CNN and Transformer models to verify the superior performance and efficiency of \textbf{FedNSAM}. The code is available at https://github.com/junkangLiu0/FedNSAM.

</details>


### [185] [ULW-SleepNet: An Ultra-Lightweight Network for Multimodal Sleep Stage Scoring](https://arxiv.org/abs/2602.23852)
*Zhaowen Wang,Dongdong Zhou,Qi Xu,Fengyu Cong,Mohammad Al-Sa'd,Jenni Raitoharju*

Main category: cs.LG

TL;DR: 提出ULW-SleepNet，一种超轻量级多模态睡眠分期框架，通过新颖的双流可分离卷积块等技术，在保持竞争力的准确率下大幅减少计算开销，适用于可穿戴和物联网设备的实时睡眠监测。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型计算需求大且多为单通道EEG设计，限制了在多模态PSG数据中的实用性，需要开发更轻量、高效的多模态睡眠分期方法。

Method: 提出ULW-SleepNet框架，包含新颖的双流可分离卷积块、深度可分离卷积、通道参数共享和全局平均池化等技术，以降低计算开销。

Result: 在Sleep-EDF-20和Sleep-EDF-78数据集上分别达到86.9%和81.4%的准确率，仅需13.3K参数和7.89M FLOPs，相比现有方法参数减少高达98.6%。

Conclusion: ULW-SleepNet在保持竞争力的准确率下大幅减少了计算需求，展示了在可穿戴和物联网设备上进行实时睡眠监测的强大潜力。

Abstract: Automatic sleep stage scoring is crucial for the diagnosis and treatment of sleep disorders. Although deep learning models have advanced the field, many existing models are computationally demanding and designed for single-channel electroencephalography (EEG), limiting their practicality for multimodal polysomnography (PSG) data. To overcome this, we propose ULW-SleepNet, an ultra-lightweight multimodal sleep stage scoring framework that efficiently integrates information from multiple physiological signals. ULW-SleepNet incorporates a novel Dual-Stream Separable Convolution (DSSC) Block, depthwise separable convolutions, channel-wise parameter sharing, and global average pooling to reduce computational overhead while maintaining competitive accuracy. Evaluated on the Sleep-EDF-20 and Sleep-EDF-78 datasets, ULW-SleepNet achieves accuracies of 86.9% and 81.4%, respectively, with only 13.3K parameters and 7.89M FLOPs. Compared to state-of-the-art methods, our model reduces parameters by up to 98.6% with only marginal performance loss, demonstrating its strong potential for real-time sleep monitoring on wearable and IoT devices. The source code for this study is publicly available at https://github.com/wzw999/ULW-SLEEPNET.

</details>


### [186] [A Theory of Random Graph Shift in Truncated-Spectrum vRKHS](https://arxiv.org/abs/2602.23880)
*Zhang Wan,Tingting Mu,Samuel Kaski*

Main category: cs.LG

TL;DR: 该论文提出了一个基于随机图生成模型的图分类域适应理论，通过向量值再生核希尔伯特空间推导出包含域差异、谱几何和振幅三项因子的泛化误差界。


<details>
  <summary>Details</summary>
Motivation: 现有域适应理论虽然支持处理图分布偏移，但图作为结构化对象的信息特性未被充分探索。图的非欧几里得性质和专用图学习架构使得对图分布偏移的细粒度分析变得复杂。

Method: 假设随机图模型作为数据生成过程，利用其在函数空间视角下与假设复杂度的联系进行细粒度分析。基于向量值再生核希尔伯特空间公式，推导出包含三项因子的泛化误差界。

Result: 泛化误差界的偏移惩罚可分解为：(1)域差异项，(2)由可访问截断谱总结的谱几何项，(3)聚合收敛和构造稳定性效应的振幅项。在真实数据和模拟中验证了这些项的见解。

Conclusion: 该理论为图分类中的域偏移提供了细粒度分析框架，通过随机图生成视角和vRKHS公式，揭示了影响泛化性能的关键因素，为图域适应方法设计提供了理论指导。

Abstract: This paper develops a theory of graph classification under domain shift through a random-graph generative lens, where we consider intra-class graphs sharing the same random graph model (RGM) and the domain shift induced by changes in RGM components. While classic domain adaptation (DA) theories have well-underpinned existing techniques to handle graph distribution shift, the information of graph samples, which are itself structured objects, is less explored. The non-Euclidean nature of graphs and specialized architectures for graph learning further complicate a fine-grained analysis of graph distribution shifts. In this paper, we propose a theory that assumes RGM as the data generative process, exploiting its connection to hypothesis complexity in function space perspective for such fine-grained analysis. Building on a vector-valued reproducing kernel Hilbert space (vRKHS) formulation, we derive a generalization bound whose shift penalty admits a factorization into (i) a domain discrepancy term, (ii) a spectral-geometry term summarized by the accessible truncated spectrum, and (iii) an amplitude term that aggregates convergence and construction-stability effects. We empirically verify the insights on these terms in both real data and simulations.

</details>


### [187] [MINT: Multimodal Imaging-to-Speech Knowledge Transfer for Early Alzheimer's Screening](https://arxiv.org/abs/2602.23994)
*Vrushank Ahire,Yogesh Kumar,Anouck Girard,M. A. Ganaie*

Main category: cs.LG

TL;DR: MINT框架将MRI的生物标志物结构转移到语音编码器中，实现无需神经影像的阿尔茨海默病早期筛查，性能与纯语音基线相当。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病的早期筛查需要生物标志物，但神经影像（如MRI）成本高、部署困难。语音分析虽无创，但纯语音分类器缺乏生物学基础，在CN与MCI的细微区分上可靠性有限。

Method: 提出MINT（多模态影像到语音知识转移）三阶段跨模态框架：1）在1,228名受试者上训练MRI教师模型，定义紧凑的神经影像嵌入空间用于CN与MCI分类；2）通过残差投影头将语音表示对齐到冻结的影像流形，使用几何损失函数；3）推理时应用冻结的MRI分类器到对齐的嵌入，无需扫描仪。

Result: 在ADNI-4数据集上，对齐的语音达到与纯语音基线相当的性能（AUC 0.720 vs 0.711），且推理时无需影像。多模态融合优于单独MRI（0.973 vs 0.958）。消融研究显示dropout正则化和自监督预训练是关键设计决策。

Conclusion: 这是首次展示MRI到语音知识转移用于阿尔茨海默病早期筛查，建立了无需推理时神经影像的生物学基础通路，为人群级认知分流提供了可行方案。

Abstract: Alzheimer's disease is a progressive neurodegenerative disorder in which mild cognitive impairment (MCI) marks a critical transition between aging and dementia. Neuroimaging modalities, such as structural MRI, provide biomarkers of this transition; however, their high costs and infrastructure needs limit their deployment at a population scale. Speech analysis offers a non-invasive alternative, but speech-only classifiers are developed independently of neuroimaging, leaving decision boundaries biologically ungrounded and limiting reliability on the subtle CN-versus-MCI distinction. We propose MINT (Multimodal Imaging-to-Speech Knowledge Transfer), a three-stage cross-modal framework that transfers biomarker structure from MRI into a speech encoder at training time. An MRI teacher, trained on 1,228 subjects, defines a compact neuroimaging embedding space for CN-versus-MCI classification. A residual projection head aligns speech representations to this frozen imaging manifold via a combined geometric loss, adapting speech to the learned biomarker space while preserving imaging encoder fidelity. The frozen MRI classifier, which is never exposed to speech, is applied to aligned embeddings at inference and requires no scanner. Evaluation on ADNI-4 shows aligned speech achieves performance comparable to speech-only baselines (AUC 0.720 vs 0.711) while requiring no imaging at inference, demonstrating that MRI-derived decision boundaries can ground speech representations. Multimodal fusion improves over MRI alone (0.973 vs 0.958). Ablation studies identify dropout regularization and self-supervised pretraining as critical design decisions. To our knowledge, this is the first demonstration of MRI-to-speech knowledge transfer for early Alzheimer's screening, establishing a biologically grounded pathway for population-level cognitive triage without neuroimaging at inference.

</details>


### [188] [Foundation World Models for Agents that Learn, Verify, and Adapt Reliably Beyond Static Environments](https://arxiv.org/abs/2602.23997)
*Florent Delgrange*

Main category: cs.LG

TL;DR: 本文提出基础世界模型概念，旨在构建持久、组合式的表示，统一强化学习、反应式/程序综合和抽象机制，以支持在开放世界中可靠学习和适应的自主智能体。


<details>
  <summary>Details</summary>
Motivation: 当前自主智能体方法通常假设固定任务和环境，缺乏应对新颖性的能力，限制了世界模型支持智能体在条件变化时演化策略的能力。需要构建能够支持学习、推理和适应的基础世界模型。

Method: 提出围绕四个组件的议程：(1)从规范中学习奖励模型以支持明确目标的优化；(2)在学习过程中集成自适应形式验证；(3)在线抽象校准以量化模型预测的可靠性；(4)由验证器指导的测试时综合和世界模型生成。

Result: 该框架使智能体能够综合可验证程序，从少量交互中推导新策略，并在适应新颖性时保持正确性。基础世界模型成为学习、推理和适应的基础。

Conclusion: 基础世界模型为自主智能体提供了不仅能良好行动，还能解释和证明其行为的底层支撑，为实现可靠、适应性强且可解释的下一代自主系统奠定基础。

Abstract: The next generation of autonomous agents must not only learn efficiently but also act reliably and adapt their behavior in open worlds. Standard approaches typically assume fixed tasks and environments with little or no novelty, which limits world models' ability to support agents that must evolve their policies as conditions change. This paper outlines a vision for foundation world models: persistent, compositional representations that unify reinforcement learning, reactive/program synthesis, and abstraction mechanisms. We propose an agenda built around four components: (i) learnable reward models from specifications to support optimization with clear objectives; (ii) adaptive formal verification integrated throughout learning; (iii) online abstraction calibration to quantify the reliability of the model's predictions; and (iv) test-time synthesis and world-model generation guided by verifiers. Together, these components enable agents to synthesize verifiable programs, derive new policies from a small number of interactions, and maintain correctness while adapting to novelty. The resulting framework positions foundation world models as a substrate for learning, reasoning, and adaptation, laying the groundwork for agents that not only act well but can explain and justify the behavior they adopt.

</details>


### [189] [InfoNCE Induces Gaussian Distribution](https://arxiv.org/abs/2602.24012)
*Roy Betser,Eyal Gofer,Meir Yossef Levi,Guy Gilboa*

Main category: cs.LG

TL;DR: 论文证明对比学习中的InfoNCE损失会诱导出高斯结构的表示，通过理论分析和实验验证了这一发现。


<details>
  <summary>Details</summary>
Motivation: 对比学习已成为现代表示学习的基石，但对其诱导的表示结构缺乏理论理解。本文旨在探究InfoNCE目标函数是否会导致表示呈现高斯分布特性。

Method: 采用两种互补的理论分析框架：1) 在特定对齐和集中假设下，证明高维表示的投影渐近趋近多元高斯分布；2) 在较弱假设下，通过添加渐近消失的正则化项（促进低特征范数和高特征熵）获得类似结果。同时在合成数据和CIFAR-10数据集上进行实验验证。

Result: 理论分析和实验结果表明，对比学习确实会诱导出高斯结构的表示。这一发现为实践中观察到的表示高斯性提供了理论解释，并支持了多个编码器架构和规模的一致性。

Conclusion: InfoNCE目标函数会诱导表示呈现高斯结构，这一高斯模型为分析学习到的表示提供了理论框架，有望支持对比学习的广泛应用。

Abstract: Contrastive learning has become a cornerstone of modern representation learning, allowing training with massive unlabeled data for both task-specific and general (foundation) models. A prototypical loss in contrastive training is InfoNCE and its variants. In this work, we show that the InfoNCE objective induces Gaussian structure in representations that emerge from contrastive training. We establish this result in two complementary regimes. First, we show that under certain alignment and concentration assumptions, projections of the high-dimensional representation asymptotically approach a multivariate Gaussian distribution. Next, under less strict assumptions, we show that adding a small asymptotically vanishing regularization term that promotes low feature norm and high feature entropy leads to similar asymptotic results. We support our analysis with experiments on synthetic and CIFAR-10 datasets across multiple encoder architectures and sizes, demonstrating consistent Gaussian behavior. This perspective provides a principled explanation for commonly observed Gaussianity in contrastive representations. The resulting Gaussian model enables principled analytical treatment of learned representations and is expected to support a wide range of applications in contrastive learning.

</details>


### [190] [pathsig: A GPU-Accelerated Library for Truncated and Projected Path Signatures](https://arxiv.org/abs/2602.24066)
*Tobias Nygaard*

Main category: cs.LG

TL;DR: pathsig是一个PyTorch原生库，通过CUDA内核并行计算路径签名，相比现有库在截断签名计算上实现10-30倍加速，在需要反向传播的训练中实现4-10倍加速。


<details>
  <summary>Details</summary>
Motivation: 现有路径签名库缺乏大规模梯度学习所需的可扩展性，需要一种能够高效处理GPU计算和反向传播的解决方案。

Method: 开发PyTorch原生库pathsig，在词基上直接计算路径签名，使用CUDA内核在前缀封闭词集上并行更新签名系数，支持用户指定词集的投影和基于非均匀路径正则性的各向异性截断。

Result: pathsig实现了高GPU吞吐量和接近最小的峰值内存使用，在截断签名计算上比现有库快10-30倍，在需要反向传播的训练中快4-10倍。

Conclusion: pathsig填补了现有签名库在大规模梯度学习方面的可扩展性空白，通过高效GPU实现和灵活的特征选择机制，为序列数据的机器学习应用提供了强大的工具。

Abstract: Path signatures provide a rich representation of sequential data, with strong theoretical guarantees and good performance in a variety of machine-learning tasks. While signatures have progressed from fixed feature extractors to trainable components of machine-learning models, existing libraries often lack the required scalability for large-scale, gradient-based learning. To address this gap, this paper introduces pathsig, a PyTorch-native library that computes path signatures directly in the word basis. By using CUDA kernels to update signature coefficients in parallel over prefix-closed word sets, pathsig achieves high GPU throughput and near-minimal peak memory. Compared with other libraries, pathsig achieves 10-30x speedups for computation of truncated signatures and up to 4-10x speedups in training that require backpropagation through the signature. Beyond regular truncation, pathsig supports projections of the (infinite-dimensional) signature onto user-specified sets of words and anisotropic truncation motivated by inhomogeneous path regularity, enabling more compact representations that can reduce dimensionality, redundancy, and computational cost.

</details>


### [191] [Leveraging Non-linear Dimension Reduction and Random Walk Co-occurrence for Node Embedding](https://arxiv.org/abs/2602.24069)
*Ryan DeWolfe*

Main category: cs.LG

TL;DR: COVE是一种可解释的高维嵌入方法，通过非线性降维技术突破节点嵌入的低维限制，结合UMAP降维后在聚类和链接预测任务上性能略有提升。


<details>
  <summary>Details</summary>
Motivation: 传统节点嵌入方法通常受限于低维空间，作者希望突破这一限制，开发可解释的高维嵌入方法，同时保持或提升在社区检测和链接预测等任务上的性能。

Method: 提出COVE高维嵌入方法，受神经嵌入方法启发，利用随机游走中的共现作为相似性指标，与扩散过程密切相关。采用COVE-UMAP-HDBSCAN流程，先进行高维嵌入，再用UMAP降维，最后用HDBSCAN聚类。

Result: COVE结合UMAP降维后，在聚类和链接预测任务上性能略有提升。在社区检测基准测试中，COVE-UMAP-HDBSCAN流程与流行的Louvain算法表现相当。

Conclusion: COVE提供了一种可解释的高维节点嵌入方法，突破了传统低维嵌入的限制，在保持性能的同时提供了更好的可解释性，为图分析任务提供了新的技术路径。

Abstract: Leveraging non-linear dimension reduction techniques, we remove the low dimension constraint from node embedding and propose COVE, an explainable high dimensional embedding that, when reduced to low dimension with UMAP, slightly increases performance on clustering and link prediction tasks. The embedding is inspired by neural embedding methods that use co-occurrence on a random walk as an indication of similarity, and is closely related to a diffusion process. Extending on recent community detection benchmarks, we find that a COVE UMAP HDBSCAN pipeline performs similarly to the popular Louvain algorithm.

</details>


### [192] [Neural Diffusion Intensity Models for Point Process Data](https://arxiv.org/abs/2602.24083)
*Xinlong Du,Harsha Honnappa,Vinayak Rao*

Main category: cs.LG

TL;DR: 提出Neural Diffusion Intensity Models，一种基于神经SDE的变分框架，用于Cox过程，通过扩大滤波理论保证变分族包含真实后验，实现高效的后验推断。


<details>
  <summary>Details</summary>
Motivation: Cox过程通过潜在随机强度建模过分散点过程数据，但强度模型的非参数估计和强度路径的后验推断通常难以处理，依赖于昂贵的MCMC方法。

Method: 引入Neural Diffusion Intensity Models，基于神经SDE的变分框架。关键理论基于扩大滤波，证明在点过程观测条件下，潜在强度保持扩散结构并具有显式漂移修正。设计摊销编码器架构，将变长事件序列映射到后验强度路径。

Result: 在合成和真实世界数据上准确恢复潜在强度动态和后验路径，相比基于MCMC的方法获得数量级的加速。

Conclusion: 提出的变分框架为Cox过程提供了高效的后验推断方法，通过理论保证变分族包含真实后验，实现单次前向传播替代重复MCMC运行。

Abstract: Cox processes model overdispersed point process data via a latent stochastic intensity, but both nonparametric estimation of the intensity model and posterior inference over intensity paths are typically intractable, relying on expensive MCMC methods. We introduce Neural Diffusion Intensity Models, a variational framework for Cox processes driven by neural SDEs. Our key theoretical result, based on enlargement of filtrations, shows that conditioning on point process observations preserves the diffusion structure of the latent intensity with an explicit drift correction. This guarantees the variational family contains the true posterior, so that ELBO maximization coincides with maximum likelihood estimation under sufficient model capacity. We design an amortized encoder architecture that maps variable-length event sequences to posterior intensity paths by simulating the drift-corrected SDE, replacing repeated MCMC runs with a single forward pass. Experiments on synthetic and real-world data demonstrate accurate recovery of latent intensity dynamics and posterior paths, with orders-of-magnitude speedups over MCMC-based methods.

</details>


### [193] [Learning with a Budget: Identifying the Best Arm with Resource Constraints](https://arxiv.org/abs/2602.24146)
*Zitian Li,Wang Chi Cheung*

Main category: cs.LG

TL;DR: 提出了资源约束下的最佳臂识别问题(BAIwRC)，开发了SH-RR算法，统一了随机和确定性资源消耗的理论分析框架


<details>
  <summary>Details</summary>
Motivation: 在许多应用中，评估不同替代方案的效果伴随着不同的成本或资源使用。受这种异质性的启发，研究资源约束下的最佳臂识别问题，其中每个臂拉动消耗一种或多种有限资源类型

Method: 提出了Successive Halving with Resource Rationing (SH-RR)算法，将资源感知分配集成到经典的成功减半框架中，使用新的有效消耗度量统一随机和确定性消耗设置的理论分析

Result: SH-RR算法在资源约束下有效识别最佳臂，通过新的有效消耗度量统一了随机和确定性资源消耗的理论分析框架

Conclusion: 该研究为资源约束下的最佳臂识别问题提供了统一的算法框架和理论分析，适用于具有异质性资源消耗的实际应用场景

Abstract: In many applications, evaluating the effectiveness of different alternatives comes with varying costs or resource usage. Motivated by such heterogeneity, we study the Best Arm Identification with Resource Constraints (BAIwRC) problem, where an agent seeks to identify the best alternative (aka arm) in the presence of resource constraints. Each arm pull consumes one or more types of limited resources. We make two key contributions. First, we propose the Successive Halving with Resource Rationing (SH-RR) algorithm, which integrates resource-aware allocation into the classical successive halving framework on best arm identification. The SH-RR algorithm unifies the theoretical analysis for both the stochastic and deterministic consumption settings, with a new \textit{effective consumption measure

</details>


### [194] [Sandwiching Polynomials for Geometric Concepts with Low Intrinsic Dimension](https://arxiv.org/abs/2602.24178)
*Adam R. Klivans,Konstantinos Stavropoulos,Arsen Vasilyan*

Main category: cs.LG

TL;DR: 本文提出了一种构造低阶三明治多项式的新方法，显著改进了多个基本函数类在边际分布下的阶数界限，特别是将k个半空间的函数从指数级改进到多项式级。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明低阶三明治多项式近似器在分布偏移学习、可测试学习和污染学习等挑战性学习设置中具有强大能力。三明治多项式通过提供目标函数的点值上下界来近似期望值，但现有方法的阶数界限不够理想，需要改进。

Method: 提出了一种相对简单的新方法，直接利用目标函数边界的光滑性来构造三明治Lipschitz函数，这些函数适用于高维逼近理论的结果。该方法特别适用于低维且具有光滑边界的函数类。

Result: 对于高斯分布下的k个半空间函数，获得了poly(k)阶的三明治多项式，相比之前的2^O(k)指数级界限有指数级改进。对于高斯分布下的低维多项式阈值函数，获得了双重指数级改进，且无需使用先前最佳结果中的FT-mollification方法。

Conclusion: 新方法通过直接利用函数边界的光滑性，为构造低阶三明治多项式提供了更简单有效的途径，显著改进了多个重要函数类的逼近效率，为挑战性学习设置中的多项式逼近提供了更好的理论基础。

Abstract: Recent work has shown the surprising power of low-degree sandwiching polynomial approximators in the context of challenging learning settings such as learning with distribution shift, testable learning, and learning with contamination. A pair of sandwiching polynomials approximate a target function in expectation while also providing pointwise upper and lower bounds on the function's values. In this paper, we give a new method for constructing low-degree sandwiching polynomials that yield greatly improved degree bounds for several fundamental function classes and marginal distributions. In particular, we obtain degree $\mathrm{poly}(k)$ sandwiching polynomials for functions of $k$ halfspaces under the Gaussian distribution, improving exponentially over the prior $2^{O(k)}$ bound. More broadly, our approach applies to function classes that are low-dimensional and have smooth boundary.
  In contrast to prior work, our proof is relatively simple and directly uses the smoothness of the target function's boundary to construct sandwiching Lipschitz functions, which are amenable to results from high-dimensional approximation theory. For low-dimensional polynomial threshold functions (PTFs) with respect to Gaussians, we obtain doubly exponential improvements without applying the FT-mollification method of Kane used in the best previous result.

</details>


### [195] [Multi-Objective Reinforcement Learning for Large-Scale Tote Allocation in Human-Robot Collaborative Fulfillment Centers](https://arxiv.org/abs/2602.24182)
*Sikata Sengupta,Guangyi Liu,Omer Gottesman,Joseph W Durham,Michael Kearns,Aaron Roth,Michael Caldara*

Main category: cs.LG

TL;DR: 该研究提出了一种多目标强化学习方法，用于优化集装箱式履约中心的整合过程，在满足实际运营约束的同时平衡处理速度、资源使用和空间利用率等竞争目标。


<details>
  <summary>Details</summary>
Motivation: 集装箱式履约中心的整合过程需要在处理速度、资源使用和空间利用率等多个竞争目标之间进行权衡，同时满足各种实际运营约束。这是一个复杂的决策问题，涉及人机协作工作站之间的物品移动，旨在释放入库库存空间并提高集装箱利用率。

Method: 将问题建模为大规模多目标强化学习任务，采用基于零和博弈中最佳响应和无悔动态的约束强化学习方法，实现原则性的极小极大策略学习。同时引入了处理误差消除问题的理论框架，避免时间平均解出现振荡行为。

Result: 在现实的仓库模拟中进行策略评估，表明该方法能有效权衡多个目标。经验观察到学习到的单一策略能够同时满足所有约束条件，尽管这在理论上无法保证。该方法返回的迭代结果其拉格朗日值接近博弈的极小极大值。

Conclusion: 这些结果证明了多目标强化学习在解决大规模工业系统中复杂、高影响力决策问题方面的潜力，为集装箱履约中心的整合优化提供了有效的解决方案。

Abstract: Optimizing the consolidation process in container-based fulfillment centers requires trading off competing objectives such as processing speed, resource usage, and space utilization while adhering to a range of real-world operational constraints. This process involves moving items between containers via a combination of human and robotic workstations to free up space for inbound inventory and increase container utilization. We formulate this problem as a large-scale Multi-Objective Reinforcement Learning (MORL) task with high-dimensional state spaces and dynamic system behavior. Our method builds on recent theoretical advances in solving constrained RL problems via best-response and no-regret dynamics in zero-sum games, enabling principled minimax policy learning. Policy evaluation on realistic warehouse simulations shows that our approach effectively trades off objectives, and we empirically observe that it learns a single policy that simultaneously satisfies all constraints, even if this is not theoretically guaranteed. We further introduce a theoretical framework to handle the problem of error cancellation, where time-averaged solutions display oscillatory behavior. This method returns a single iterate whose Lagrangian value is close to the minimax value of the game. These results demonstrate the promise of MORL in solving complex, high-impact decision-making problems in large-scale industrial systems.

</details>


### [196] [Flow-Based Density Ratio Estimation for Intractable Distributions with Applications in Genomics](https://arxiv.org/abs/2602.24201)
*Egor Antipov,Alessandro Palma,Lorenzo Consoli,Stephan Günnemann,Andrea Dittadi,Fabian J. Theis*

Main category: cs.LG

TL;DR: 提出一种基于条件感知流匹配的密度比估计方法，避免分别计算两个分布的似然积分，在单细胞基因组学数据分析中支持治疗效应估计和批次校正评估。


<details>
  <summary>Details</summary>
Motivation: 密度比估计是概率建模的核心问题，但现有方法如归一化流需要分别计算两个分布的似然积分，计算成本高昂。需要一种更高效的方法来比较不同数据生成过程下的样本似然。

Method: 利用条件感知流匹配技术，推导出单一动力学公式来跟踪生成轨迹上的密度比，避免分别计算两个分布的似然积分。

Result: 在模拟基准测试中实现了具有竞争力的闭式比率估计性能，在单细胞基因组学数据分析中支持治疗效应估计和批次校正评估等多样化任务。

Conclusion: 提出的条件感知流匹配方法为密度比估计提供了一种高效的计算框架，特别适用于需要比较不同实验条件下细胞状态的生物信息学应用。

Abstract: Estimating density ratios between pairs of intractable data distributions is a core problem in probabilistic modeling, enabling principled comparisons of sample likelihoods under different data-generating processes across conditions and covariates. While exact-likelihood models such as normalizing flows offer a promising approach to density ratio estimation, naive flow-based evaluations are computationally expensive, as they require simulating costly likelihood integrals for each distribution separately. In this work, we leverage condition-aware flow matching to derive a single dynamical formulation for tracking density ratios along generative trajectories. We demonstrate competitive performance on simulated benchmarks for closed-form ratio estimation, and show that our method supports versatile tasks in single-cell genomics data analysis, where likelihood-based comparisons of cellular states across experimental conditions enable treatment effect estimation and batch correction evaluation.

</details>


### [197] [The Stability of Online Algorithms in Performative Prediction](https://arxiv.org/abs/2602.24207)
*Gabriele Farina,Juan Carlos Perdomo*

Main category: cs.LG

TL;DR: 论文展示了在预测性决策中，任何无遗憾算法都能收敛到混合的预测性稳定均衡，无需对模型影响数据分布的方式做限制性假设。


<details>
  <summary>Details</summary>
Motivation: 算法预测在决策中的使用会导致反馈循环，模型部署会影响数据分布，进而影响后续的重新训练。Perdomo等人2020年将这一动态形式化为预测性预测。现有研究对模型如何影响分布有严格限制，需要更通用的收敛结果。

Method: 使用鞅论论证和允许随机化，避免了对模型影响数据分布方式的任何限制性假设。通过无条件约简，将预测性设置中的收敛问题与在线优化联系起来。

Result: 主要结果是任何无遗憾算法在预测性设置中都能收敛到混合的预测性稳定均衡，即模型主动塑造数据分布，使其预测在后验中看起来最优。这绕过了最近关于寻找稳定模型的硬度结果。

Conclusion: 该工作建立了在线优化与预测性之间的技术联系，解释了为什么常见算法（如梯度下降）具有自然稳定性并能防止失控的反馈循环。希望这一连接能促进两个领域之间的思想技术转移。

Abstract: The use of algorithmic predictions in decision-making leads to a feedback loop where the models we deploy actively influence the data distributions we see, and later use to retrain on. This dynamic was formalized by Perdomo et al. 2020 in their work on performative prediction. Our main result is an unconditional reduction showing that any no-regret algorithm deployed in performative settings converges to a (mixed) performatively stable equilibrium: a solution in which models actively shape data distributions in ways that their own predictions look optimal in hindsight. Prior to our work, all positive results in this area made strong restrictions on how models influenced distributions. By using a martingale argument and allowing randomization, we avoid any such assumption and sidestep recent hardness results for finding stable models. Lastly, on a more conceptual note, our connection sheds light on why common algorithms, like gradient descent, are naturally stabilizing and prevent runaway feedback loops. We hope our work enables future technical transfer of ideas between online optimization and performativity.

</details>


### [198] [An Efficient Unsupervised Federated Learning Approach for Anomaly Detection in Heterogeneous IoT Networks](https://arxiv.org/abs/2602.24209)
*Mohsen Tajgardan,Atena Shiranzaei,Mahdi Rabbani,Reza Khoshkangini,Mahtab Jamali*

Main category: cs.LG

TL;DR: 提出一个高效的联邦学习框架，利用两个不同物联网数据集的共享特征来增强异常检测，同时保持数据集特定特征，并使用可解释AI技术提高透明度。


<details>
  <summary>Details</summary>
Motivation: 物联网环境中的联邦学习面临数据异构性挑战，特别是在异常检测任务中，设备能力、数据格式和通信约束的差异影响了全局模型性能和隐私保护。需要一种能有效处理特征异构性并保持隐私的解决方案。

Method: 提出一个无监督联邦学习框架，利用两个物联网数据集（一个专注于异常检测，另一个专注于设备识别）的共享特征，同时保留数据集特定特征。使用可解释AI技术（如SHAP）识别影响本地模型决策的关键特征。

Result: 在真实物联网数据集上的实验表明，该方法在异常检测准确率方面显著优于传统联邦学习方法。

Conclusion: 这项工作强调了利用互补数据集的共享特征来优化无监督联邦学习，在去中心化物联网环境中实现卓越异常检测结果的潜力。

Abstract: Federated learning (FL) is an effective paradigm for distributed environments such as the Internet of Things (IoT), where data from diverse devices with varying functionalities remains localized while contributing to a shared global model. By eliminating the need to transmit raw data, FL inherently preserves privacy. However, the heterogeneous nature of IoT data, stemming from differences in device capabilities, data formats, and communication constraints, poses significant challenges to maintaining both global model performance and privacy. In the context of IoT-based anomaly detection, unsupervised FL offers a promising means to identify abnormal behavior without centralized data aggregation. Nevertheless, feature heterogeneity across devices complicates model training and optimization, hindering effective implementation. In this study we propose an efficient unsupervised FL framework that enhances anomaly detection by leveraging shared features from two distinct IoT datasets: one focused on anomaly detection and the other on device identification, while preserving dataset-specific features. To improve transparency and interpretability, we employ explainable AI techniques, such as SHAP, to identify key features influencing local model decisions. Experiments conducted on real-world IoT datasets demonstrate that the proposed method significantly outperforms conventional FL approaches in anomaly detection accuracy. This work underscores the potential of using shared features from complementary datasets to optimize unsupervised federated learning and achieve superior anomaly detection results in decentralized IoT environments.

</details>


### [199] [Adaptive Combinatorial Experimental Design: Pareto Optimality for Decision-Making and Inference](https://arxiv.org/abs/2602.24231)
*Hongrui Xie,Junyu Cao,Kan Xu*

Main category: cs.LG

TL;DR: 本文首次研究了自适应组合实验设计，聚焦于组合多臂老虎机中遗憾最小化与统计功效之间的权衡，提出了帕累托最优性概念，并针对全老虎机反馈和半老虎机反馈两种情况分别设计了MixCombKL和MixCombUCB算法。


<details>
  <summary>Details</summary>
Motivation: 在组合多臂老虎机中，最小化遗憾需要重复利用高奖励臂，而准确推断奖励差距需要充分探索次优动作。这种权衡在自适应组合实验设计中尚未得到系统研究，本文旨在填补这一空白。

Method: 通过帕累托最优性概念形式化权衡问题，针对两种信息结构（全老虎机反馈和半老虎机反馈）分别提出MixCombKL和MixCombUCB算法，并建立理论保证。

Result: 两种算法都被证明是帕累托最优的，在遗憾和臂差距估计误差方面都获得了有限时间保证。研究还发现更丰富的反馈能显著收紧可达到的帕累托前沿，主要增益来自所提方法下估计精度的提升。

Conclusion: 这些发现为多目标决策中的自适应组合实验建立了原则性框架，揭示了反馈结构对权衡效率的重要影响，为实际应用提供了理论基础和算法支持。

Abstract: In this paper, we provide the first investigation into adaptive combinatorial experimental design, focusing on the trade-off between regret minimization and statistical power in combinatorial multi-armed bandits (CMAB). While minimizing regret requires repeated exploitation of high-reward arms, accurate inference on reward gaps requires sufficient exploration of suboptimal actions. We formalize this trade-off through the concept of Pareto optimality and establish equivalent conditions for Pareto-efficient learning in CMAB. We consider two relevant cases under different information structures, i.e., full-bandit feedback and semi-bandit feedback, and propose two algorithms MixCombKL and MixCombUCB respectively for these two cases. We provide theoretical guarantees showing that both algorithms are Pareto optimal, achieving finite-time guarantees on both regret and estimation error of arm gaps. Our results further reveal that richer feedback significantly tightens the attainable Pareto frontier, with the primary gains arising from improved estimation accuracy under our proposed methods. Taken together, these findings establish a principled framework for adaptive combinatorial experimentation in multi-objective decision-making.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [200] [Data-Driven Linearization based Arc Fault Prediction in Medium Voltage Electrical Distribution System](https://arxiv.org/abs/2602.24247)
*Mihir Sinha,Kriti Thakur,Prasanta K. Panigrahi,Alivelu Manga Parimi,Mayukha Pal*

Main category: eess.SY

TL;DR: 提出一种数据驱动线性化框架，用于中压配电系统中高阻抗电弧故障的早期预测，仅使用故障前健康区域数据即可提前11毫秒预测故障发生


<details>
  <summary>Details</summary>
Motivation: 中压配电系统中的高阻抗电弧故障由于故障电流水平低和非线性瞬态行为而难以检测，传统检测算法在动态波形场景下预测困难，需要开发能够早期预测故障并提供可解释性和可扩展性的方法

Method: 采用数据驱动线性化框架，通过坐标嵌入和多项式变换将非线性电流波形转换为线性化空间，仅使用故障前健康区域（0.10秒至0.18秒）数据进行训练，有效捕捉不可见的故障前兆

Result: 该方法在0.189秒预测到电弧故障开始，比实际故障发生时间0.200秒提前11毫秒，表现出显著的早期预警能力。通过特征值分析、预测误差测量、误差增长率和波形再生保真度等性能评估，证实了方法的有效性

Conclusion: 提出的数据驱动线性化框架能够可靠预测中压配电系统中的电弧故障，特别是能够提前预测故障，这对于预防实际故障和事故特别有帮助，证明了该方法在实际应用中的价值

Abstract: High-impedance arc faults (HIAFs) in medium-voltage electrical distribution systems are difficult to detect due to their low fault current levels and nonlinear transient behavior. Traditional detection algorithms generally struggle with predictions under dynamic waveform scenarios. This research provides our approach of using a unique data-driven linearization (DDL) framework for early prediction of HIAFs, giving both interpretability and scalability. The proposed method translates nonlinear current waveforms into a linearized space using coordinate embeddings and polynomial transformation, enabling precise modelling of fault precursors.The total duration of the test waveform is 0.5 seconds, within which the arc fault occurs between 0.2 seconds to 0.3 seconds. Our proposed approach using DDL, trained solely on the pre-fault healthy region (0.10 seconds to 0.18 seconds) effectively captures certain invisible fault precursors, to accurately predict the onset of fault at 0.189 seconds, which is approximately 0.011 seconds (i.e., 11 milliseconds) earlier than the actual fault occurrence. In particular, the framework predicts the start of arc faults at 0.189 seconds, significantly earlier of the actual fault incidence at 0.200 seconds, demonstrating substantial early warning capability. Performance evaluation comprises eigenvalue analysis, prediction error measures, error growth rate and waveform regeneration fidelity. Such early prediction proves that the model is capable of correctly foreseeing faults which is especially helpful in preventing real-world faults and accidents. It confirms that our proposed approach reliably predicts arc faults in medium-voltage power distribution systems

</details>


### [201] [FaultXformer: A Transformer-Encoder Based Fault Classification and Location Identification model in PMU-Integrated Active Electrical Distribution System](https://arxiv.org/abs/2602.24254)
*Kriti Thakur,Alivelu Manga Parimi,Mayukha Pal*

Main category: eess.SY

TL;DR: FaultXformer：基于Transformer编码器的双阶段架构，用于电力配电网的故障类型分类和位置识别，在DER高渗透率场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着分布式能源资源（DERs）在电力配电网中的集成度不断提高，电网运行变得更加复杂和多变，因此需要更准确的故障检测和定位方法。传统方法在处理这种复杂性和变异性方面存在局限性。

Method: 提出FaultXformer，一种基于Transformer编码器的双阶段架构。第一阶段利用PMU获取的实时电流时间序列数据提取丰富的时序信息；第二阶段处理这些特征以区分不同的故障类型并确定故障位置。使用IEEE 13节点测试馈线生成数据集，包含20个故障位置和多种DER集成场景，采用分层10折交叉验证进行评估。

Result: FaultXformer在故障类型分类上平均准确率达到98.76%，在故障位置识别上达到98.92%。相比传统深度学习基线（CNN、RNN、LSTM），在分类准确率上分别高出1.70%、34.95%、2.04%，在位置准确率上分别高出10.82%、40.89%、6.27%。

Conclusion: FaultXformer在DER高渗透率场景下表现出卓越的性能，显著优于传统深度学习模型，证明了基于Transformer的架构在电力系统故障分析中的有效性。

Abstract: Accurate fault detection and localization in electrical distribution systems is crucial, especially with the increasing integration of distributed energy resources (DERs), which inject greater variability and complexity into grid operations. In this study, FaultXformer is proposed, a Transformer encoder-based architecture developed for automatic fault analysis using real-time current data obtained from phasor measurement unit (PMU). The approach utilizes time-series current data to initially extract rich temporal information in stage 1, which is crucial for identifying the fault type and precisely determining its location across multiple nodes. In Stage 2, these extracted features are processed to differentiate among distinct fault types and identify the respective fault location within the distribution system. Thus, this dual-stage transformer encoder pipeline enables high-fidelity representation learning, considerably boosting the performance of the work. The model was validated on a dataset generated from the IEEE 13-node test feeder, simulated with 20 separate fault locations and several DER integration scenarios, utilizing current measurements from four strategically located PMUs. To demonstrate robust performance evaluation, stratified 10-fold cross-validation is performed. FaultXformer achieved average accuracies of 98.76% in fault type classification and 98.92% in fault location identification across cross-validation, consistently surpassing conventional deep learning baselines convolutional neural network (CNN), recurrent neural network (RNN). long short-term memory (LSTM) by 1.70%, 34.95%, and 2.04% in classification accuracy and by 10.82%, 40.89%, and 6.27% in location accuracy, respectively. These results demonstrate the efficacy of the proposed model with significant DER penetration.

</details>


### [202] [Curriculum-Based Soft Actor-Critic for Multi-Section R2R Tension Control](https://arxiv.org/abs/2602.24259)
*Shihao Li,Jiachen Li,Christopher Martin,Zijun Chen,Dongmei Chen,Wei Li*

Main category: eess.SY

TL;DR: 本文提出了一种基于课程学习的Soft Actor-Critic控制器，用于多段卷对卷制造中的张力控制，能够在宽范围操作条件下实现精确跟踪并处理大扰动。


<details>
  <summary>Details</summary>
Motivation: 卷对卷制造中的精确张力控制在变化的操作条件和过程不确定性下非常困难，需要能够适应参数变化和显著不确定性的控制方法。

Method: 采用课程学习的Soft Actor-Critic控制器，分三个阶段训练策略：从27-33N的窄范围开始，逐步扩展到20-40N的完整操作范围，使策略能够在标称和扰动条件下泛化。

Result: 在三段卷对卷基准测试中，学习到的控制器在标称操作中实现精确跟踪，并能处理大扰动（包括20N到40N的阶跃变化），使用单一策略且无需针对特定场景重新调整。

Conclusion: 当系统参数变化且过程不确定性显著时，课程训练的SAC控制器是基于模型控制的实际替代方案，能够在宽操作范围内实现鲁棒控制。

Abstract: Precise tension control in roll-to-roll (R2R) manufacturing is difficult under varying operating conditions and process uncertainty. This paper presents a curriculum-based Soft Actor-Critic (SAC) controller for multi-section R2R tension control. The policy is trained in three phases with progressively wider reference ranges, from 27 to 33 N to the full operating envelope of 20 to 40 N, so it can generalize across nominal and disturbed conditions. On a three-section R2R benchmark, the learned controller achieves accurate tracking in nominal operation and handles large disturbances, including 20 N to 40 N step changes, with a single policy and no scenario-specific retuning. These results indicate that curriculum-trained SAC is a practical alternative to model-based control when system parameters vary and process uncertainty is significant.

</details>


### [203] [Virtual Constraint for a Quadrotor UAV Enforcing a Body-Axis Pointing Direction](https://arxiv.org/abs/2602.24268)
*Alexandre Anahory Simoes,Leonardo Colombo,Juan Giribet,Efstratios Stratoglou*

Main category: eess.SY

TL;DR: 提出了一种在SE(3)上的几何控制框架，用于四旋翼无人机执行指向驱动任务，无需完成完整的姿态参考。


<details>
  <summary>Details</summary>
Motivation: 四旋翼无人机在执行指向驱动任务（如目标跟踪、监视等）时，通常需要完整的姿态控制，但某些任务只需要特定的指向约束，而不需要完整的姿态参考。现有方法可能过于复杂或不必要地限制了无人机的运动能力。

Method: 通过虚拟约束定义任务流形和相关的容许速度集，在满足有效驱动分布横截性条件下，通过线性系统选择输入获得反馈控制律，确保流形不变性。进一步推导了局部离流形稳定化扩展。

Result: 在横截性条件下，不变性强制输入被唯一确定，产生了构造性控制律，对于相关任务获得了闭式表达式。案例研究表明，该方法能够将机体轴锁定到规定的视线方向，同时保持固定高度。

Conclusion: 提出的几何控制框架能够有效处理四旋翼无人机的指向驱动任务，通过任务流形和容许速度集编码任务要求，在满足横截性条件下获得唯一控制律，为相关应用提供了理论保证和实用控制方案。

Abstract: We propose a geometric control framework on $SE(3)$ for quadrotors that enforces pointing-driven missions without completing a full attitude reference. The mission is encoded through virtual constraints defining a task manifold and an associated set of admissible velocities, and invariance is achieved by a feedback law obtained from a linear system in selected inputs. Under a transversality condition with the effective actuation distribution, the invariance-enforcing input is uniquely defined, yielding a constructive control law and, for relevant tasks, closed-form expressions. We further derive a local off-manifold stabilization extension. As a case study, we lock a body axis to a prescribed line-of-sight direction while maintaining fixed altitude.

</details>
